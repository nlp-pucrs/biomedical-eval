{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Qualidade Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiUihPf0EA2S",
        "colab_type": "text"
      },
      "source": [
        "# Create Question Words from MeSH terms\n",
        "\n",
        "**Links úteis:**\n",
        "\n",
        "* MeSH Browser: https://meshb.nlm.nih.gov/search\n",
        "\n",
        "* Unified Medical Language System ®: https://uts.nlm.nih.gov/home.html\n",
        "\n",
        "* UMLS® Reference Manual [Internet]. \n",
        "https://www.ncbi.nlm.nih.gov/books/NBK9685/\n",
        "\n",
        "* Metathesaurus\n",
        "https://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/index.html\n",
        "\n",
        "* Gensim\n",
        "https://www.pydoc.io/pypi/gensim-3.2.0/index.html\n",
        "\n",
        "\n",
        "\n",
        "**Question Words:**\n",
        "* Pares de palavras de domínio amplo:\n",
        "https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/test/test_data/questions-words.txt (inglês)\n",
        "https://github.com/nlx-group/LX-DSemVectors/blob/master/testsets/LX-4WAnalogiesBr.txt (português)\n",
        "\n",
        "\n",
        "\n",
        "**Word Embeddings:**\n",
        "* Embeddings de Artigos Médicos em Inlgês:\n",
        "http://evexdb.org/pmresources/vec-space-models/\n",
        "\n",
        "* Embeddings do PubMed + MIMIC:\n",
        "https://github.com/ncbi-nlp/BioSentVec#biowordvec-biomedical-word-embeddings-with-fasttext\n",
        "\n",
        "* Embeddings de Domínio Amplo Português:\n",
        "http://nilc.icmc.usp.br/embeddings\n",
        "\n",
        "* Wikipedia: https://fasttext.cc/docs/en/pretrained-vectors.html\n",
        "\n",
        "* Pucrs: http://www.inf.pucrs.br/linatural/wordpress/recursos-e-ferramentas/word-embeddings-para-saude/\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rA4u9n_10RJw"
      },
      "source": [
        "## Mount GoogleDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fb798290-379f-420c-9421-cd3d1e38c87b",
        "id": "ZG_D1Atf0P6G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#Montar google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KQ9oTMf90xf",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D1jv4H1T9JwY",
        "colab": {}
      },
      "source": [
        "#imports\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import random\n",
        "import requests\n",
        "import os\n",
        "import logging\n",
        "import tarfile\n",
        "\n",
        "\n",
        "from datetime import datetime\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import FastText\n",
        "from gensim.test.utils import datapath"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcEw6ldxWPl_",
        "colab_type": "text"
      },
      "source": [
        "## Log Definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5BqlSGZVOON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#logging.basicConfig(level=logging.DEBUG)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PELAvB3Hiad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_wR6o-T97bU",
        "colab_type": "text"
      },
      "source": [
        "## Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OM4Yrr03iCVt",
        "colab_type": "text"
      },
      "source": [
        "### Create directorys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2ZU8UuL6dxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataDir = \"./data/\"\n",
        "if not os.path.exists(dataDir):\n",
        "    os.makedirs(dataDir)\n",
        "\n",
        "QWDir = \"./qw/\"\n",
        "if not os.path.exists(QWDir):\n",
        "    os.makedirs(QWDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpE9aeKoiHyy",
        "colab_type": "text"
      },
      "source": [
        "### Filenames MeSH and UMLS\n",
        "(google drive)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1FFFdcmdbR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Localização dos arquivos\n",
        "filenameMESH=\"/content/drive/My Drive/Embeddings/desc2019.xml\"\n",
        "filenameUMLS=\"/content/drive/My Drive/Embeddings/MRCONSO.RRF\"\n",
        "\n",
        "#filenameMESH=\"/content/drive/My Drive/Embeddings - old/mesh/MESH_FILES/xmlmesh/desc2019/desc2019.xml\"\n",
        "#filenameUMLS=\"/content/drive/My Drive/Embeddings - old/UMLS/2019AA/2019AA/META/MRCONSO.RRF\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRn5lVyTAYRk",
        "colab_type": "text"
      },
      "source": [
        "### filenames word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV0Dnm0hAcGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INGLES\n",
        "filePubMed= \"http://evexdb.org/pmresources/vec-space-models/PubMed-w2v.bin\"\n",
        "fileBioWordVec=\"https://ftp.ncbi.nlm.nih.gov/pub/lu/Suppl/BioSentVec/BioWordVec_PubMed_MIMICIII_d200.vec.bin\"\n",
        "fileWikipediaENG = \"https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.zip\"\n",
        "\n",
        "#PORT\n",
        "filePucrs = \"http://grupopln.inf.pucrs.br/health/health_word2vec_300v1.tar.gz\"\n",
        "fileNilc = \"http://143.107.183.175:22980/download.php?file=embeddings/fasttext/skip_s300.zip\"\n",
        "fileWikipediaPOR = \"https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.pt.zip\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu4UBRBYDYER",
        "colab_type": "text"
      },
      "source": [
        "### filenames question words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9oOJQR3Dal1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "QWDominioAmploENG= \"https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/test/test_data/questions-words.txt\"\n",
        "QWDominioAmploPOR = \"/content/drive/My Drive/Embeddings/LX-4WAnalogiesBr.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAEXMyaf-XhJ",
        "colab_type": "text"
      },
      "source": [
        "### filename models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wl_Od2R-ZbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fileModelPucrs = \"/content/data/health_word2vec_300.model\"\n",
        "fileModelNilc = \"/content/data/skip_s300.txt\"\n",
        "fileModelWikipediaPOR = \"/content/data/wiki.pt.vec\"\n",
        "\n",
        "fileModelWikipediaENG=\"/content/data/wiki.en.vec\"\n",
        "fileModelPubMed=\"/content/data/PubMed-w2v.bin\"\n",
        "fileModelBioWordVec=\"/content/data/BioWordVec_PubMed_MIMICIII_d200.vec.bin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f3ZSMyy-Bu5",
        "colab_type": "text"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv-1GNpKGZ6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MESH xml Constants:\n",
        "DESCRIPTOR_RECORD = \"DescriptorRecord\"\n",
        "DESCRIPTOR_UI = \"DescriptorUI\"\n",
        "DESCRIPTOR_NAME = \"DescriptorName/String\"\n",
        "\n",
        "PHARM_ACTION_LIST = \"PharmacologicalActionList/PharmacologicalAction\"\n",
        "DESCRIPTOR_REF_UI = \"DescriptorReferredTo/DescriptorUI\"\n",
        "DESCRIPTOR_REF_NAME = \"DescriptorReferredTo/DescriptorName/String\"\n",
        "\n",
        "\n",
        "#TERM_LIST = \"ConceptList/Concept/TermList\"\n",
        "#TERM_UI = \"TermUI\" '''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMuzJjKg-dBn",
        "colab_type": "text"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBmvhd6P-H3f",
        "colab_type": "text"
      },
      "source": [
        "## Basic Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGrJToL1_Em5",
        "colab_type": "text"
      },
      "source": [
        "### log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Kvs-a4RAt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log(logInfo):\n",
        "  dh = datetime.now()\n",
        "  dh = dh.astimezone(timezone(timedelta(hours=-3)))\n",
        "  dh = dh.strftime('%d/%m/%Y %H:%M:%S')\n",
        "  logger.debug(dh + \" - \" + logInfo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4caFMlIQagu",
        "colab_type": "text"
      },
      "source": [
        "### logProgress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY7QQNbKQh0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logProgress(n, tot, i=6000):\n",
        "  if(n % i == 0):\n",
        "    p = (n/tot)*100\n",
        "    logger.debug(\"Progress... \" + \"{:.0f}\".format(p) + \"%\")  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FauiG0E4_JZP",
        "colab_type": "text"
      },
      "source": [
        "### newEntry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyRaX4A8VqjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def newEntry(heading, word1UI, word1, word2UI, word2):\n",
        "  pair = {\n",
        "        \"heading\": heading,\n",
        "        \"word1UI\":  word1UI,\n",
        "        \"word1\":    word1,\n",
        "        \"word2UI\":  word2UI,\n",
        "        \"word2\":    word2,\n",
        "    }\n",
        "  return pair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NXJagCf_N1g",
        "colab_type": "text"
      },
      "source": [
        "### clearTerm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASlKbK9pDpAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clearTerm(term):\n",
        "  if(\"[\" in term):\n",
        "    i = term.index(\"[\")\n",
        "    term = term[:i]\n",
        "  \n",
        "  if(\"(\" in term):\n",
        "    i = term.index(\"(\")\n",
        "    term = term[:i]\n",
        "  \n",
        "  term = term.strip()\n",
        "  return term"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSVExfv1Y0PY",
        "colab_type": "text"
      },
      "source": [
        "### downloadFile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JamzZXaJBW4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downloadFile(url, filePath, filename=\"\"):  \n",
        "  if(filename == \"\"):\n",
        "    name = url.split(\"/\")[-1]\n",
        "  else:\n",
        "    name = filename\n",
        "  filePath = filePath+name\n",
        "  \n",
        "  if(not os.path.exists(filePath)): \n",
        "    log(\"Downloading... \" + filePath)\n",
        "    r = requests.get(url, allow_redirects=True)\n",
        "    file = open(filePath, 'wb').write(r.content)\n",
        "    log(\"File downloaded \" + filePath)\n",
        "  else:\n",
        "    print(\"File already downloaded.\")\n",
        "  return filePath"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC2dfJbH-MCQ",
        "colab_type": "text"
      },
      "source": [
        "## Dictionaries functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxajE1qU-ijf",
        "colab_type": "text"
      },
      "source": [
        "### loadMeSH\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WWo8dtsRPA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadMeSHXML(filename):\n",
        "  log(\"Loading MeSH XML\")\n",
        "  tree = ET.parse(filename)\n",
        "  root = tree.getroot()\n",
        "  log(\"MeSH XML Loaded\")\n",
        "  return root"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMgFs8Ff-poQ",
        "colab_type": "text"
      },
      "source": [
        "### loadUMLSDict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7G-gmsRRijI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadUMLSDict():\n",
        "  log(\"Loading dictionaries file \" )\n",
        "  dictionaries = pd.read_csv(filenameUMLS, index_col = False, sep=\"|\", header=0, \n",
        "                      names = [\"CUI\", \"LAT\", \"TS\", \"LUI\", \"STT\", \"SUI\", \n",
        "                               \"ISPREF\", \"AUI\", \"SAUI\", \"SCUI\", \"SDUI\", \"SAB\", \"TTY\",\n",
        "                               \"CODE\", \"STR\", \"SRL\", \"SUPPRESS\", \"CVF\"],\n",
        "                      error_bad_lines=False)\n",
        "  \n",
        "  dictionaries = dictionaries[[\"CUI\", \"LAT\", \"SUI\", \"TTY\", \"CODE\", \"STR\"]]  \n",
        "  \n",
        "  log(\"dictionaries file loaded \" )\n",
        "  return dictionaries"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9B1Uc7x-5Ta",
        "colab_type": "text"
      },
      "source": [
        "### getDictLanguage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-sGBBuDRzt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDictLanguage(lang):\n",
        "  log(\"Loading dict \" + lang)\n",
        "  dic = dictionaries[dictionaries[\"LAT\"] == lang]\n",
        "  log(\"Dict loaded \")\n",
        "  return dic\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac4slGl__Ubf",
        "colab_type": "text"
      },
      "source": [
        "### listTerms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xFrMDx_qnoq",
        "colab_type": "code",
        "outputId": "37adf4be-833c-46b4-917f-11b7dd633a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "def listTerms(root):\n",
        "    listTerms = []\n",
        "    for pDesc in root.findall(DESCRIPTOR_RECORD):\n",
        "      descriptorUI = pDesc.find(DESCRIPTOR_UI).text  \n",
        "      descriptorName = pDesc.find(DESCRIPTOR_NAME).text\n",
        "      listTerms.append(descriptorUI + \" - \" + descriptorName)  \n",
        "    return listTerms;"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-320036f53231>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for (pDesc in root.findall(DESCRIPTOR_RECORD)):\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ8T1oJMlMu3",
        "colab_type": "text"
      },
      "source": [
        "### getDictDescriptorName"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZDR5MviQ-TT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getDictDescriptorName(dic, descriptorUI):\n",
        "  descriptorName = dic[(dic[\"CODE\"] == descriptorUI) & (dic[\"TTY\"] == \"MH\")][\"STR\"]\n",
        "  if(not descriptorName.empty):\n",
        "    descriptorName = clearTerm(descriptorName.iloc[0])\n",
        "  else:\n",
        "    descriptorName = \"\"\n",
        "\n",
        "  return descriptorName\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zirn0Q5R-S9_",
        "colab_type": "text"
      },
      "source": [
        "## Pairs functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0dFevTDAb7L",
        "colab_type": "text"
      },
      "source": [
        "### pairDescriptorPharmacologicalActionFiltering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsttwu83T4vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pairDescriptorPharmacologicalActionFiltering(root, dic): \n",
        "  \n",
        "  \n",
        "  pairs = [] \n",
        "  notFound = 0\n",
        "  moreWords = 0\n",
        "  i = 0\n",
        "  tot = len(root.findall(DESCRIPTOR_RECORD))\n",
        "  for pDesc in root.findall(DESCRIPTOR_RECORD): \n",
        "      \n",
        "    logProgress(i, tot)\n",
        "\n",
        "    i = i + 1\n",
        "      \n",
        "    descriptorUI = pDesc.find(DESCRIPTOR_UI).text \n",
        "    descriptorName = dic[dic[\"CODE\"] == descriptorUI][\"STR\"][0:1]\n",
        "    \n",
        "    if(descriptorName.empty):\n",
        "      notFound = notFound + 1  \n",
        "    else:      \n",
        "      descriptorName = clearTerm(descriptorName.iloc[0])\n",
        "      \n",
        "\n",
        "      if(len(descriptorName.split(\" \")) == 1):\n",
        "        pharmList = pDesc.findall(PHARM_ACTION_LIST) \n",
        "\n",
        "        for pharm in pharmList: \n",
        "          pharmUI = pharm.find(DESCRIPTOR_REF_UI).text \n",
        "          pharmTerm = dic[(dic[\"CODE\"] == pharmUI) & (dic[\"TTY\"] == \"MH\")][\"STR\"][0:1]\n",
        "          \n",
        "          if(pharmTerm.empty):\n",
        "            notFound = notFound + 1 \n",
        "          else:\n",
        "            pharmTerm = clearTerm(pharmTerm.iloc[0])\n",
        "            if(len(pharmTerm.split(\" \")) == 1):\n",
        "              pairs.append(newEntry(\"\", descriptorUI, descriptorName.lower(), pharmUI, pharmTerm.lower()))\n",
        "        \n",
        "        \n",
        "      else:\n",
        "        moreWords = moreWords + 1;\n",
        "        \n",
        "\n",
        "  log(\"Translations not found: \" + str(notFound))  \n",
        "  log(\"Descriptors with more than one word: \" + str(moreWords))  \n",
        "  log(\"Total pairs: \" + str(len(pairs)))  \n",
        "\n",
        "  \n",
        "  return pairs; \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEwqjiIhzVKc",
        "colab_type": "text"
      },
      "source": [
        "### filterTermsWordEmbbedings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZrYn0g3zX2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filterTermsWordEmbbedings(pairs, models):\n",
        "  pairs2 = pairs.copy()\n",
        "  \n",
        "  for model in models:\n",
        "    print(\"Filtering \" + str(len(pairs2)) )\n",
        "    for p in pairs:\n",
        "      if((p['word1'] not in model.wv.index2word[:300000]) or (p['word2'] not in model.wv.index2word[:300000])):\n",
        "        if(p in pairs2):\n",
        "          pairs2.remove(p)\n",
        "  print(\"Result \" + str(len(pairs2)) )\n",
        " \n",
        "  return pairs2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqmnC6-y_Dnh",
        "colab_type": "text"
      },
      "source": [
        "### questionWordsFile2PairsList"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa5Bycmv_LPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def questionWordsFile2PairsList(file):\n",
        "  pairs = []\n",
        "\n",
        "  for l in open(file , \"r\"):\n",
        "    words = l.split(\" \", 4)\n",
        "    if(len(words) == 4):    \n",
        "      pairs.append(newEntry(\"\", \"\", clearTerm(words[0].lower()), \"\", clearTerm(words[1].lower())))\n",
        "      pairs.append(newEntry(\"\", \"\", clearTerm(words[2].lower()), \"\", clearTerm(words[3].replace(\"\\n\", \"\"))))\n",
        "\n",
        "  \n",
        "  return pairs\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1tGZsfj-V_9",
        "colab_type": "text"
      },
      "source": [
        "## File Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj0bnSX3Af8i",
        "colab_type": "text"
      },
      "source": [
        "### createQuestionWordsFile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOEkV5wa3Y8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createQuestionWordsFile(fileName, pairsList,  section=\"section\", size=1000):\n",
        "  \n",
        "  log(\"Creating File...\")\n",
        "  \n",
        "  if os.path.exists(fileName):\n",
        "    os.remove(fileName)\n",
        "\n",
        "  file  = open(fileName, 'a+')  \n",
        "  file.write(\": \"+ section.lower() + \" \\n\")\n",
        "  i = 0\n",
        "\n",
        "  lines = []\n",
        "  \n",
        "  while i < size:\n",
        "\n",
        "    logProgress(i, size, 10)\n",
        "      \n",
        "    pair1 = random.choice(pairsList)\n",
        "    pair2 = random.choice(pairsList)\n",
        "    \n",
        "    \n",
        "    if(pair1 != pair2 and (pair1, pair2) not in lines):\n",
        "      lines.append((pair1, pair2))\n",
        "      file.write(pair1[\"word1\"] + \" \" + pair1[\"word2\"] + \" \" + pair2[\"word1\"] + \" \" + pair2[\"word2\"]+\"\\n\")\n",
        "      i = i + 1  \n",
        "  \n",
        "  log(\"File created:\" + fileName)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdiqGdDoAhbC",
        "colab_type": "text"
      },
      "source": [
        "### createCompleteQuestionWordsFile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9dClQ1RtTGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createCompleteQuestionWordsFile(fileName, pairsList, section = \"section\"):  \n",
        "  \n",
        "  log(\"Creating File...\")\n",
        "\n",
        "  lines = []\n",
        "\n",
        "  if os.path.exists(fileName):\n",
        "    os.remove(fileName)\n",
        "\n",
        "  file  = open(fileName, 'a+')  \n",
        "  section.replace(\" \", \"-\")\n",
        "  log(section)\n",
        "  file.write(\": \"+ section.lower() + \" \\n\")\n",
        "  \n",
        "  pairsList1 = pairsList.copy()\n",
        "  totalPairs = 0  \n",
        "  ignore = 0\n",
        "  total = len(pairsList)\n",
        "  i = 0\n",
        "  log(\"Total pairs :\" + str(total))\n",
        "  while len(pairsList1) > 0:   \n",
        "    i += 1\n",
        "\n",
        "    pair1 = pairsList1[0];\n",
        "    word1 = pair1[\"word1\"]\n",
        "    word2 = pair1[\"word2\"]\n",
        "    \n",
        "    for pair2 in pairsList1[1:]:    \n",
        "        word3 = pair2[\"word1\"]\n",
        "        word4 = pair2[\"word2\"]\n",
        "\n",
        "        line = (word1, word2, word3, word4)\n",
        "        lines.append(line)\n",
        "\n",
        "          \n",
        "    pairsList1.pop(0)\n",
        "       \n",
        "\n",
        "  mylist = list( dict.fromkeys(lines) )\n",
        "  lines = list(mylist)\n",
        "\n",
        "\n",
        "  for line in lines:\n",
        "    totalPairs +=  1 \n",
        "    file.write(line[0] + \" \" + line[1] + \" \" + line[2] + \" \" + line[3] + \"\\n\")        \n",
        "\n",
        "  \n",
        "  file.close()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK8D78iwhPMZ",
        "colab_type": "text"
      },
      "source": [
        "### fileLineCount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erX29bQzBUmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fileLineCount(fname):\n",
        "    return sum(1 for line in open(fname))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMZLz-C0_vFj",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz1KF4Yqg2v6",
        "colab_type": "text"
      },
      "source": [
        "### printScore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKm4uEwuDLEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printScore(analogy_scores, qwFile):\n",
        "  log(\"\\n ### Result ### \")\n",
        "  \n",
        "  totalPairs = fileLineCount(qwFile) - 1\n",
        "  testedPairs = len(analogy_scores[1][0]['correct']) + len(analogy_scores[1][0]['incorrect'])\n",
        "  notTestedPairs = totalPairs - testedPairs\n",
        "  corrects = len(analogy_scores[1][0]['correct'])\n",
        "  incorrects =  testedPairs - corrects\n",
        "  \n",
        "  if(totalPairs > 0):\n",
        "    pTested = (testedPairs/totalPairs)*100\n",
        "    pNotTestedPairs = (notTestedPairs/totalPairs)*100\n",
        "  else:\n",
        "    pTested = 0       \n",
        "    pNotTestedPairs = 0\n",
        "\n",
        "  if(testedPairs > 0):                                                   \n",
        "    pCorrects = (corrects/testedPairs)*100\n",
        "    pIncorrects = (incorrects/testedPairs)*100\n",
        "  else:\n",
        "    pCorrects = 0\n",
        "    pIncorrects = 0\n",
        "                                             \n",
        "    \n",
        "  print(\"# Score = \" + str(analogy_scores[0]))\n",
        "  print(\"# Total pairs = \" + str(totalPairs))\n",
        "  print(\"# Tested pairs = \" + str(testedPairs) + \" - \" + \"{:.4f}\".format(pTested) + \"%\")  \n",
        "  print(\"# Not Tested pairs = \" + str(notTestedPairs) + \" - \" + \"{:.4f}\".format(pNotTestedPairs) + \"%\")  \n",
        "  print(\"# Corrects = \"  + str(corrects) + \" - \" + \"{:.4f}\".format(pCorrects) + \"%\")  \n",
        "  print(\"# Incorrects = \"  + str(incorrects) + \" - \" + \"{:.4f}\".format(pIncorrects) + \"%\")  \n",
        "  #printCorrects(analogy_scores)\n",
        "  print(\"\\n\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWRJLsUehAqh",
        "colab_type": "text"
      },
      "source": [
        "### printCorrects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXLLQWmpDeE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printCorrects(analogy_scores):\n",
        "  print(\"Corrects:\")\n",
        "  for c in analogy_scores[1][0]['correct']:\n",
        "      print(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLcL-Uz-hDLl",
        "colab_type": "text"
      },
      "source": [
        "### printIncorrects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJdh2X4whGAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printIncorrects(analogy_scores):\n",
        "  print(\"Incorrects:\")\n",
        "  for i in analogy_scores[1][0]['incorrect']:\n",
        "      print(i)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcmY1OslNJBu",
        "colab_type": "text"
      },
      "source": [
        "##Create Question Words Files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D58WnvZZ4Im",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = loadMeSHXML(filenameMESH)\n",
        "dictionaries = loadUMLSDict() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnhUn7Sci7wq",
        "colab_type": "text"
      },
      "source": [
        "### Define idioma dos experimentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppH_xG1XjC__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lang = 'pt' # ou 'en'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2g7bmQujIE4",
        "colab_type": "text"
      },
      "source": [
        "### Português"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO_jLGBFhrn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'pt':\n",
        "  tf = tarfile.open(downloadFile(filePucrs, dataDir))\n",
        "  tf.extractall(dataDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkLzH1MXCrPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'pt': fn = downloadFile(fileNilc, dataDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeGKSDbpjAvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'pt':\n",
        "  zip = ZipFile(fn)\n",
        "  zip.extractall(dataDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfufg4e3jaGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'pt':\n",
        "  zip = ZipFile(downloadFile(fileWikipediaPOR, dataDir))\n",
        "  zip.extractall(dataDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4wMopDFEBAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'pt':\n",
        "  # Carregar modelos: PUCRS \n",
        "  modelPucrs = Word2Vec.load(fileModelPucrs)\n",
        "\n",
        "  # Carregar modelo Nilc\n",
        "  modelNilc = KeyedVectors.load_word2vec_format(fileModelNilc)\n",
        "\n",
        "  # Carregar modelo Wikipedia\n",
        "  modelWikipediaPOR = KeyedVectors.load_word2vec_format(fileModelWikipediaPOR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_X0q1E766-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separar pares (pharm - pharmAction)\n",
        "if lang == 'pt': pairsPT = pairDescriptorPharmacologicalActionFiltering(root, getDictLanguage(\"POR\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucDdf3Aq68Hs",
        "colab_type": "code",
        "outputId": "05df2c49-cee5-48b4-bab1-9a869f5731f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        }
      },
      "source": [
        "# Filtrar por pares conhecidos\n",
        "if lang == 'pt':\n",
        "  pairsPucrs = filterTermsWordEmbbedings(pairsPT, [modelPucrs])\n",
        "  print(\"# Total de pares no modelo da Pucrs: \" + str(len(pairsPucrs)) + \"\\n\")\n",
        "\n",
        "  pairsNilc = filterTermsWordEmbbedings(pairsPT, [modelNilc])\n",
        "  print(\"# Total de pares no modelo Nilc: \" + str(len(pairsNilc)) + \"\\n\")\n",
        "\n",
        "  pairsWiki = filterTermsWordEmbbedings(pairsPT, [modelWikipediaPOR])\n",
        "  print(\"# Total de pares no modelo Wikipedia: \" + str(len(pairsWiki)) + \"\\n\")\n",
        "\n",
        "  pairsTotal = filterTermsWordEmbbedings(pairsPT, [modelPucrs, modelNilc, modelWikipediaPOR])\n",
        "  print(\"# Total de pares em todos modelos : \" + str(len(pairsTotal)) + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filtering 2002\n",
            "Filtering 2002\n",
            "Result 128\n",
            "# Total de pares no modelo da Pucrs: 128\n",
            "\n",
            "Filtering 2002\n",
            "Result 128\n",
            "# Total de pares no modelo da Pucrs: 128\n",
            "\n",
            "Filtering 2002\n",
            "Result 269\n",
            "# Total de pares no modelo Nilc: 269\n",
            "\n",
            "Filtering 2002\n",
            "Result 269\n",
            "# Total de pares no modelo Nilc: 269\n",
            "\n",
            "Filtering 2002\n",
            "Result 253\n",
            "# Total de pares no modelo Wikipedia: 253\n",
            "\n",
            "Filtering 2002\n",
            "Result 253\n",
            "# Total de pares no modelo Wikipedia: 253\n",
            "\n",
            "Filtering 2002\n",
            "Filtering 128\n",
            "Filtering 128\n",
            "Filtering 52\n",
            "Filtering 52\n",
            "Result 50\n",
            "# Total de pares em todos modelos : 50\n",
            "\n",
            "Result 50\n",
            "# Total de pares em todos modelos : 50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8v19LyrHKeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gerar arquivo completo\n",
        "if lang == 'pt':\n",
        "  QW_Pharm_POR=QWDir+\"QW_POR.txt\"\n",
        "  createCompleteQuestionWordsFile(QW_Pharm_POR, pairsTotal, section=\"pharm + pharmAction\")\n",
        "  print(\"Total de pares no arquivo: \" + str(fileLineCount(QW_Pharm_POR) - 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "540GC-9Z_sAW",
        "colab_type": "code",
        "outputId": "7154db28-6591-4a79-b253-2e2d37634e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "if lang == 'pt': \n",
        "  pairsQW = questionWordsFile2PairsList(QWDominioAmploPOR)\n",
        "\n",
        "\n",
        "  # Filtrar por pares conhecidos\n",
        "if lang == 'pt':\n",
        "  pairsPucrs = filterTermsWordEmbbedings(pairsQW, [modelPucrs])\n",
        "  print(\"# Total de pares no modelo da Pucrs: \" + str(len(pairsPucrs)) + \"\\n\")\n",
        "\n",
        "  pairsNilc = filterTermsWordEmbbedings(pairsQW, [modelNilc])\n",
        "  print(\"# Total de pares no modelo Nilc: \" + str(len(pairsNilc)) + \"\\n\")\n",
        "\n",
        "  pairsWiki = filterTermsWordEmbbedings(pairsQW, [modelWikipediaPOR])\n",
        "  print(\"# Total de pares no modelo Wikipedia: \" + str(len(pairsWiki)) + \"\\n\")\n",
        "\n",
        "  pairsTotal = filterTermsWordEmbbedings(pairsQW, [modelPucrs, modelNilc, modelWikipediaPOR])\n",
        "  print(\"# Total de pares em todos modelos : \" + str(len(pairsTotal)) + \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filtering 35116\n",
            "Result 7199\n",
            "# Total de pares no modelo da Pucrs: 7199\n",
            "\n",
            "Filtering 35116\n",
            "Result 24874\n",
            "# Total de pares no modelo Nilc: 24874\n",
            "\n",
            "Filtering 35116\n",
            "Result 24350\n",
            "# Total de pares no modelo Wikipedia: 24350\n",
            "\n",
            "Filtering 35116\n",
            "Filtering 7199\n",
            "Filtering 7199\n",
            "Result 7199\n",
            "# Total de pares em todos modelos : 7199\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgEq_4huPCOJ",
        "colab_type": "code",
        "outputId": "6881f1af-b63d-4863-ee17-5b59e18450f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Gerar arquivo completo\n",
        "if lang == 'pt':\n",
        "  QWDominioAmploPOR_2=QWDir+\"QW_POR_2.txt\"\n",
        "  createCompleteQuestionWordsFile(QWDominioAmploPOR_2, pairsTotal, section=\"pharm + pharmAction\")\n",
        "  print(\"Total de pares no arquivo: \" + str(fileLineCount(QWDominioAmploPOR_2) - 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total de pares no arquivo: 6947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPLUCjjKjOFf",
        "colab_type": "text"
      },
      "source": [
        "### Inglês"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbyTuWq9Y0KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if lang == 'en': downloadFile(filePubMed, dataDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZsz2eppZbXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'en':\n",
        "  zip = ZipFile(downloadFile(fileWikipediaENG, dataDir))\n",
        "  zip.extractall(dataDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki7mjNzSm37r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Carregar modelo PubMed\n",
        "if lang == 'en': modelPubMed = KeyedVectors.load_word2vec_format(fileModelPubMed, binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzKVDiRJZg1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'en':\n",
        "  # Carregar Modelo Bioword\n",
        "  modelBioWordVec = KeyedVectors.load_word2vec_format(downloadFile(fileBioWordVec, dataDir), binary=True)\n",
        "\n",
        "  # Carregar modelo Wikipedia\n",
        "  modelWikipediaENG =  KeyedVectors.load_word2vec_format(fileModelWikipediaENG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mmifeXHm7BM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'en':\n",
        "  # Gerar pares com 1 palavra\n",
        "  pairsENG = pairDescriptorPharmacologicalActionFiltering(root, getDictLanguage(\"ENG\"))\n",
        "\n",
        "  # Pares existentes no modelo PubMed\n",
        "  pairsPubMed = filterTermsWordEmbbedings(pairsENG, [modelPubMed])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mXsn5YtYRa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'en':\n",
        "  # Pares existentes no modelo BioWordVec\n",
        "  pairsBioWordVec = filterTermsWordEmbbedings(pairsENG, [modelBioWordVec])\n",
        "\n",
        "  # Pares existentes no modelo Wikipedia\n",
        "  pairsWikipedia = filterTermsWordEmbbedings(pairsENG, [modelWikipediaENG])\n",
        "\n",
        "  # Pares existentes nos 2 modelos\n",
        "  totalPairsENG = filterTermsWordEmbbedings(pairsENG, [modelPubMed, modelBioWordVec, modelWikipediaENG])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTgfZy5NYiEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gerar um arquivo com no máximo 1000 pares\n",
        "if lang == 'en':\n",
        "  QW_Pharm_ENG=QWDir + \"/QW_ENG.txt\"\n",
        "  createQuestionWordsFile(QW_Pharm_ENG, totalPairsENG,  size=1225)\n",
        "  print(\"Total de pares no arquivo: \" + str(fileLineCount(QW_Pharm_ENG) - 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuyQkR6ohWds",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq2QSkEfhaQi",
        "colab_type": "text"
      },
      "source": [
        "## Português"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObnXN0jPhd0x",
        "colab_type": "text"
      },
      "source": [
        "### Domínimo Específico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z6tjIys7p4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Avaliar:\n",
        "if lang == 'pt':\n",
        "  asPucrsEspPOR = modelPucrs.wv.evaluate_word_analogies(QW_Pharm_POR, case_insensitive=True)\n",
        "  printScore(asPucrsEspPOR, QW_Pharm_POR)\n",
        "\n",
        "  asNilcEspPOR = modelNilc.evaluate_word_analogies(QW_Pharm_POR, case_insensitive=True)\n",
        "  printScore(asNilcEspPOR, QW_Pharm_POR)\n",
        "\n",
        "  asWikiEspPOR = modelWikipediaPOR.evaluate_word_analogies(QW_Pharm_POR, case_insensitive=True)\n",
        "  printScore(asWikiEspPOR, QW_Pharm_POR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFS0XaRChjif",
        "colab_type": "text"
      },
      "source": [
        "### Domínimo Amplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q4-_ADqk2dv",
        "colab_type": "code",
        "outputId": "4ba3bfb6-903d-4f41-ab7b-41028d7b6597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "# Avaliar:\n",
        "if lang == 'pt':\n",
        "  asPucrsAmpPOR = modelPucrs.wv.evaluate_word_analogies(QWDominioAmploPOR_2, case_insensitive=True)\n",
        "  printScore(asPucrsAmpPOR, QWDominioAmploPOR_2)\n",
        "\n",
        "  asNilcAmpPOR = modelNilc.evaluate_word_analogies(QWDominioAmploPOR_2, case_insensitive=True)\n",
        "  printScore(asNilcAmpPOR, QWDominioAmploPOR_2)\n",
        "\n",
        "  asWikiAmpPOR = modelWikipediaPOR.evaluate_word_analogies(QWDominioAmploPOR_2, case_insensitive=True)\n",
        "  printScore(asWikiAmpPOR, QWDominioAmploPOR_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Score = 0.04563120771556067\n",
            "# Total pairs = 6947\n",
            "# Tested pairs = 6947 - 100.0000%\n",
            "# Not Tested pairs = 0 - 0.0000%\n",
            "# Corrects = 317 - 4.5631%\n",
            "# Incorrects = 6630 - 95.4369%\n",
            "\n",
            "\n",
            "# Score = 0.2149129120483662\n",
            "# Total pairs = 6947\n",
            "# Tested pairs = 6947 - 100.0000%\n",
            "# Not Tested pairs = 0 - 0.0000%\n",
            "# Corrects = 1493 - 21.4913%\n",
            "# Incorrects = 5454 - 78.5087%\n",
            "\n",
            "\n",
            "# Score = 0.25435439758168993\n",
            "# Total pairs = 6947\n",
            "# Tested pairs = 6947 - 100.0000%\n",
            "# Not Tested pairs = 0 - 0.0000%\n",
            "# Corrects = 1767 - 25.4354%\n",
            "# Incorrects = 5180 - 74.5646%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7eahxPMhox9",
        "colab_type": "text"
      },
      "source": [
        "## Inglês"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScNXhbzBhrVr",
        "colab_type": "text"
      },
      "source": [
        "### Domínio Específico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDG6RFxsug6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'en':\n",
        "  asPubMedEspENG = modelPubMed.evaluate_word_analogies(QW_Pharm_ENG, case_insensitive=True)\n",
        "  printScore(asPubMedEspENG, QW_Pharm_ENG)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVWDPxf8Yq6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'en':\n",
        "  asBioWordVecEspENG = modelBioWordVec.evaluate_word_analogies(QW_Pharm_ENG, case_insensitive=True)\n",
        "  printScore(asBioWordVecEspENG, filenameQW_ENG)\n",
        "\n",
        "  asWikipediaEspENG = modelWikipediaENG.evaluate_word_analogies(QW_Pharm_ENG, case_insensitive=True)\n",
        "  printScore(asWikipediaEspENG, filenameQW_ENG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tIAeMg8ht_f",
        "colab_type": "text"
      },
      "source": [
        "### Domínio Amplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYLN9X8RukXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'en':\n",
        "  asPubMedAmpENG = modelPubMed.evaluate_word_analogies(datapath('questions-words.txt'), case_insensitive=True)\n",
        "  printScore(asPubMedAmpENG, datapath('questions-words.txt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WREcmkQbqBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if lang == 'en':\n",
        "  asBioWordVecAmpENG = modelBioWordVec.evaluate_word_analogies(datapath('questions-words.txt'), case_insensitive=True)\n",
        "  printScore(asBioWordVecAmpENG, QWDominioAmploENG)\n",
        "\n",
        "  asWikipediaAmpENG = modelWikipediaENG.evaluate_word_analogies(datapath('questions-words.txt'), case_insensitive=True)\n",
        "  printScore(asWikipediaAmpENG, QWDominioAmploENG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4nJ1MoOlyV_",
        "colab_type": "text"
      },
      "source": [
        "## Other Languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ijeTwQP7tIHm",
        "colab": {}
      },
      "source": [
        "languages = list(dictionaries[\"LAT\"].unique())\n",
        "languages.remove(\"ENG\")\n",
        "languages.remove(\"POR\")\n",
        "print(languages)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgqZSBRW_4xw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for lan in languages:\n",
        "  print(\"Creating file for language: \" + lan)\n",
        "  pairs = pairDescriptorPharmacologicalActionFiltering(root, getDictLanguage(lan))\n",
        "  if len(pairs) > 0:\n",
        "    createQuestionWordsFile(\"qw/QW_\"+lan+\".txt\", pairs,  size=2500)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}