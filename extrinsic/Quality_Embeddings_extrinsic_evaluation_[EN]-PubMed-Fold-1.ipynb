{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quality Embeddings: extrinsic evaluation [EN].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp5-a7qLGSFT",
        "colab_type": "code",
        "outputId": "a0df8022-cf7b-4aee-cb7c-7f283b8ef5a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install flair -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 143kB 2.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 983kB 51.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 54.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 798kB 46.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 53.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 46.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 45.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 32.9MB/s \n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqvynY3V9iCc",
        "colab_type": "code",
        "outputId": "b1a977d0-9582-4b3e-b338-73e445b77367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!wget -c https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
        "!unzip -o drugsCom_raw.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-08 14:24:30--  https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42989872 (41M) [application/x-httpd-php]\n",
            "Saving to: ‘drugsCom_raw.zip’\n",
            "\n",
            "drugsCom_raw.zip    100%[===================>]  41.00M  30.2MB/s    in 1.4s    \n",
            "\n",
            "2020-03-08 14:24:32 (30.2 MB/s) - ‘drugsCom_raw.zip’ saved [42989872/42989872]\n",
            "\n",
            "Archive:  drugsCom_raw.zip\n",
            "  inflating: drugsComTest_raw.tsv    \n",
            "  inflating: drugsComTrain_raw.tsv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVgelMk39uuZ",
        "colab_type": "code",
        "outputId": "8f9c4350-4b8b-4997-e5d8-fb95cc8a7a7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "drugs = pd.read_csv('/content/drugsComTrain_raw.tsv', sep='\\t', header=0)#, nrows=10000)\n",
        "print(drugs.shape, drugs.columns)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(161297, 7) Index(['Unnamed: 0', 'drugName', 'condition', 'review', 'rating', 'date',\n",
            "       'usefulCount'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1iEuePrhY6y",
        "colab_type": "code",
        "outputId": "4e827251-6398-402a-8f28-f217edd58e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "drugs[['Unnamed: 0','rating']].groupby('rating').count()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>21619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>6931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>6513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>5012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>8013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>6343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>9456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>18890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>27531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.0</th>\n",
              "      <td>50989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0\n",
              "rating            \n",
              "1.0          21619\n",
              "2.0           6931\n",
              "3.0           6513\n",
              "4.0           5012\n",
              "5.0           8013\n",
              "6.0           6343\n",
              "7.0           9456\n",
              "8.0          18890\n",
              "9.0          27531\n",
              "10.0         50989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ay8xkQYhusm",
        "colab_type": "code",
        "outputId": "7fcf309e-1754-4017-fdd0-44b0d190909d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "drugs = pd.read_csv('/content/drugsComTrain_raw.tsv', sep='\\t', header=0, nrows=20000)\n",
        "drugs[['Unnamed: 0','rating']].groupby('rating').count()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>2658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>1019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>1144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>2269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>3412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.0</th>\n",
              "      <td>6387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0\n",
              "rating            \n",
              "1.0           2658\n",
              "2.0            872\n",
              "3.0            811\n",
              "4.0            651\n",
              "5.0           1019\n",
              "6.0            777\n",
              "7.0           1144\n",
              "8.0           2269\n",
              "9.0           3412\n",
              "10.0          6387"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFATEJgwHwQQ",
        "colab_type": "code",
        "outputId": "8eb503c8-33c7-4569-c032-44e4ced964eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from flair.data import Sentence, Label\n",
        "\n",
        "sentences = []\n",
        "for idx in drugs.index:\n",
        "  data = drugs.iloc[idx]\n",
        "  sentence = Sentence(data.review, labels=[Label(value=str(data.rating))], use_tokenizer=True)\n",
        "  sentences.append(sentence)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXUic-jpLXP0",
        "colab_type": "code",
        "outputId": "601fe307-357c-4f53-aaaa-32757f94e851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!wget -c https://ghc-flair.s3.amazonaws.com/PubMed-w2v.bin \n",
        "\n",
        "import gensim\n",
        "\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('/content/PubMed-w2v.bin', binary=True)\n",
        "word_vectors.save('pubmed.model')\n",
        "\n",
        "n_loop = 0"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-08 14:25:28--  https://ghc-flair.s3.amazonaws.com/PubMed-w2v.bin\n",
            "Resolving ghc-flair.s3.amazonaws.com (ghc-flair.s3.amazonaws.com)... 52.216.24.212\n",
            "Connecting to ghc-flair.s3.amazonaws.com (ghc-flair.s3.amazonaws.com)|52.216.24.212|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1909156308 (1.8G) [application/octet-stream]\n",
            "Saving to: ‘PubMed-w2v.bin’\n",
            "\n",
            "PubMed-w2v.bin      100%[===================>]   1.78G  75.4MB/s    in 24s     \n",
            "\n",
            "2020-03-08 14:25:53 (74.9 MB/s) - ‘PubMed-w2v.bin’ saved [1909156308/1909156308]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzeJV4E1h6tf",
        "colab_type": "code",
        "outputId": "fd43263f-a988-428a-8ce0-e0f4a7b347f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from flair.embeddings import WordEmbeddings\n",
        "custom_embedding =  WordEmbeddings('pubmed.model')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slP7-_93IaWF",
        "colab_type": "code",
        "outputId": "fea5b4df-ece8-4498-d30c-2542a9846628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "from flair.data import Sentence, Corpus\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings, BertEmbeddings\n",
        "from flair.models.text_regression_model import TextRegressor\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "\n",
        "target_set = drugs['rating'].values\n",
        "\n",
        "results = []\n",
        "\n",
        "## TEST\n",
        "kfold_test = StratifiedKFold(n_splits=3, random_state=13)\n",
        "for i, (train, test) in enumerate(kfold_test.split(target_set, target_set)):\n",
        "\n",
        "  if i > n_loop:\n",
        "    break;\n",
        "\n",
        "  if i < n_loop:\n",
        "    continue;\n",
        "\n",
        "\n",
        "  print(i, len(train), len(test))\n",
        "  corpus = Corpus([sentences[t] for t in train], [sentences[d] for d in test], [sentences[e] for e in test]) \n",
        "\n",
        "  label_dict = corpus.make_label_dictionary()\n",
        "  \n",
        "  word_embeddings = [custom_embedding]\n",
        "  \n",
        "  document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
        "                                                                       hidden_size=512,\n",
        "                                                                       reproject_words=True,\n",
        "                                                                       reproject_words_dimension=256,\n",
        "                                                                       )\n",
        "  model = TextRegressor(document_embeddings)\n",
        "\n",
        "  trainer = ModelTrainer(model, corpus)\n",
        "\n",
        "  result = trainer.train('train_'+str(i)+'/')\n",
        "\n",
        "  print(str(i) + \" - Test score: \" + str(result[\"test_score\"]))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 13333 6667\n",
            "2020-03-08 14:26:50,085 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "100%|██████████| 13333/13333 [00:00<00:00, 236115.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-08 14:26:50,170 [b'4.0', b'2.0', b'3.0', b'10.0', b'6.0', b'5.0', b'1.0', b'9.0', b'8.0', b'7.0']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-08 14:26:58,126 Using REGRESSION - experimental\n",
            "2020-03-08 14:26:58,128 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:26:58,129 Model: \"TextRegressor(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('pubmed.model')\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=200, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (loss_function): MSELoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-03-08 14:26:58,131 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:26:58,132 Corpus: \"Corpus: 13333 train + 6667 dev + 6667 test sentences\"\n",
            "2020-03-08 14:26:58,134 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:26:58,135 Parameters:\n",
            "2020-03-08 14:26:58,136  - learning_rate: \"0.1\"\n",
            "2020-03-08 14:26:58,137  - mini_batch_size: \"32\"\n",
            "2020-03-08 14:26:58,139  - patience: \"3\"\n",
            "2020-03-08 14:26:58,140  - anneal_factor: \"0.5\"\n",
            "2020-03-08 14:26:58,141  - max_epochs: \"100\"\n",
            "2020-03-08 14:26:58,142  - shuffle: \"True\"\n",
            "2020-03-08 14:26:58,143  - train_with_dev: \"False\"\n",
            "2020-03-08 14:26:58,144  - batch_growth_annealing: \"False\"\n",
            "2020-03-08 14:26:58,145 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:26:58,146 Model training base path: \"train_0\"\n",
            "2020-03-08 14:26:58,146 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:26:58,147 Device: cuda:0\n",
            "2020-03-08 14:26:58,148 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:26:58,149 Embeddings storage mode: cpu\n",
            "2020-03-08 14:26:58,150 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:27:17,366 epoch 1 - iter 41/417 - loss 15.85099295 - samples/sec: 68.32\n",
            "2020-03-08 14:27:34,204 epoch 1 - iter 82/417 - loss 14.28150150 - samples/sec: 77.97\n",
            "2020-03-08 14:27:50,721 epoch 1 - iter 123/417 - loss 13.53590219 - samples/sec: 79.50\n",
            "2020-03-08 14:28:07,722 epoch 1 - iter 164/417 - loss 13.03559706 - samples/sec: 77.22\n",
            "2020-03-08 14:28:24,622 epoch 1 - iter 205/417 - loss 12.72541782 - samples/sec: 77.68\n",
            "2020-03-08 14:28:41,580 epoch 1 - iter 246/417 - loss 12.51810060 - samples/sec: 77.42\n",
            "2020-03-08 14:28:58,580 epoch 1 - iter 287/417 - loss 12.39877830 - samples/sec: 77.23\n",
            "2020-03-08 14:29:16,000 epoch 1 - iter 328/417 - loss 12.24828484 - samples/sec: 75.37\n",
            "2020-03-08 14:29:35,818 epoch 1 - iter 369/417 - loss 12.17870648 - samples/sec: 66.24\n",
            "2020-03-08 14:29:52,830 epoch 1 - iter 410/417 - loss 12.08506745 - samples/sec: 77.17\n",
            "2020-03-08 14:29:55,590 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:29:55,592 EPOCH 1 done: loss 12.0674 - lr 0.1000\n",
            "2020-03-08 14:31:07,373 DEV : loss 0.328063040971756 - score 0.20587216858872004\n",
            "2020-03-08 14:31:08,796 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:31:46,073 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:31:55,309 epoch 2 - iter 41/417 - loss 11.22593898 - samples/sec: 142.14\n",
            "2020-03-08 14:32:04,347 epoch 2 - iter 82/417 - loss 10.92059306 - samples/sec: 145.32\n",
            "2020-03-08 14:32:13,477 epoch 2 - iter 123/417 - loss 10.97039193 - samples/sec: 143.88\n",
            "2020-03-08 14:32:22,266 epoch 2 - iter 164/417 - loss 10.96197163 - samples/sec: 149.48\n",
            "2020-03-08 14:32:31,061 epoch 2 - iter 205/417 - loss 10.91316803 - samples/sec: 149.38\n",
            "2020-03-08 14:32:39,592 epoch 2 - iter 246/417 - loss 10.97575213 - samples/sec: 153.96\n",
            "2020-03-08 14:32:48,276 epoch 2 - iter 287/417 - loss 10.90992499 - samples/sec: 151.28\n",
            "2020-03-08 14:32:57,162 epoch 2 - iter 328/417 - loss 10.87007967 - samples/sec: 147.82\n",
            "2020-03-08 14:33:06,383 epoch 2 - iter 369/417 - loss 10.87454493 - samples/sec: 142.46\n",
            "2020-03-08 14:33:15,087 epoch 2 - iter 410/417 - loss 10.86636753 - samples/sec: 150.92\n",
            "2020-03-08 14:33:16,548 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:33:16,549 EPOCH 2 done: loss 10.8549 - lr 0.1000\n",
            "2020-03-08 14:33:45,952 DEV : loss 0.3447433412075043 - score 0.23538687937884084\n",
            "2020-03-08 14:33:47,388 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:34:24,868 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:34:34,344 epoch 3 - iter 41/417 - loss 10.32493574 - samples/sec: 138.56\n",
            "2020-03-08 14:34:43,597 epoch 3 - iter 82/417 - loss 10.63276307 - samples/sec: 141.96\n",
            "2020-03-08 14:34:52,891 epoch 3 - iter 123/417 - loss 10.83572869 - samples/sec: 141.32\n",
            "2020-03-08 14:35:01,965 epoch 3 - iter 164/417 - loss 10.86052250 - samples/sec: 144.77\n",
            "2020-03-08 14:35:11,489 epoch 3 - iter 205/417 - loss 10.78216348 - samples/sec: 137.91\n",
            "2020-03-08 14:35:20,815 epoch 3 - iter 246/417 - loss 10.71320161 - samples/sec: 140.85\n",
            "2020-03-08 14:35:29,862 epoch 3 - iter 287/417 - loss 10.74962951 - samples/sec: 145.20\n",
            "2020-03-08 14:35:38,676 epoch 3 - iter 328/417 - loss 10.78706020 - samples/sec: 149.06\n",
            "2020-03-08 14:35:47,390 epoch 3 - iter 369/417 - loss 10.77111323 - samples/sec: 150.74\n",
            "2020-03-08 14:35:56,342 epoch 3 - iter 410/417 - loss 10.73112659 - samples/sec: 146.73\n",
            "2020-03-08 14:35:57,813 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:35:57,814 EPOCH 3 done: loss 10.7300 - lr 0.1000\n",
            "2020-03-08 14:36:29,223 DEV : loss 0.32938411831855774 - score 0.21968367827510735\n",
            "2020-03-08 14:36:30,654 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 14:36:30,656 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:36:40,271 epoch 4 - iter 41/417 - loss 10.20035294 - samples/sec: 136.51\n",
            "2020-03-08 14:36:52,762 epoch 4 - iter 82/417 - loss 10.53898656 - samples/sec: 105.12\n",
            "2020-03-08 14:37:01,930 epoch 4 - iter 123/417 - loss 10.47979005 - samples/sec: 143.27\n",
            "2020-03-08 14:37:10,656 epoch 4 - iter 164/417 - loss 10.70180258 - samples/sec: 150.54\n",
            "2020-03-08 14:37:19,384 epoch 4 - iter 205/417 - loss 10.68895742 - samples/sec: 150.52\n",
            "2020-03-08 14:37:28,045 epoch 4 - iter 246/417 - loss 10.69581556 - samples/sec: 151.68\n",
            "2020-03-08 14:37:36,401 epoch 4 - iter 287/417 - loss 10.57700025 - samples/sec: 157.23\n",
            "2020-03-08 14:37:45,586 epoch 4 - iter 328/417 - loss 10.60619240 - samples/sec: 143.00\n",
            "2020-03-08 14:37:54,433 epoch 4 - iter 369/417 - loss 10.58959944 - samples/sec: 148.46\n",
            "2020-03-08 14:38:03,307 epoch 4 - iter 410/417 - loss 10.59013247 - samples/sec: 148.02\n",
            "2020-03-08 14:38:04,756 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:38:04,757 EPOCH 4 done: loss 10.5842 - lr 0.1000\n",
            "2020-03-08 14:38:34,751 DEV : loss 0.30566298961639404 - score 0.3570028388553879\n",
            "2020-03-08 14:38:36,173 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:39:13,921 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:39:25,852 epoch 5 - iter 41/417 - loss 10.57821945 - samples/sec: 134.15\n",
            "2020-03-08 14:39:35,414 epoch 5 - iter 82/417 - loss 10.58529834 - samples/sec: 137.37\n",
            "2020-03-08 14:39:44,745 epoch 5 - iter 123/417 - loss 10.45576275 - samples/sec: 140.76\n",
            "2020-03-08 14:39:53,808 epoch 5 - iter 164/417 - loss 10.33232397 - samples/sec: 144.96\n",
            "2020-03-08 14:40:02,961 epoch 5 - iter 205/417 - loss 10.20191127 - samples/sec: 143.54\n",
            "2020-03-08 14:40:12,354 epoch 5 - iter 246/417 - loss 10.11303670 - samples/sec: 139.85\n",
            "2020-03-08 14:40:21,544 epoch 5 - iter 287/417 - loss 10.06162836 - samples/sec: 142.92\n",
            "2020-03-08 14:40:30,522 epoch 5 - iter 328/417 - loss 10.02301510 - samples/sec: 146.32\n",
            "2020-03-08 14:40:39,143 epoch 5 - iter 369/417 - loss 10.00030726 - samples/sec: 152.37\n",
            "2020-03-08 14:40:47,903 epoch 5 - iter 410/417 - loss 9.99185164 - samples/sec: 149.94\n",
            "2020-03-08 14:40:49,348 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:40:49,350 EPOCH 5 done: loss 9.9903 - lr 0.1000\n",
            "2020-03-08 14:41:20,922 DEV : loss 0.2793782651424408 - score 0.48330946138507214\n",
            "2020-03-08 14:41:22,362 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:41:58,169 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:42:07,705 epoch 6 - iter 41/417 - loss 9.86639364 - samples/sec: 137.68\n",
            "2020-03-08 14:42:17,056 epoch 6 - iter 82/417 - loss 9.77580197 - samples/sec: 140.46\n",
            "2020-03-08 14:42:26,408 epoch 6 - iter 123/417 - loss 9.69904518 - samples/sec: 140.45\n",
            "2020-03-08 14:42:35,582 epoch 6 - iter 164/417 - loss 9.61459026 - samples/sec: 143.18\n",
            "2020-03-08 14:42:44,510 epoch 6 - iter 205/417 - loss 9.62679462 - samples/sec: 147.15\n",
            "2020-03-08 14:42:53,089 epoch 6 - iter 246/417 - loss 9.54384029 - samples/sec: 153.12\n",
            "2020-03-08 14:43:01,810 epoch 6 - iter 287/417 - loss 9.48990249 - samples/sec: 150.62\n",
            "2020-03-08 14:43:10,497 epoch 6 - iter 328/417 - loss 9.50311617 - samples/sec: 151.22\n",
            "2020-03-08 14:43:19,997 epoch 6 - iter 369/417 - loss 9.47497656 - samples/sec: 138.26\n",
            "2020-03-08 14:43:29,140 epoch 6 - iter 410/417 - loss 9.47088203 - samples/sec: 143.67\n",
            "2020-03-08 14:43:30,678 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:43:30,679 EPOCH 6 done: loss 9.4672 - lr 0.1000\n",
            "2020-03-08 14:44:01,450 DEV : loss 0.25559037923812866 - score 0.506925053402512\n",
            "2020-03-08 14:44:02,867 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:44:40,955 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:44:53,017 epoch 7 - iter 41/417 - loss 9.06033719 - samples/sec: 135.07\n",
            "2020-03-08 14:45:02,859 epoch 7 - iter 82/417 - loss 9.10332424 - samples/sec: 133.46\n",
            "2020-03-08 14:45:12,126 epoch 7 - iter 123/417 - loss 9.40545169 - samples/sec: 141.75\n",
            "2020-03-08 14:45:21,545 epoch 7 - iter 164/417 - loss 9.35062882 - samples/sec: 139.46\n",
            "2020-03-08 14:45:30,808 epoch 7 - iter 205/417 - loss 9.31063682 - samples/sec: 141.83\n",
            "2020-03-08 14:45:40,214 epoch 7 - iter 246/417 - loss 9.30360658 - samples/sec: 139.65\n",
            "2020-03-08 14:45:49,362 epoch 7 - iter 287/417 - loss 9.29428452 - samples/sec: 143.58\n",
            "2020-03-08 14:45:58,674 epoch 7 - iter 328/417 - loss 9.17946468 - samples/sec: 141.08\n",
            "2020-03-08 14:46:07,937 epoch 7 - iter 369/417 - loss 9.15890045 - samples/sec: 141.81\n",
            "2020-03-08 14:46:17,346 epoch 7 - iter 410/417 - loss 9.17304553 - samples/sec: 139.59\n",
            "2020-03-08 14:46:18,894 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:46:18,895 EPOCH 7 done: loss 9.1624 - lr 0.1000\n",
            "2020-03-08 14:46:49,966 DEV : loss 0.25661638379096985 - score 0.5229511714910507\n",
            "2020-03-08 14:46:51,403 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:47:30,386 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:47:40,522 epoch 8 - iter 41/417 - loss 8.99439002 - samples/sec: 137.62\n",
            "2020-03-08 14:47:49,881 epoch 8 - iter 82/417 - loss 8.91708223 - samples/sec: 140.36\n",
            "2020-03-08 14:47:59,326 epoch 8 - iter 123/417 - loss 8.83100014 - samples/sec: 139.06\n",
            "2020-03-08 14:48:08,035 epoch 8 - iter 164/417 - loss 8.88086895 - samples/sec: 150.84\n",
            "2020-03-08 14:48:16,774 epoch 8 - iter 205/417 - loss 8.87021027 - samples/sec: 150.34\n",
            "2020-03-08 14:48:25,814 epoch 8 - iter 246/417 - loss 8.93061642 - samples/sec: 145.31\n",
            "2020-03-08 14:48:34,907 epoch 8 - iter 287/417 - loss 8.91844062 - samples/sec: 144.48\n",
            "2020-03-08 14:48:43,415 epoch 8 - iter 328/417 - loss 8.93196177 - samples/sec: 154.41\n",
            "2020-03-08 14:48:52,175 epoch 8 - iter 369/417 - loss 8.87837934 - samples/sec: 149.97\n",
            "2020-03-08 14:49:00,936 epoch 8 - iter 410/417 - loss 8.89219880 - samples/sec: 149.92\n",
            "2020-03-08 14:49:02,338 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:49:02,339 EPOCH 8 done: loss 8.8768 - lr 0.1000\n",
            "2020-03-08 14:49:32,985 DEV : loss 0.2823137938976288 - score 0.530328321886534\n",
            "2020-03-08 14:49:34,426 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:50:10,168 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:50:21,005 epoch 9 - iter 41/417 - loss 9.11488483 - samples/sec: 140.33\n",
            "2020-03-08 14:50:30,153 epoch 9 - iter 82/417 - loss 9.01523153 - samples/sec: 143.58\n",
            "2020-03-08 14:50:39,467 epoch 9 - iter 123/417 - loss 8.89016822 - samples/sec: 141.08\n",
            "2020-03-08 14:50:48,585 epoch 9 - iter 164/417 - loss 8.82954189 - samples/sec: 144.07\n",
            "2020-03-08 14:50:57,311 epoch 9 - iter 205/417 - loss 8.84661760 - samples/sec: 150.54\n",
            "2020-03-08 14:51:05,880 epoch 9 - iter 246/417 - loss 8.80769089 - samples/sec: 153.32\n",
            "2020-03-08 14:51:14,833 epoch 9 - iter 287/417 - loss 8.75604559 - samples/sec: 146.76\n",
            "2020-03-08 14:51:23,722 epoch 9 - iter 328/417 - loss 8.74568745 - samples/sec: 147.78\n",
            "2020-03-08 14:51:32,663 epoch 9 - iter 369/417 - loss 8.74500325 - samples/sec: 146.94\n",
            "2020-03-08 14:51:41,511 epoch 9 - iter 410/417 - loss 8.74041250 - samples/sec: 148.49\n",
            "2020-03-08 14:51:42,971 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:51:42,972 EPOCH 9 done: loss 8.7272 - lr 0.1000\n",
            "2020-03-08 14:52:13,795 DEV : loss 0.2350611835718155 - score 0.5623271184169447\n",
            "2020-03-08 14:52:15,229 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:52:49,837 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:53:02,201 epoch 10 - iter 41/417 - loss 8.27048570 - samples/sec: 135.38\n",
            "2020-03-08 14:53:11,637 epoch 10 - iter 82/417 - loss 8.57626486 - samples/sec: 139.20\n",
            "2020-03-08 14:53:20,934 epoch 10 - iter 123/417 - loss 8.53174346 - samples/sec: 141.28\n",
            "2020-03-08 14:53:30,120 epoch 10 - iter 164/417 - loss 8.40323495 - samples/sec: 143.00\n",
            "2020-03-08 14:53:38,816 epoch 10 - iter 205/417 - loss 8.45900177 - samples/sec: 151.06\n",
            "2020-03-08 14:53:47,548 epoch 10 - iter 246/417 - loss 8.49726989 - samples/sec: 150.43\n",
            "2020-03-08 14:53:56,069 epoch 10 - iter 287/417 - loss 8.53440663 - samples/sec: 154.16\n",
            "2020-03-08 14:54:05,289 epoch 10 - iter 328/417 - loss 8.45269431 - samples/sec: 142.48\n",
            "2020-03-08 14:54:14,183 epoch 10 - iter 369/417 - loss 8.43390541 - samples/sec: 147.70\n",
            "2020-03-08 14:54:23,495 epoch 10 - iter 410/417 - loss 8.46604251 - samples/sec: 141.05\n",
            "2020-03-08 14:54:24,876 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:54:24,877 EPOCH 10 done: loss 8.4749 - lr 0.1000\n",
            "2020-03-08 14:54:55,179 DEV : loss 0.2770712673664093 - score 0.56499000264467\n",
            "2020-03-08 14:54:56,606 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:55:31,372 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:55:44,268 epoch 11 - iter 41/417 - loss 7.88856499 - samples/sec: 138.57\n",
            "2020-03-08 14:55:53,648 epoch 11 - iter 82/417 - loss 8.08610657 - samples/sec: 140.04\n",
            "2020-03-08 14:56:02,591 epoch 11 - iter 123/417 - loss 7.99964868 - samples/sec: 146.88\n",
            "2020-03-08 14:56:11,368 epoch 11 - iter 164/417 - loss 8.11929169 - samples/sec: 149.65\n",
            "2020-03-08 14:56:20,237 epoch 11 - iter 205/417 - loss 8.15259824 - samples/sec: 148.10\n",
            "2020-03-08 14:56:28,703 epoch 11 - iter 246/417 - loss 8.13675044 - samples/sec: 155.17\n",
            "2020-03-08 14:56:37,198 epoch 11 - iter 287/417 - loss 8.19110967 - samples/sec: 154.64\n",
            "2020-03-08 14:56:45,801 epoch 11 - iter 328/417 - loss 8.21776763 - samples/sec: 152.68\n",
            "2020-03-08 14:56:54,265 epoch 11 - iter 369/417 - loss 8.27429572 - samples/sec: 155.21\n",
            "2020-03-08 14:57:02,878 epoch 11 - iter 410/417 - loss 8.24963186 - samples/sec: 152.51\n",
            "2020-03-08 14:57:04,422 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:57:04,424 EPOCH 11 done: loss 8.2431 - lr 0.1000\n",
            "2020-03-08 14:57:37,229 DEV : loss 0.28755983710289 - score 0.5821503364062024\n",
            "2020-03-08 14:57:38,643 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:58:14,945 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:58:25,265 epoch 12 - iter 41/417 - loss 8.35931329 - samples/sec: 136.46\n",
            "2020-03-08 14:58:34,468 epoch 12 - iter 82/417 - loss 8.03419279 - samples/sec: 142.73\n",
            "2020-03-08 14:58:43,826 epoch 12 - iter 123/417 - loss 8.12341347 - samples/sec: 140.34\n",
            "2020-03-08 14:58:52,817 epoch 12 - iter 164/417 - loss 8.12843976 - samples/sec: 146.13\n",
            "2020-03-08 14:59:01,713 epoch 12 - iter 205/417 - loss 8.15601262 - samples/sec: 147.67\n",
            "2020-03-08 14:59:10,158 epoch 12 - iter 246/417 - loss 8.13306930 - samples/sec: 155.55\n",
            "2020-03-08 14:59:18,749 epoch 12 - iter 287/417 - loss 8.09290315 - samples/sec: 152.93\n",
            "2020-03-08 14:59:27,208 epoch 12 - iter 328/417 - loss 8.15210770 - samples/sec: 155.29\n",
            "2020-03-08 14:59:36,025 epoch 12 - iter 369/417 - loss 8.12185372 - samples/sec: 148.98\n",
            "2020-03-08 14:59:44,651 epoch 12 - iter 410/417 - loss 8.09741656 - samples/sec: 152.31\n",
            "2020-03-08 14:59:46,063 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:59:46,064 EPOCH 12 done: loss 8.1055 - lr 0.1000\n",
            "2020-03-08 15:00:15,430 DEV : loss 0.21259014308452606 - score 0.6109342366647017\n",
            "2020-03-08 15:00:16,847 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:00:53,213 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:01:04,176 epoch 13 - iter 41/417 - loss 7.93031850 - samples/sec: 136.64\n",
            "2020-03-08 15:01:13,335 epoch 13 - iter 82/417 - loss 7.60475694 - samples/sec: 143.42\n",
            "2020-03-08 15:01:22,311 epoch 13 - iter 123/417 - loss 7.73882030 - samples/sec: 146.36\n",
            "2020-03-08 15:01:31,239 epoch 13 - iter 164/417 - loss 7.80598293 - samples/sec: 147.13\n",
            "2020-03-08 15:01:40,076 epoch 13 - iter 205/417 - loss 7.77722228 - samples/sec: 148.64\n",
            "2020-03-08 15:01:49,030 epoch 13 - iter 246/417 - loss 7.85872521 - samples/sec: 146.73\n",
            "2020-03-08 15:01:58,539 epoch 13 - iter 287/417 - loss 7.85588202 - samples/sec: 138.14\n",
            "2020-03-08 15:02:07,901 epoch 13 - iter 328/417 - loss 7.82669022 - samples/sec: 140.30\n",
            "2020-03-08 15:02:16,467 epoch 13 - iter 369/417 - loss 7.93711735 - samples/sec: 153.37\n",
            "2020-03-08 15:02:25,168 epoch 13 - iter 410/417 - loss 7.92660189 - samples/sec: 150.97\n",
            "2020-03-08 15:02:26,632 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:02:26,633 EPOCH 13 done: loss 7.9396 - lr 0.1000\n",
            "2020-03-08 15:02:58,066 DEV : loss 0.2231082171201706 - score 0.6131768322812566\n",
            "2020-03-08 15:02:59,487 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:03:38,870 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:03:49,592 epoch 14 - iter 41/417 - loss 7.81655222 - samples/sec: 133.64\n",
            "2020-03-08 15:03:59,090 epoch 14 - iter 82/417 - loss 8.04134200 - samples/sec: 138.30\n",
            "2020-03-08 15:04:08,429 epoch 14 - iter 123/417 - loss 7.76965853 - samples/sec: 140.67\n",
            "2020-03-08 15:04:17,569 epoch 14 - iter 164/417 - loss 7.73280983 - samples/sec: 143.71\n",
            "2020-03-08 15:04:27,128 epoch 14 - iter 205/417 - loss 7.75999793 - samples/sec: 137.44\n",
            "2020-03-08 15:04:36,288 epoch 14 - iter 246/417 - loss 7.75707588 - samples/sec: 143.40\n",
            "2020-03-08 15:04:45,315 epoch 14 - iter 287/417 - loss 7.70218700 - samples/sec: 145.51\n",
            "2020-03-08 15:04:54,309 epoch 14 - iter 328/417 - loss 7.67566150 - samples/sec: 146.06\n",
            "2020-03-08 15:05:03,063 epoch 14 - iter 369/417 - loss 7.74221733 - samples/sec: 150.07\n",
            "2020-03-08 15:05:12,050 epoch 14 - iter 410/417 - loss 7.75069987 - samples/sec: 146.17\n",
            "2020-03-08 15:05:13,567 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:05:13,568 EPOCH 14 done: loss 7.7685 - lr 0.1000\n",
            "2020-03-08 15:05:45,355 DEV : loss 0.23835048079490662 - score 0.6132406847230542\n",
            "2020-03-08 15:05:46,772 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:06:25,961 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:06:36,550 epoch 15 - iter 41/417 - loss 7.20111624 - samples/sec: 138.12\n",
            "2020-03-08 15:06:45,986 epoch 15 - iter 82/417 - loss 7.32018892 - samples/sec: 139.23\n",
            "2020-03-08 15:06:55,164 epoch 15 - iter 123/417 - loss 7.45556752 - samples/sec: 143.13\n",
            "2020-03-08 15:07:04,188 epoch 15 - iter 164/417 - loss 7.58069109 - samples/sec: 145.56\n",
            "2020-03-08 15:07:13,555 epoch 15 - iter 205/417 - loss 7.66530250 - samples/sec: 140.25\n",
            "2020-03-08 15:07:22,329 epoch 15 - iter 246/417 - loss 7.58400637 - samples/sec: 149.73\n",
            "2020-03-08 15:07:31,143 epoch 15 - iter 287/417 - loss 7.65735750 - samples/sec: 149.01\n",
            "2020-03-08 15:07:39,863 epoch 15 - iter 328/417 - loss 7.59413733 - samples/sec: 150.64\n",
            "2020-03-08 15:07:48,341 epoch 15 - iter 369/417 - loss 7.59365128 - samples/sec: 154.98\n",
            "2020-03-08 15:07:57,125 epoch 15 - iter 410/417 - loss 7.62685143 - samples/sec: 149.51\n",
            "2020-03-08 15:07:58,548 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:07:58,549 EPOCH 15 done: loss 7.6225 - lr 0.1000\n",
            "2020-03-08 15:08:29,092 DEV : loss 0.21864977478981018 - score 0.6276081286825873\n",
            "2020-03-08 15:08:30,536 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:09:06,720 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:09:18,620 epoch 16 - iter 41/417 - loss 7.50308652 - samples/sec: 134.71\n",
            "2020-03-08 15:09:28,022 epoch 16 - iter 82/417 - loss 7.34522493 - samples/sec: 139.70\n",
            "2020-03-08 15:09:37,250 epoch 16 - iter 123/417 - loss 7.33274485 - samples/sec: 142.37\n",
            "2020-03-08 15:09:46,352 epoch 16 - iter 164/417 - loss 7.34739773 - samples/sec: 144.31\n",
            "2020-03-08 15:09:55,358 epoch 16 - iter 205/417 - loss 7.34092269 - samples/sec: 145.86\n",
            "2020-03-08 15:10:04,426 epoch 16 - iter 246/417 - loss 7.30992406 - samples/sec: 144.86\n",
            "2020-03-08 15:10:13,297 epoch 16 - iter 287/417 - loss 7.35141840 - samples/sec: 148.09\n",
            "2020-03-08 15:10:22,185 epoch 16 - iter 328/417 - loss 7.39161023 - samples/sec: 147.80\n",
            "2020-03-08 15:10:30,984 epoch 16 - iter 369/417 - loss 7.37339004 - samples/sec: 149.28\n",
            "2020-03-08 15:10:39,929 epoch 16 - iter 410/417 - loss 7.39344578 - samples/sec: 146.84\n",
            "2020-03-08 15:10:41,401 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:10:41,402 EPOCH 16 done: loss 7.3840 - lr 0.1000\n",
            "2020-03-08 15:11:13,477 DEV : loss 0.202858567237854 - score 0.6395644977174095\n",
            "2020-03-08 15:11:14,924 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:11:53,459 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:12:04,470 epoch 17 - iter 41/417 - loss 7.70451163 - samples/sec: 135.87\n",
            "2020-03-08 15:12:14,043 epoch 17 - iter 82/417 - loss 7.36623778 - samples/sec: 137.23\n",
            "2020-03-08 15:12:23,437 epoch 17 - iter 123/417 - loss 7.32477668 - samples/sec: 139.81\n",
            "2020-03-08 15:12:32,373 epoch 17 - iter 164/417 - loss 7.33468185 - samples/sec: 147.02\n",
            "2020-03-08 15:12:41,138 epoch 17 - iter 205/417 - loss 7.43690282 - samples/sec: 149.87\n",
            "2020-03-08 15:12:49,766 epoch 17 - iter 246/417 - loss 7.36980203 - samples/sec: 152.26\n",
            "2020-03-08 15:12:58,532 epoch 17 - iter 287/417 - loss 7.34251861 - samples/sec: 149.86\n",
            "2020-03-08 15:13:07,813 epoch 17 - iter 328/417 - loss 7.36934910 - samples/sec: 141.54\n",
            "2020-03-08 15:13:17,207 epoch 17 - iter 369/417 - loss 7.40094146 - samples/sec: 139.83\n",
            "2020-03-08 15:13:26,533 epoch 17 - iter 410/417 - loss 7.36586003 - samples/sec: 140.86\n",
            "2020-03-08 15:13:28,103 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:13:28,104 EPOCH 17 done: loss 7.3630 - lr 0.1000\n",
            "2020-03-08 15:13:59,392 DEV : loss 0.20103666186332703 - score 0.6364094659703885\n",
            "2020-03-08 15:14:00,820 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:14:00,822 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:14:10,410 epoch 18 - iter 41/417 - loss 7.24759462 - samples/sec: 136.89\n",
            "2020-03-08 15:14:19,483 epoch 18 - iter 82/417 - loss 7.13064861 - samples/sec: 144.80\n",
            "2020-03-08 15:14:28,369 epoch 18 - iter 123/417 - loss 7.13019841 - samples/sec: 147.82\n",
            "2020-03-08 15:14:37,869 epoch 18 - iter 164/417 - loss 7.19367381 - samples/sec: 138.27\n",
            "2020-03-08 15:14:47,254 epoch 18 - iter 205/417 - loss 7.23194016 - samples/sec: 139.98\n",
            "2020-03-08 15:14:55,728 epoch 18 - iter 246/417 - loss 7.09422565 - samples/sec: 155.04\n",
            "2020-03-08 15:15:04,360 epoch 18 - iter 287/417 - loss 7.19311102 - samples/sec: 152.20\n",
            "2020-03-08 15:15:12,997 epoch 18 - iter 328/417 - loss 7.21019882 - samples/sec: 152.11\n",
            "2020-03-08 15:15:22,058 epoch 18 - iter 369/417 - loss 7.24044116 - samples/sec: 144.98\n",
            "2020-03-08 15:15:31,105 epoch 18 - iter 410/417 - loss 7.26569369 - samples/sec: 145.20\n",
            "2020-03-08 15:15:32,543 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:15:32,544 EPOCH 18 done: loss 7.2636 - lr 0.1000\n",
            "2020-03-08 15:16:01,946 DEV : loss 0.21368487179279327 - score 0.6454069684861129\n",
            "2020-03-08 15:16:03,374 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:16:40,014 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:16:50,476 epoch 19 - iter 41/417 - loss 7.41114092 - samples/sec: 133.99\n",
            "2020-03-08 15:17:00,147 epoch 19 - iter 82/417 - loss 7.13429854 - samples/sec: 135.81\n",
            "2020-03-08 15:17:09,626 epoch 19 - iter 123/417 - loss 7.09256342 - samples/sec: 138.58\n",
            "2020-03-08 15:17:19,066 epoch 19 - iter 164/417 - loss 7.22662460 - samples/sec: 139.16\n",
            "2020-03-08 15:17:28,292 epoch 19 - iter 205/417 - loss 7.30338381 - samples/sec: 142.39\n",
            "2020-03-08 15:17:37,398 epoch 19 - iter 246/417 - loss 7.26705313 - samples/sec: 144.26\n",
            "2020-03-08 15:17:46,457 epoch 19 - iter 287/417 - loss 7.19831061 - samples/sec: 145.02\n",
            "2020-03-08 15:17:58,483 epoch 19 - iter 328/417 - loss 7.19938245 - samples/sec: 109.20\n",
            "2020-03-08 15:18:08,255 epoch 19 - iter 369/417 - loss 7.17320662 - samples/sec: 134.40\n",
            "2020-03-08 15:18:17,189 epoch 19 - iter 410/417 - loss 7.21668058 - samples/sec: 147.04\n",
            "2020-03-08 15:18:18,675 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:18:18,676 EPOCH 19 done: loss 7.2018 - lr 0.1000\n",
            "2020-03-08 15:18:49,276 DEV : loss 0.2067965865135193 - score 0.6483699223476824\n",
            "2020-03-08 15:18:50,727 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:19:26,496 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:19:36,735 epoch 20 - iter 41/417 - loss 7.52659855 - samples/sec: 138.49\n",
            "2020-03-08 15:19:45,974 epoch 20 - iter 82/417 - loss 7.41184072 - samples/sec: 142.21\n",
            "2020-03-08 15:19:55,364 epoch 20 - iter 123/417 - loss 7.30513112 - samples/sec: 139.88\n",
            "2020-03-08 15:20:04,167 epoch 20 - iter 164/417 - loss 7.32039554 - samples/sec: 149.24\n",
            "2020-03-08 15:20:13,053 epoch 20 - iter 205/417 - loss 7.23986380 - samples/sec: 147.84\n",
            "2020-03-08 15:20:21,908 epoch 20 - iter 246/417 - loss 7.15829038 - samples/sec: 148.35\n",
            "2020-03-08 15:20:30,924 epoch 20 - iter 287/417 - loss 7.09984081 - samples/sec: 145.71\n",
            "2020-03-08 15:20:40,020 epoch 20 - iter 328/417 - loss 7.10110366 - samples/sec: 144.42\n",
            "2020-03-08 15:20:49,069 epoch 20 - iter 369/417 - loss 7.06618930 - samples/sec: 145.15\n",
            "2020-03-08 15:20:58,294 epoch 20 - iter 410/417 - loss 7.04047330 - samples/sec: 142.38\n",
            "2020-03-08 15:20:59,820 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:20:59,821 EPOCH 20 done: loss 7.0402 - lr 0.1000\n",
            "2020-03-08 15:21:31,666 DEV : loss 0.19468142092227936 - score 0.64876411284756\n",
            "2020-03-08 15:21:33,100 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:22:12,027 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:22:22,088 epoch 21 - iter 41/417 - loss 6.68082755 - samples/sec: 141.79\n",
            "2020-03-08 15:22:31,159 epoch 21 - iter 82/417 - loss 6.65834878 - samples/sec: 144.81\n",
            "2020-03-08 15:22:39,934 epoch 21 - iter 123/417 - loss 6.87651068 - samples/sec: 149.73\n",
            "2020-03-08 15:22:48,665 epoch 21 - iter 164/417 - loss 6.75642086 - samples/sec: 150.44\n",
            "2020-03-08 15:22:57,531 epoch 21 - iter 205/417 - loss 6.68328593 - samples/sec: 148.16\n",
            "2020-03-08 15:23:06,189 epoch 21 - iter 246/417 - loss 6.74423026 - samples/sec: 151.71\n",
            "2020-03-08 15:23:14,863 epoch 21 - iter 287/417 - loss 6.83266233 - samples/sec: 151.45\n",
            "2020-03-08 15:23:23,927 epoch 21 - iter 328/417 - loss 6.77951779 - samples/sec: 144.93\n",
            "2020-03-08 15:23:33,226 epoch 21 - iter 369/417 - loss 6.78162063 - samples/sec: 141.27\n",
            "2020-03-08 15:23:42,577 epoch 21 - iter 410/417 - loss 6.78216283 - samples/sec: 140.47\n",
            "2020-03-08 15:23:44,194 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:23:44,195 EPOCH 21 done: loss 6.7848 - lr 0.1000\n",
            "2020-03-08 15:24:14,478 DEV : loss 0.22201885282993317 - score 0.6520019903468118\n",
            "2020-03-08 15:24:15,919 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:24:54,428 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:25:06,308 epoch 22 - iter 41/417 - loss 6.74781653 - samples/sec: 133.39\n",
            "2020-03-08 15:25:15,440 epoch 22 - iter 82/417 - loss 6.67991469 - samples/sec: 143.83\n",
            "2020-03-08 15:25:24,696 epoch 22 - iter 123/417 - loss 6.63232603 - samples/sec: 141.91\n",
            "2020-03-08 15:25:33,677 epoch 22 - iter 164/417 - loss 6.66111377 - samples/sec: 146.25\n",
            "2020-03-08 15:25:42,330 epoch 22 - iter 205/417 - loss 6.63150602 - samples/sec: 151.80\n",
            "2020-03-08 15:25:51,152 epoch 22 - iter 246/417 - loss 6.64424115 - samples/sec: 148.89\n",
            "2020-03-08 15:25:59,937 epoch 22 - iter 287/417 - loss 6.68918286 - samples/sec: 149.55\n",
            "2020-03-08 15:26:08,791 epoch 22 - iter 328/417 - loss 6.72363840 - samples/sec: 148.37\n",
            "2020-03-08 15:26:18,046 epoch 22 - iter 369/417 - loss 6.78094309 - samples/sec: 141.94\n",
            "2020-03-08 15:26:27,050 epoch 22 - iter 410/417 - loss 6.84148186 - samples/sec: 145.89\n",
            "2020-03-08 15:26:28,504 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:26:28,506 EPOCH 22 done: loss 6.8474 - lr 0.1000\n",
            "2020-03-08 15:26:58,695 DEV : loss 0.2050040364265442 - score 0.669134932246849\n",
            "2020-03-08 15:27:00,178 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:27:39,309 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:27:49,650 epoch 23 - iter 41/417 - loss 7.43865361 - samples/sec: 136.09\n",
            "2020-03-08 15:27:59,086 epoch 23 - iter 82/417 - loss 6.95463775 - samples/sec: 139.22\n",
            "2020-03-08 15:28:08,266 epoch 23 - iter 123/417 - loss 6.93550020 - samples/sec: 143.11\n",
            "2020-03-08 15:28:17,240 epoch 23 - iter 164/417 - loss 6.83958130 - samples/sec: 146.39\n",
            "2020-03-08 15:28:26,569 epoch 23 - iter 205/417 - loss 6.87743109 - samples/sec: 140.81\n",
            "2020-03-08 15:28:35,915 epoch 23 - iter 246/417 - loss 6.86754357 - samples/sec: 140.55\n",
            "2020-03-08 15:28:44,954 epoch 23 - iter 287/417 - loss 6.78154580 - samples/sec: 145.34\n",
            "2020-03-08 15:28:54,080 epoch 23 - iter 328/417 - loss 6.77990380 - samples/sec: 143.93\n",
            "2020-03-08 15:29:02,639 epoch 23 - iter 369/417 - loss 6.74134717 - samples/sec: 153.48\n",
            "2020-03-08 15:29:11,375 epoch 23 - iter 410/417 - loss 6.68597450 - samples/sec: 150.42\n",
            "2020-03-08 15:29:12,883 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:29:12,884 EPOCH 23 done: loss 6.6837 - lr 0.1000\n",
            "2020-03-08 15:29:44,342 DEV : loss 0.19315437972545624 - score 0.6633673097506432\n",
            "2020-03-08 15:29:45,781 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:29:45,782 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:29:55,166 epoch 24 - iter 41/417 - loss 6.81695047 - samples/sec: 139.89\n",
            "2020-03-08 15:30:03,985 epoch 24 - iter 82/417 - loss 6.68616555 - samples/sec: 148.96\n",
            "2020-03-08 15:30:13,427 epoch 24 - iter 123/417 - loss 6.70117413 - samples/sec: 139.13\n",
            "2020-03-08 15:30:21,894 epoch 24 - iter 164/417 - loss 6.70795918 - samples/sec: 155.15\n",
            "2020-03-08 15:30:30,587 epoch 24 - iter 205/417 - loss 6.68880298 - samples/sec: 151.11\n",
            "2020-03-08 15:30:39,337 epoch 24 - iter 246/417 - loss 6.65529348 - samples/sec: 150.12\n",
            "2020-03-08 15:30:47,940 epoch 24 - iter 287/417 - loss 6.65769689 - samples/sec: 152.69\n",
            "2020-03-08 15:30:56,871 epoch 24 - iter 328/417 - loss 6.67728760 - samples/sec: 147.08\n",
            "2020-03-08 15:31:05,992 epoch 24 - iter 369/417 - loss 6.69270761 - samples/sec: 144.00\n",
            "2020-03-08 15:31:14,831 epoch 24 - iter 410/417 - loss 6.65235875 - samples/sec: 148.61\n",
            "2020-03-08 15:31:16,318 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:31:16,319 EPOCH 24 done: loss 6.6605 - lr 0.1000\n",
            "2020-03-08 15:31:45,818 DEV : loss 0.19626259803771973 - score 0.6612074375897333\n",
            "2020-03-08 15:31:47,237 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 15:31:47,239 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:31:56,699 epoch 25 - iter 41/417 - loss 6.79366842 - samples/sec: 138.75\n",
            "2020-03-08 15:32:05,855 epoch 25 - iter 82/417 - loss 6.71466492 - samples/sec: 143.47\n",
            "2020-03-08 15:32:14,792 epoch 25 - iter 123/417 - loss 6.76497369 - samples/sec: 146.97\n",
            "2020-03-08 15:32:23,505 epoch 25 - iter 164/417 - loss 6.73836078 - samples/sec: 150.78\n",
            "2020-03-08 15:32:32,213 epoch 25 - iter 205/417 - loss 6.66472056 - samples/sec: 150.86\n",
            "2020-03-08 15:32:41,084 epoch 25 - iter 246/417 - loss 6.67009105 - samples/sec: 148.09\n",
            "2020-03-08 15:32:50,331 epoch 25 - iter 287/417 - loss 6.73206669 - samples/sec: 142.05\n",
            "2020-03-08 15:32:59,434 epoch 25 - iter 328/417 - loss 6.67280464 - samples/sec: 144.29\n",
            "2020-03-08 15:33:08,198 epoch 25 - iter 369/417 - loss 6.62623923 - samples/sec: 149.87\n",
            "2020-03-08 15:33:17,152 epoch 25 - iter 410/417 - loss 6.58919730 - samples/sec: 146.70\n",
            "2020-03-08 15:33:18,781 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:33:18,782 EPOCH 25 done: loss 6.5813 - lr 0.1000\n",
            "2020-03-08 15:33:47,849 DEV : loss 0.2170187532901764 - score 0.6501799062345385\n",
            "2020-03-08 15:33:49,263 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 15:33:49,264 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:33:57,857 epoch 26 - iter 41/417 - loss 6.93013603 - samples/sec: 152.76\n",
            "2020-03-08 15:34:06,776 epoch 26 - iter 82/417 - loss 6.63035019 - samples/sec: 147.29\n",
            "2020-03-08 15:34:15,916 epoch 26 - iter 123/417 - loss 6.60239572 - samples/sec: 143.73\n",
            "2020-03-08 15:34:25,045 epoch 26 - iter 164/417 - loss 6.63997092 - samples/sec: 143.88\n",
            "2020-03-08 15:34:33,937 epoch 26 - iter 205/417 - loss 6.55209508 - samples/sec: 147.74\n",
            "2020-03-08 15:34:42,711 epoch 26 - iter 246/417 - loss 6.52985798 - samples/sec: 149.72\n",
            "2020-03-08 15:34:51,604 epoch 26 - iter 287/417 - loss 6.49322386 - samples/sec: 147.74\n",
            "2020-03-08 15:35:00,654 epoch 26 - iter 328/417 - loss 6.50373678 - samples/sec: 145.15\n",
            "2020-03-08 15:35:09,759 epoch 26 - iter 369/417 - loss 6.49672268 - samples/sec: 144.27\n",
            "2020-03-08 15:35:18,919 epoch 26 - iter 410/417 - loss 6.47871470 - samples/sec: 143.40\n",
            "2020-03-08 15:35:20,405 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:35:20,406 EPOCH 26 done: loss 6.4666 - lr 0.1000\n",
            "2020-03-08 15:35:50,788 DEV : loss 0.19441230595111847 - score 0.6702568556469206\n",
            "2020-03-08 15:35:52,214 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:36:27,489 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:36:38,563 epoch 27 - iter 41/417 - loss 5.94287815 - samples/sec: 135.44\n",
            "2020-03-08 15:36:48,098 epoch 27 - iter 82/417 - loss 6.03587410 - samples/sec: 137.77\n",
            "2020-03-08 15:37:00,746 epoch 27 - iter 123/417 - loss 6.07033122 - samples/sec: 103.83\n",
            "2020-03-08 15:37:10,230 epoch 27 - iter 164/417 - loss 6.10584172 - samples/sec: 138.50\n",
            "2020-03-08 15:37:19,206 epoch 27 - iter 205/417 - loss 6.14106158 - samples/sec: 146.37\n",
            "2020-03-08 15:37:28,081 epoch 27 - iter 246/417 - loss 6.18752950 - samples/sec: 148.03\n",
            "2020-03-08 15:37:36,757 epoch 27 - iter 287/417 - loss 6.26508390 - samples/sec: 151.40\n",
            "2020-03-08 15:37:45,610 epoch 27 - iter 328/417 - loss 6.27256775 - samples/sec: 148.38\n",
            "2020-03-08 15:37:54,429 epoch 27 - iter 369/417 - loss 6.34059503 - samples/sec: 148.95\n",
            "2020-03-08 15:38:03,066 epoch 27 - iter 410/417 - loss 6.39473943 - samples/sec: 152.11\n",
            "2020-03-08 15:38:04,668 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:38:04,669 EPOCH 27 done: loss 6.3978 - lr 0.1000\n",
            "2020-03-08 15:38:33,987 DEV : loss 0.19301897287368774 - score 0.6745577466990644\n",
            "2020-03-08 15:38:35,402 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:39:11,018 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:39:21,649 epoch 28 - iter 41/417 - loss 5.88989483 - samples/sec: 135.77\n",
            "2020-03-08 15:39:30,960 epoch 28 - iter 82/417 - loss 5.97478080 - samples/sec: 141.07\n",
            "2020-03-08 15:39:40,239 epoch 28 - iter 123/417 - loss 6.10346553 - samples/sec: 141.58\n",
            "2020-03-08 15:39:49,690 epoch 28 - iter 164/417 - loss 6.10574784 - samples/sec: 138.99\n",
            "2020-03-08 15:39:58,923 epoch 28 - iter 205/417 - loss 6.09363387 - samples/sec: 142.28\n",
            "2020-03-08 15:40:07,721 epoch 28 - iter 246/417 - loss 6.12274146 - samples/sec: 149.33\n",
            "2020-03-08 15:40:16,392 epoch 28 - iter 287/417 - loss 6.17836574 - samples/sec: 151.49\n",
            "2020-03-08 15:40:25,495 epoch 28 - iter 328/417 - loss 6.25010053 - samples/sec: 144.32\n",
            "2020-03-08 15:40:34,796 epoch 28 - iter 369/417 - loss 6.26012740 - samples/sec: 141.21\n",
            "2020-03-08 15:40:43,929 epoch 28 - iter 410/417 - loss 6.26773997 - samples/sec: 143.86\n",
            "2020-03-08 15:40:45,474 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:40:45,475 EPOCH 28 done: loss 6.3038 - lr 0.1000\n",
            "2020-03-08 15:41:16,115 DEV : loss 0.20340611040592194 - score 0.6731938407553086\n",
            "2020-03-08 15:41:17,556 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:41:17,558 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:41:27,063 epoch 29 - iter 41/417 - loss 5.95845724 - samples/sec: 138.09\n",
            "2020-03-08 15:41:36,278 epoch 29 - iter 82/417 - loss 5.99924959 - samples/sec: 142.56\n",
            "2020-03-08 15:41:45,366 epoch 29 - iter 123/417 - loss 6.02933639 - samples/sec: 144.53\n",
            "2020-03-08 15:41:54,658 epoch 29 - iter 164/417 - loss 5.99196665 - samples/sec: 141.37\n",
            "2020-03-08 15:42:03,971 epoch 29 - iter 205/417 - loss 6.19125031 - samples/sec: 141.05\n",
            "2020-03-08 15:42:13,284 epoch 29 - iter 246/417 - loss 6.21215234 - samples/sec: 141.06\n",
            "2020-03-08 15:42:22,447 epoch 29 - iter 287/417 - loss 6.20513550 - samples/sec: 143.37\n",
            "2020-03-08 15:42:31,646 epoch 29 - iter 328/417 - loss 6.22525525 - samples/sec: 142.80\n",
            "2020-03-08 15:42:40,884 epoch 29 - iter 369/417 - loss 6.24479224 - samples/sec: 142.21\n",
            "2020-03-08 15:42:49,655 epoch 29 - iter 410/417 - loss 6.23070184 - samples/sec: 149.78\n",
            "2020-03-08 15:42:51,262 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:42:51,263 EPOCH 29 done: loss 6.2104 - lr 0.1000\n",
            "2020-03-08 15:43:22,171 DEV : loss 0.19332557916641235 - score 0.670969503554703\n",
            "2020-03-08 15:43:23,595 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 15:43:23,596 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:43:33,117 epoch 30 - iter 41/417 - loss 5.55957304 - samples/sec: 137.89\n",
            "2020-03-08 15:43:42,337 epoch 30 - iter 82/417 - loss 5.84213636 - samples/sec: 142.46\n",
            "2020-03-08 15:43:51,706 epoch 30 - iter 123/417 - loss 6.08036898 - samples/sec: 140.20\n",
            "2020-03-08 15:44:01,025 epoch 30 - iter 164/417 - loss 6.14921810 - samples/sec: 140.94\n",
            "2020-03-08 15:44:10,290 epoch 30 - iter 205/417 - loss 6.17834036 - samples/sec: 141.80\n",
            "2020-03-08 15:44:19,519 epoch 30 - iter 246/417 - loss 6.18846645 - samples/sec: 142.34\n",
            "2020-03-08 15:44:28,510 epoch 30 - iter 287/417 - loss 6.18492066 - samples/sec: 146.12\n",
            "2020-03-08 15:44:37,711 epoch 30 - iter 328/417 - loss 6.21884813 - samples/sec: 142.78\n",
            "2020-03-08 15:44:46,948 epoch 30 - iter 369/417 - loss 6.15947185 - samples/sec: 142.21\n",
            "2020-03-08 15:44:56,212 epoch 30 - iter 410/417 - loss 6.15278198 - samples/sec: 141.78\n",
            "2020-03-08 15:44:57,724 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:44:57,726 EPOCH 30 done: loss 6.1572 - lr 0.1000\n",
            "2020-03-08 15:45:30,071 DEV : loss 0.18461115658283234 - score 0.6817979777815666\n",
            "2020-03-08 15:45:31,482 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:46:07,290 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:46:18,067 epoch 31 - iter 41/417 - loss 5.65836396 - samples/sec: 136.37\n",
            "2020-03-08 15:46:27,605 epoch 31 - iter 82/417 - loss 5.94586897 - samples/sec: 137.75\n",
            "2020-03-08 15:46:37,087 epoch 31 - iter 123/417 - loss 6.12311340 - samples/sec: 138.56\n",
            "2020-03-08 15:46:46,182 epoch 31 - iter 164/417 - loss 6.09521336 - samples/sec: 144.45\n",
            "2020-03-08 15:46:55,055 epoch 31 - iter 205/417 - loss 6.12626461 - samples/sec: 148.04\n",
            "2020-03-08 15:47:03,805 epoch 31 - iter 246/417 - loss 6.07697920 - samples/sec: 150.14\n",
            "2020-03-08 15:47:12,932 epoch 31 - iter 287/417 - loss 6.10877409 - samples/sec: 143.90\n",
            "2020-03-08 15:47:21,933 epoch 31 - iter 328/417 - loss 6.08400653 - samples/sec: 145.96\n",
            "2020-03-08 15:47:30,824 epoch 31 - iter 369/417 - loss 6.07810112 - samples/sec: 147.74\n",
            "2020-03-08 15:47:39,691 epoch 31 - iter 410/417 - loss 6.08514179 - samples/sec: 148.16\n",
            "2020-03-08 15:47:41,150 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:47:41,152 EPOCH 31 done: loss 6.0912 - lr 0.1000\n",
            "2020-03-08 15:48:12,584 DEV : loss 0.1954067498445511 - score 0.6712845828993369\n",
            "2020-03-08 15:48:14,031 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:48:14,032 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:48:23,714 epoch 32 - iter 41/417 - loss 6.15118701 - samples/sec: 135.57\n",
            "2020-03-08 15:48:33,249 epoch 32 - iter 82/417 - loss 5.93533915 - samples/sec: 137.78\n",
            "2020-03-08 15:48:42,357 epoch 32 - iter 123/417 - loss 5.99441031 - samples/sec: 144.24\n",
            "2020-03-08 15:48:51,351 epoch 32 - iter 164/417 - loss 5.95520171 - samples/sec: 146.04\n",
            "2020-03-08 15:48:59,878 epoch 32 - iter 205/417 - loss 6.03482869 - samples/sec: 154.06\n",
            "2020-03-08 15:49:08,548 epoch 32 - iter 246/417 - loss 5.96828211 - samples/sec: 151.52\n",
            "2020-03-08 15:49:17,140 epoch 32 - iter 287/417 - loss 5.97568533 - samples/sec: 152.91\n",
            "2020-03-08 15:49:25,940 epoch 32 - iter 328/417 - loss 6.02728534 - samples/sec: 149.29\n",
            "2020-03-08 15:49:34,596 epoch 32 - iter 369/417 - loss 6.05399567 - samples/sec: 151.77\n",
            "2020-03-08 15:49:43,290 epoch 32 - iter 410/417 - loss 6.06577560 - samples/sec: 151.09\n",
            "2020-03-08 15:49:44,657 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:49:44,658 EPOCH 32 done: loss 6.0697 - lr 0.1000\n",
            "2020-03-08 15:50:14,386 DEV : loss 0.19952204823493958 - score 0.6771932644952606\n",
            "2020-03-08 15:50:15,801 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 15:50:15,803 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:50:25,474 epoch 33 - iter 41/417 - loss 6.07063220 - samples/sec: 135.71\n",
            "2020-03-08 15:50:34,318 epoch 33 - iter 82/417 - loss 5.88035395 - samples/sec: 148.53\n",
            "2020-03-08 15:50:43,369 epoch 33 - iter 123/417 - loss 5.92778572 - samples/sec: 145.13\n",
            "2020-03-08 15:50:52,285 epoch 33 - iter 164/417 - loss 5.95393022 - samples/sec: 147.35\n",
            "2020-03-08 15:51:01,528 epoch 33 - iter 205/417 - loss 5.91269233 - samples/sec: 142.10\n",
            "2020-03-08 15:51:10,416 epoch 33 - iter 246/417 - loss 5.97239667 - samples/sec: 147.79\n",
            "2020-03-08 15:51:19,131 epoch 33 - iter 287/417 - loss 5.93387664 - samples/sec: 150.72\n",
            "2020-03-08 15:51:27,793 epoch 33 - iter 328/417 - loss 5.93496500 - samples/sec: 151.66\n",
            "2020-03-08 15:51:36,589 epoch 33 - iter 369/417 - loss 5.93269514 - samples/sec: 149.32\n",
            "2020-03-08 15:51:45,564 epoch 33 - iter 410/417 - loss 5.98982252 - samples/sec: 146.33\n",
            "2020-03-08 15:51:47,194 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:51:47,195 EPOCH 33 done: loss 5.9804 - lr 0.1000\n",
            "2020-03-08 15:52:19,414 DEV : loss 0.1807505339384079 - score 0.6853883693674109\n",
            "2020-03-08 15:52:20,830 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:52:59,166 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:53:10,206 epoch 34 - iter 41/417 - loss 5.57696295 - samples/sec: 133.64\n",
            "2020-03-08 15:53:19,468 epoch 34 - iter 82/417 - loss 5.65457933 - samples/sec: 141.84\n",
            "2020-03-08 15:53:28,767 epoch 34 - iter 123/417 - loss 5.83239674 - samples/sec: 141.26\n",
            "2020-03-08 15:53:38,259 epoch 34 - iter 164/417 - loss 5.83063582 - samples/sec: 138.37\n",
            "2020-03-08 15:53:47,341 epoch 34 - iter 205/417 - loss 5.83722318 - samples/sec: 144.62\n",
            "2020-03-08 15:53:56,277 epoch 34 - iter 246/417 - loss 5.84313398 - samples/sec: 147.03\n",
            "2020-03-08 15:54:05,233 epoch 34 - iter 287/417 - loss 5.87244333 - samples/sec: 146.69\n",
            "2020-03-08 15:54:14,617 epoch 34 - iter 328/417 - loss 5.93893291 - samples/sec: 139.98\n",
            "2020-03-08 15:54:23,790 epoch 34 - iter 369/417 - loss 5.94168129 - samples/sec: 143.19\n",
            "2020-03-08 15:54:32,906 epoch 34 - iter 410/417 - loss 5.88232774 - samples/sec: 144.11\n",
            "2020-03-08 15:54:34,443 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:54:34,444 EPOCH 34 done: loss 5.8811 - lr 0.1000\n",
            "2020-03-08 15:55:08,434 DEV : loss 0.18946444988250732 - score 0.6805018914355486\n",
            "2020-03-08 15:55:09,866 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:55:09,867 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:55:19,448 epoch 35 - iter 41/417 - loss 5.52048693 - samples/sec: 137.00\n",
            "2020-03-08 15:55:28,670 epoch 35 - iter 82/417 - loss 5.66561783 - samples/sec: 142.43\n",
            "2020-03-08 15:55:38,236 epoch 35 - iter 123/417 - loss 5.80063225 - samples/sec: 137.31\n",
            "2020-03-08 15:55:47,443 epoch 35 - iter 164/417 - loss 5.82270871 - samples/sec: 142.69\n",
            "2020-03-08 15:55:56,378 epoch 35 - iter 205/417 - loss 5.77327874 - samples/sec: 147.05\n",
            "2020-03-08 15:56:05,312 epoch 35 - iter 246/417 - loss 5.74799144 - samples/sec: 147.04\n",
            "2020-03-08 15:56:14,089 epoch 35 - iter 287/417 - loss 5.73438495 - samples/sec: 149.66\n",
            "2020-03-08 15:56:22,772 epoch 35 - iter 328/417 - loss 5.78417593 - samples/sec: 151.28\n",
            "2020-03-08 15:56:31,950 epoch 35 - iter 369/417 - loss 5.79023584 - samples/sec: 143.13\n",
            "2020-03-08 15:56:40,957 epoch 35 - iter 410/417 - loss 5.81851950 - samples/sec: 145.85\n",
            "2020-03-08 15:56:42,536 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:56:42,537 EPOCH 35 done: loss 5.8225 - lr 0.1000\n",
            "2020-03-08 15:57:11,253 DEV : loss 0.18396806716918945 - score 0.6974387940927865\n",
            "2020-03-08 15:57:12,661 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:57:50,739 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:58:02,696 epoch 36 - iter 41/417 - loss 5.64991549 - samples/sec: 134.13\n",
            "2020-03-08 15:58:11,978 epoch 36 - iter 82/417 - loss 5.66184418 - samples/sec: 141.52\n",
            "2020-03-08 15:58:21,057 epoch 36 - iter 123/417 - loss 5.71834850 - samples/sec: 144.69\n",
            "2020-03-08 15:58:30,275 epoch 36 - iter 164/417 - loss 5.74916689 - samples/sec: 142.49\n",
            "2020-03-08 15:58:38,731 epoch 36 - iter 205/417 - loss 5.72765192 - samples/sec: 155.33\n",
            "2020-03-08 15:58:47,382 epoch 36 - iter 246/417 - loss 5.74110037 - samples/sec: 151.86\n",
            "2020-03-08 15:58:55,807 epoch 36 - iter 287/417 - loss 5.74327020 - samples/sec: 155.93\n",
            "2020-03-08 15:59:04,807 epoch 36 - iter 328/417 - loss 5.74923588 - samples/sec: 145.94\n",
            "2020-03-08 15:59:13,902 epoch 36 - iter 369/417 - loss 5.76906668 - samples/sec: 144.46\n",
            "2020-03-08 15:59:22,846 epoch 36 - iter 410/417 - loss 5.72222691 - samples/sec: 146.88\n",
            "2020-03-08 15:59:24,316 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:59:24,318 EPOCH 36 done: loss 5.7327 - lr 0.1000\n",
            "2020-03-08 15:59:54,350 DEV : loss 0.20061010122299194 - score 0.684395203475485\n",
            "2020-03-08 15:59:55,780 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:59:55,782 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:00:05,570 epoch 37 - iter 41/417 - loss 5.45995177 - samples/sec: 134.10\n",
            "2020-03-08 16:00:14,672 epoch 37 - iter 82/417 - loss 5.45356533 - samples/sec: 144.31\n",
            "2020-03-08 16:00:23,295 epoch 37 - iter 123/417 - loss 5.57382572 - samples/sec: 152.33\n",
            "2020-03-08 16:00:31,835 epoch 37 - iter 164/417 - loss 5.55655181 - samples/sec: 153.80\n",
            "2020-03-08 16:00:40,826 epoch 37 - iter 205/417 - loss 5.59417378 - samples/sec: 146.13\n",
            "2020-03-08 16:00:50,020 epoch 37 - iter 246/417 - loss 5.74765421 - samples/sec: 142.89\n",
            "2020-03-08 16:00:59,110 epoch 37 - iter 287/417 - loss 5.72443377 - samples/sec: 144.49\n",
            "2020-03-08 16:01:07,868 epoch 37 - iter 328/417 - loss 5.67267903 - samples/sec: 149.98\n",
            "2020-03-08 16:01:16,657 epoch 37 - iter 369/417 - loss 5.68304517 - samples/sec: 149.51\n",
            "2020-03-08 16:01:25,473 epoch 37 - iter 410/417 - loss 5.70359801 - samples/sec: 149.01\n",
            "2020-03-08 16:01:26,923 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:01:26,924 EPOCH 37 done: loss 5.7048 - lr 0.1000\n",
            "2020-03-08 16:01:58,437 DEV : loss 0.1813952624797821 - score 0.6887287548384811\n",
            "2020-03-08 16:01:59,864 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 16:01:59,865 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:02:09,775 epoch 38 - iter 41/417 - loss 5.31672284 - samples/sec: 132.45\n",
            "2020-03-08 16:02:19,020 epoch 38 - iter 82/417 - loss 5.49335525 - samples/sec: 142.08\n",
            "2020-03-08 16:02:28,090 epoch 38 - iter 123/417 - loss 5.38983859 - samples/sec: 144.79\n",
            "2020-03-08 16:02:36,891 epoch 38 - iter 164/417 - loss 5.34927483 - samples/sec: 149.26\n",
            "2020-03-08 16:02:45,879 epoch 38 - iter 205/417 - loss 5.36356878 - samples/sec: 146.16\n",
            "2020-03-08 16:02:54,785 epoch 38 - iter 246/417 - loss 5.39535177 - samples/sec: 147.49\n",
            "2020-03-08 16:03:03,858 epoch 38 - iter 287/417 - loss 5.47111569 - samples/sec: 144.78\n",
            "2020-03-08 16:03:12,489 epoch 38 - iter 328/417 - loss 5.52521120 - samples/sec: 152.22\n",
            "2020-03-08 16:03:21,507 epoch 38 - iter 369/417 - loss 5.57986693 - samples/sec: 145.68\n",
            "2020-03-08 16:03:30,777 epoch 38 - iter 410/417 - loss 5.56155521 - samples/sec: 141.70\n",
            "2020-03-08 16:03:32,233 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:03:32,234 EPOCH 38 done: loss 5.5780 - lr 0.1000\n",
            "2020-03-08 16:04:01,744 DEV : loss 0.1780710518360138 - score 0.6919158256848346\n",
            "2020-03-08 16:04:03,171 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 16:04:03,172 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:04:12,174 epoch 39 - iter 41/417 - loss 5.53732775 - samples/sec: 145.82\n",
            "2020-03-08 16:04:21,184 epoch 39 - iter 82/417 - loss 5.42157664 - samples/sec: 145.81\n",
            "2020-03-08 16:04:30,141 epoch 39 - iter 123/417 - loss 5.32018546 - samples/sec: 146.67\n",
            "2020-03-08 16:04:38,842 epoch 39 - iter 164/417 - loss 5.35238539 - samples/sec: 150.98\n",
            "2020-03-08 16:04:47,399 epoch 39 - iter 205/417 - loss 5.29822051 - samples/sec: 153.50\n",
            "2020-03-08 16:04:56,043 epoch 39 - iter 246/417 - loss 5.39995026 - samples/sec: 151.99\n",
            "2020-03-08 16:05:04,896 epoch 39 - iter 287/417 - loss 5.41830008 - samples/sec: 148.39\n",
            "2020-03-08 16:05:13,952 epoch 39 - iter 328/417 - loss 5.46387680 - samples/sec: 145.05\n",
            "2020-03-08 16:05:22,852 epoch 39 - iter 369/417 - loss 5.40987756 - samples/sec: 147.58\n",
            "2020-03-08 16:05:31,747 epoch 39 - iter 410/417 - loss 5.43191384 - samples/sec: 147.69\n",
            "2020-03-08 16:05:33,174 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:05:33,175 EPOCH 39 done: loss 5.4191 - lr 0.1000\n",
            "2020-03-08 16:06:04,094 DEV : loss 0.19654163718223572 - score 0.6987400789092071\n",
            "2020-03-08 16:06:05,530 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:06:44,812 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:06:54,863 epoch 40 - iter 41/417 - loss 5.14281347 - samples/sec: 139.48\n",
            "2020-03-08 16:07:03,887 epoch 40 - iter 82/417 - loss 5.19437589 - samples/sec: 145.55\n",
            "2020-03-08 16:07:13,211 epoch 40 - iter 123/417 - loss 5.23443897 - samples/sec: 140.88\n",
            "2020-03-08 16:07:22,379 epoch 40 - iter 164/417 - loss 5.13000889 - samples/sec: 143.29\n",
            "2020-03-08 16:07:31,316 epoch 40 - iter 205/417 - loss 5.18282606 - samples/sec: 146.97\n",
            "2020-03-08 16:07:40,318 epoch 40 - iter 246/417 - loss 5.24413883 - samples/sec: 145.91\n",
            "2020-03-08 16:07:48,902 epoch 40 - iter 287/417 - loss 5.27560700 - samples/sec: 153.03\n",
            "2020-03-08 16:07:57,853 epoch 40 - iter 328/417 - loss 5.27251824 - samples/sec: 146.78\n",
            "2020-03-08 16:08:07,114 epoch 40 - iter 369/417 - loss 5.29188910 - samples/sec: 141.83\n",
            "2020-03-08 16:08:16,380 epoch 40 - iter 410/417 - loss 5.29799627 - samples/sec: 141.76\n",
            "2020-03-08 16:08:18,045 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:08:18,047 EPOCH 40 done: loss 5.3079 - lr 0.1000\n",
            "2020-03-08 16:08:47,867 DEV : loss 0.18394668400287628 - score 0.6984125747746294\n",
            "2020-03-08 16:08:49,294 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:08:49,296 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:08:58,668 epoch 41 - iter 41/417 - loss 5.12477289 - samples/sec: 140.05\n",
            "2020-03-08 16:09:07,425 epoch 41 - iter 82/417 - loss 5.30397877 - samples/sec: 150.01\n",
            "2020-03-08 16:09:16,304 epoch 41 - iter 123/417 - loss 5.15644612 - samples/sec: 147.95\n",
            "2020-03-08 16:09:25,007 epoch 41 - iter 164/417 - loss 5.14472305 - samples/sec: 150.93\n",
            "2020-03-08 16:09:34,068 epoch 41 - iter 205/417 - loss 5.13136646 - samples/sec: 144.97\n",
            "2020-03-08 16:09:43,130 epoch 41 - iter 246/417 - loss 5.24368527 - samples/sec: 144.97\n",
            "2020-03-08 16:09:51,940 epoch 41 - iter 287/417 - loss 5.26565781 - samples/sec: 149.13\n",
            "2020-03-08 16:10:00,739 epoch 41 - iter 328/417 - loss 5.26157665 - samples/sec: 149.29\n",
            "2020-03-08 16:10:09,352 epoch 41 - iter 369/417 - loss 5.32141527 - samples/sec: 152.52\n",
            "2020-03-08 16:10:17,945 epoch 41 - iter 410/417 - loss 5.33867605 - samples/sec: 152.91\n",
            "2020-03-08 16:10:19,470 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:10:19,471 EPOCH 41 done: loss 5.3354 - lr 0.1000\n",
            "2020-03-08 16:10:51,555 DEV : loss 0.20243294537067413 - score 0.7002570228981813\n",
            "2020-03-08 16:10:52,988 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:11:27,726 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:11:38,967 epoch 42 - iter 41/417 - loss 5.69258357 - samples/sec: 132.59\n",
            "2020-03-08 16:11:51,283 epoch 42 - iter 82/417 - loss 5.43805960 - samples/sec: 106.62\n",
            "2020-03-08 16:12:00,132 epoch 42 - iter 123/417 - loss 5.33572706 - samples/sec: 148.46\n",
            "2020-03-08 16:12:08,857 epoch 42 - iter 164/417 - loss 5.33231449 - samples/sec: 150.58\n",
            "2020-03-08 16:12:17,465 epoch 42 - iter 205/417 - loss 5.33054516 - samples/sec: 152.63\n",
            "2020-03-08 16:12:26,175 epoch 42 - iter 246/417 - loss 5.36972917 - samples/sec: 150.82\n",
            "2020-03-08 16:12:35,256 epoch 42 - iter 287/417 - loss 5.32768703 - samples/sec: 144.66\n",
            "2020-03-08 16:12:44,150 epoch 42 - iter 328/417 - loss 5.32101668 - samples/sec: 147.68\n",
            "2020-03-08 16:12:52,728 epoch 42 - iter 369/417 - loss 5.30254650 - samples/sec: 153.14\n",
            "2020-03-08 16:13:01,280 epoch 42 - iter 410/417 - loss 5.31994066 - samples/sec: 153.62\n",
            "2020-03-08 16:13:02,738 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:13:02,740 EPOCH 42 done: loss 5.3407 - lr 0.1000\n",
            "2020-03-08 16:13:33,596 DEV : loss 0.2049456089735031 - score 0.7028122762079737\n",
            "2020-03-08 16:13:35,024 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:14:10,994 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:14:24,989 epoch 43 - iter 41/417 - loss 5.08370752 - samples/sec: 134.18\n",
            "2020-03-08 16:14:34,563 epoch 43 - iter 82/417 - loss 5.12047821 - samples/sec: 137.20\n",
            "2020-03-08 16:14:43,738 epoch 43 - iter 123/417 - loss 5.15611025 - samples/sec: 143.19\n",
            "2020-03-08 16:14:52,792 epoch 43 - iter 164/417 - loss 5.26054603 - samples/sec: 145.08\n",
            "2020-03-08 16:15:01,651 epoch 43 - iter 205/417 - loss 5.24334517 - samples/sec: 148.28\n",
            "2020-03-08 16:15:10,455 epoch 43 - iter 246/417 - loss 5.23410045 - samples/sec: 149.21\n",
            "2020-03-08 16:15:19,522 epoch 43 - iter 287/417 - loss 5.23772963 - samples/sec: 144.88\n",
            "2020-03-08 16:15:28,336 epoch 43 - iter 328/417 - loss 5.29047161 - samples/sec: 149.06\n",
            "2020-03-08 16:15:37,112 epoch 43 - iter 369/417 - loss 5.30049586 - samples/sec: 149.69\n",
            "2020-03-08 16:15:45,753 epoch 43 - iter 410/417 - loss 5.26572976 - samples/sec: 152.05\n",
            "2020-03-08 16:15:47,176 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:15:47,177 EPOCH 43 done: loss 5.2655 - lr 0.1000\n",
            "2020-03-08 16:16:18,055 DEV : loss 0.1742209792137146 - score 0.7042094032501232\n",
            "2020-03-08 16:16:19,474 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:16:56,107 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:17:05,812 epoch 44 - iter 41/417 - loss 5.14381727 - samples/sec: 137.58\n",
            "2020-03-08 16:17:15,312 epoch 44 - iter 82/417 - loss 4.90690739 - samples/sec: 138.30\n",
            "2020-03-08 16:17:24,591 epoch 44 - iter 123/417 - loss 4.87207233 - samples/sec: 141.59\n",
            "2020-03-08 16:17:33,916 epoch 44 - iter 164/417 - loss 5.03940135 - samples/sec: 140.86\n",
            "2020-03-08 16:17:43,027 epoch 44 - iter 205/417 - loss 5.03361780 - samples/sec: 144.19\n",
            "2020-03-08 16:17:51,911 epoch 44 - iter 246/417 - loss 5.01941086 - samples/sec: 147.87\n",
            "2020-03-08 16:18:00,652 epoch 44 - iter 287/417 - loss 5.06880934 - samples/sec: 150.28\n",
            "2020-03-08 16:18:09,683 epoch 44 - iter 328/417 - loss 5.09891781 - samples/sec: 145.45\n",
            "2020-03-08 16:18:18,789 epoch 44 - iter 369/417 - loss 5.11479500 - samples/sec: 144.23\n",
            "2020-03-08 16:18:28,050 epoch 44 - iter 410/417 - loss 5.13802542 - samples/sec: 141.83\n",
            "2020-03-08 16:18:29,614 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:18:29,615 EPOCH 44 done: loss 5.1369 - lr 0.1000\n",
            "2020-03-08 16:19:00,680 DEV : loss 0.20635946094989777 - score 0.7051846837293528\n",
            "2020-03-08 16:19:02,117 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:19:37,992 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:19:50,877 epoch 45 - iter 41/417 - loss 5.22738743 - samples/sec: 134.21\n",
            "2020-03-08 16:20:00,082 epoch 45 - iter 82/417 - loss 5.07446853 - samples/sec: 142.71\n",
            "2020-03-08 16:20:09,429 epoch 45 - iter 123/417 - loss 4.94333142 - samples/sec: 140.53\n",
            "2020-03-08 16:20:18,794 epoch 45 - iter 164/417 - loss 5.01981300 - samples/sec: 140.27\n",
            "2020-03-08 16:20:28,113 epoch 45 - iter 205/417 - loss 5.05833296 - samples/sec: 140.95\n",
            "2020-03-08 16:20:37,275 epoch 45 - iter 246/417 - loss 5.07360700 - samples/sec: 143.38\n",
            "2020-03-08 16:20:46,411 epoch 45 - iter 287/417 - loss 5.07301288 - samples/sec: 143.77\n",
            "2020-03-08 16:20:55,290 epoch 45 - iter 328/417 - loss 5.10325828 - samples/sec: 147.96\n",
            "2020-03-08 16:21:04,263 epoch 45 - iter 369/417 - loss 5.08663320 - samples/sec: 146.38\n",
            "2020-03-08 16:21:13,133 epoch 45 - iter 410/417 - loss 5.11293396 - samples/sec: 148.09\n",
            "2020-03-08 16:21:14,651 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:21:14,652 EPOCH 45 done: loss 5.1185 - lr 0.1000\n",
            "2020-03-08 16:21:44,390 DEV : loss 0.1872851848602295 - score 0.686674899560545\n",
            "2020-03-08 16:21:45,801 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:21:45,803 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:21:55,390 epoch 46 - iter 41/417 - loss 4.69313241 - samples/sec: 136.91\n",
            "2020-03-08 16:22:04,759 epoch 46 - iter 82/417 - loss 4.87540394 - samples/sec: 140.21\n",
            "2020-03-08 16:22:14,151 epoch 46 - iter 123/417 - loss 5.04571357 - samples/sec: 139.85\n",
            "2020-03-08 16:22:23,357 epoch 46 - iter 164/417 - loss 4.92636942 - samples/sec: 142.71\n",
            "2020-03-08 16:22:32,425 epoch 46 - iter 205/417 - loss 4.92934615 - samples/sec: 144.83\n",
            "2020-03-08 16:22:41,528 epoch 46 - iter 246/417 - loss 4.97456411 - samples/sec: 144.29\n",
            "2020-03-08 16:22:50,466 epoch 46 - iter 287/417 - loss 4.98650174 - samples/sec: 146.99\n",
            "2020-03-08 16:22:59,170 epoch 46 - iter 328/417 - loss 4.95797662 - samples/sec: 150.89\n",
            "2020-03-08 16:23:07,901 epoch 46 - iter 369/417 - loss 4.95050684 - samples/sec: 150.46\n",
            "2020-03-08 16:23:16,663 epoch 46 - iter 410/417 - loss 4.93097523 - samples/sec: 149.93\n",
            "2020-03-08 16:23:18,180 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:23:18,181 EPOCH 46 done: loss 4.9280 - lr 0.1000\n",
            "2020-03-08 16:23:49,901 DEV : loss 0.170768141746521 - score 0.701491769004756\n",
            "2020-03-08 16:23:51,343 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 16:23:51,344 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:24:00,907 epoch 47 - iter 41/417 - loss 5.19443100 - samples/sec: 137.26\n",
            "2020-03-08 16:24:09,821 epoch 47 - iter 82/417 - loss 5.04909682 - samples/sec: 147.37\n",
            "2020-03-08 16:24:18,745 epoch 47 - iter 123/417 - loss 4.97192225 - samples/sec: 147.20\n",
            "2020-03-08 16:24:27,479 epoch 47 - iter 164/417 - loss 5.01347736 - samples/sec: 150.41\n",
            "2020-03-08 16:24:36,133 epoch 47 - iter 205/417 - loss 5.00803292 - samples/sec: 151.80\n",
            "2020-03-08 16:24:44,715 epoch 47 - iter 246/417 - loss 4.98457467 - samples/sec: 153.08\n",
            "2020-03-08 16:24:53,127 epoch 47 - iter 287/417 - loss 4.97057578 - samples/sec: 156.15\n",
            "2020-03-08 16:25:01,817 epoch 47 - iter 328/417 - loss 4.97757095 - samples/sec: 151.17\n",
            "2020-03-08 16:25:10,547 epoch 47 - iter 369/417 - loss 4.93415303 - samples/sec: 150.46\n",
            "2020-03-08 16:25:19,282 epoch 47 - iter 410/417 - loss 4.93015348 - samples/sec: 150.40\n",
            "2020-03-08 16:25:20,758 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:25:20,759 EPOCH 47 done: loss 4.9142 - lr 0.1000\n",
            "2020-03-08 16:25:50,454 DEV : loss 0.1730458289384842 - score 0.7070200762656998\n",
            "2020-03-08 16:25:51,900 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:26:27,609 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:26:38,463 epoch 48 - iter 41/417 - loss 4.85185724 - samples/sec: 135.16\n",
            "2020-03-08 16:26:47,962 epoch 48 - iter 82/417 - loss 4.88783360 - samples/sec: 138.27\n",
            "2020-03-08 16:26:57,239 epoch 48 - iter 123/417 - loss 4.82335916 - samples/sec: 141.57\n",
            "2020-03-08 16:27:06,396 epoch 48 - iter 164/417 - loss 4.69638313 - samples/sec: 143.44\n",
            "2020-03-08 16:27:16,010 epoch 48 - iter 205/417 - loss 4.85322970 - samples/sec: 136.64\n",
            "2020-03-08 16:27:25,137 epoch 48 - iter 246/417 - loss 4.82720842 - samples/sec: 143.93\n",
            "2020-03-08 16:27:34,327 epoch 48 - iter 287/417 - loss 4.78764464 - samples/sec: 142.94\n",
            "2020-03-08 16:27:43,270 epoch 48 - iter 328/417 - loss 4.78330393 - samples/sec: 146.89\n",
            "2020-03-08 16:27:52,277 epoch 48 - iter 369/417 - loss 4.82865792 - samples/sec: 145.87\n",
            "2020-03-08 16:28:01,294 epoch 48 - iter 410/417 - loss 4.79609545 - samples/sec: 145.69\n",
            "2020-03-08 16:28:02,822 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:28:02,823 EPOCH 48 done: loss 4.7946 - lr 0.1000\n",
            "2020-03-08 16:28:34,925 DEV : loss 0.19078654050827026 - score 0.7039054228042566\n",
            "2020-03-08 16:28:36,371 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:28:36,372 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:28:45,937 epoch 49 - iter 41/417 - loss 4.96859617 - samples/sec: 137.23\n",
            "2020-03-08 16:28:55,353 epoch 49 - iter 82/417 - loss 4.82091444 - samples/sec: 139.49\n",
            "2020-03-08 16:29:04,794 epoch 49 - iter 123/417 - loss 4.83110594 - samples/sec: 139.12\n",
            "2020-03-08 16:29:14,047 epoch 49 - iter 164/417 - loss 4.91308603 - samples/sec: 141.96\n",
            "2020-03-08 16:29:23,497 epoch 49 - iter 205/417 - loss 4.89035135 - samples/sec: 139.00\n",
            "2020-03-08 16:29:32,994 epoch 49 - iter 246/417 - loss 4.84439740 - samples/sec: 138.30\n",
            "2020-03-08 16:29:42,316 epoch 49 - iter 287/417 - loss 4.83201244 - samples/sec: 140.92\n",
            "2020-03-08 16:29:50,985 epoch 49 - iter 328/417 - loss 4.83138489 - samples/sec: 151.53\n",
            "2020-03-08 16:29:59,871 epoch 49 - iter 369/417 - loss 4.80333580 - samples/sec: 147.85\n",
            "2020-03-08 16:30:08,827 epoch 49 - iter 410/417 - loss 4.80542045 - samples/sec: 146.68\n",
            "2020-03-08 16:30:10,326 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:30:10,327 EPOCH 49 done: loss 4.8129 - lr 0.1000\n",
            "2020-03-08 16:30:43,252 DEV : loss 0.16947810351848602 - score 0.7075019035563074\n",
            "2020-03-08 16:30:44,674 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:31:19,209 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:31:31,347 epoch 50 - iter 41/417 - loss 4.59797339 - samples/sec: 135.68\n",
            "2020-03-08 16:31:40,767 epoch 50 - iter 82/417 - loss 4.58536687 - samples/sec: 139.48\n",
            "2020-03-08 16:31:50,140 epoch 50 - iter 123/417 - loss 4.53534314 - samples/sec: 140.16\n",
            "2020-03-08 16:31:59,405 epoch 50 - iter 164/417 - loss 4.54301702 - samples/sec: 141.80\n",
            "2020-03-08 16:32:08,348 epoch 50 - iter 205/417 - loss 4.58887247 - samples/sec: 146.90\n",
            "2020-03-08 16:32:17,229 epoch 50 - iter 246/417 - loss 4.65940103 - samples/sec: 147.93\n",
            "2020-03-08 16:32:25,916 epoch 50 - iter 287/417 - loss 4.70877175 - samples/sec: 151.24\n",
            "2020-03-08 16:32:34,665 epoch 50 - iter 328/417 - loss 4.71324779 - samples/sec: 150.18\n",
            "2020-03-08 16:32:43,879 epoch 50 - iter 369/417 - loss 4.73047265 - samples/sec: 142.55\n",
            "2020-03-08 16:32:53,133 epoch 50 - iter 410/417 - loss 4.71138427 - samples/sec: 141.98\n",
            "2020-03-08 16:32:54,553 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:32:54,554 EPOCH 50 done: loss 4.7197 - lr 0.1000\n",
            "2020-03-08 16:33:23,749 DEV : loss 0.17106272280216217 - score 0.7098632186788725\n",
            "2020-03-08 16:33:25,173 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:34:00,857 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:34:11,413 epoch 51 - iter 41/417 - loss 4.51793132 - samples/sec: 137.93\n",
            "2020-03-08 16:34:20,631 epoch 51 - iter 82/417 - loss 4.60242961 - samples/sec: 142.50\n",
            "2020-03-08 16:34:29,663 epoch 51 - iter 123/417 - loss 4.65862502 - samples/sec: 145.44\n",
            "2020-03-08 16:34:38,350 epoch 51 - iter 164/417 - loss 4.55337592 - samples/sec: 151.23\n",
            "2020-03-08 16:34:47,188 epoch 51 - iter 205/417 - loss 4.50349287 - samples/sec: 148.64\n",
            "2020-03-08 16:34:56,087 epoch 51 - iter 246/417 - loss 4.54286305 - samples/sec: 147.60\n",
            "2020-03-08 16:35:05,270 epoch 51 - iter 287/417 - loss 4.58558533 - samples/sec: 143.03\n",
            "2020-03-08 16:35:14,757 epoch 51 - iter 328/417 - loss 4.63237441 - samples/sec: 138.45\n",
            "2020-03-08 16:35:24,054 epoch 51 - iter 369/417 - loss 4.69271013 - samples/sec: 141.29\n",
            "2020-03-08 16:35:32,916 epoch 51 - iter 410/417 - loss 4.70341188 - samples/sec: 148.23\n",
            "2020-03-08 16:35:34,316 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:35:34,317 EPOCH 51 done: loss 4.7028 - lr 0.1000\n",
            "2020-03-08 16:36:05,090 DEV : loss 0.1738908737897873 - score 0.6997234021468612\n",
            "2020-03-08 16:36:06,521 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:36:06,523 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:36:15,642 epoch 52 - iter 41/417 - loss 4.59375841 - samples/sec: 143.95\n",
            "2020-03-08 16:36:24,597 epoch 52 - iter 82/417 - loss 4.57133578 - samples/sec: 146.69\n",
            "2020-03-08 16:36:33,573 epoch 52 - iter 123/417 - loss 4.61691718 - samples/sec: 146.33\n",
            "2020-03-08 16:36:42,680 epoch 52 - iter 164/417 - loss 4.61357376 - samples/sec: 144.23\n",
            "2020-03-08 16:36:51,663 epoch 52 - iter 205/417 - loss 4.60897676 - samples/sec: 146.26\n",
            "2020-03-08 16:37:00,248 epoch 52 - iter 246/417 - loss 4.71603186 - samples/sec: 153.04\n",
            "2020-03-08 16:37:08,622 epoch 52 - iter 287/417 - loss 4.66416982 - samples/sec: 156.87\n",
            "2020-03-08 16:37:17,103 epoch 52 - iter 328/417 - loss 4.65044643 - samples/sec: 154.93\n",
            "2020-03-08 16:37:26,063 epoch 52 - iter 369/417 - loss 4.63937544 - samples/sec: 146.63\n",
            "2020-03-08 16:37:35,486 epoch 52 - iter 410/417 - loss 4.61967646 - samples/sec: 139.38\n",
            "2020-03-08 16:37:37,052 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:37:37,053 EPOCH 52 done: loss 4.6255 - lr 0.1000\n",
            "2020-03-08 16:38:08,898 DEV : loss 0.17802846431732178 - score 0.7123778750256543\n",
            "2020-03-08 16:38:10,345 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:38:45,995 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:38:59,631 epoch 53 - iter 41/417 - loss 4.39448540 - samples/sec: 134.33\n",
            "2020-03-08 16:39:09,245 epoch 53 - iter 82/417 - loss 4.50200603 - samples/sec: 136.63\n",
            "2020-03-08 16:39:18,501 epoch 53 - iter 123/417 - loss 4.49140088 - samples/sec: 141.93\n",
            "2020-03-08 16:39:27,565 epoch 53 - iter 164/417 - loss 4.49663148 - samples/sec: 144.93\n",
            "2020-03-08 16:39:36,490 epoch 53 - iter 205/417 - loss 4.49790859 - samples/sec: 147.20\n",
            "2020-03-08 16:39:45,151 epoch 53 - iter 246/417 - loss 4.50854627 - samples/sec: 151.68\n",
            "2020-03-08 16:39:53,998 epoch 53 - iter 287/417 - loss 4.51486827 - samples/sec: 148.50\n",
            "2020-03-08 16:40:02,908 epoch 53 - iter 328/417 - loss 4.52641362 - samples/sec: 147.43\n",
            "2020-03-08 16:40:12,296 epoch 53 - iter 369/417 - loss 4.51402443 - samples/sec: 139.93\n",
            "2020-03-08 16:40:21,070 epoch 53 - iter 410/417 - loss 4.52431971 - samples/sec: 149.74\n",
            "2020-03-08 16:40:22,561 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:40:22,562 EPOCH 53 done: loss 4.5350 - lr 0.1000\n",
            "2020-03-08 16:40:53,013 DEV : loss 0.195816770195961 - score 0.712555444183621\n",
            "2020-03-08 16:40:54,431 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:41:29,533 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:41:42,563 epoch 54 - iter 41/417 - loss 4.69355783 - samples/sec: 133.43\n",
            "2020-03-08 16:41:52,065 epoch 54 - iter 82/417 - loss 4.66597222 - samples/sec: 138.24\n",
            "2020-03-08 16:42:01,486 epoch 54 - iter 123/417 - loss 4.52513286 - samples/sec: 139.43\n",
            "2020-03-08 16:42:10,895 epoch 54 - iter 164/417 - loss 4.55492755 - samples/sec: 139.60\n",
            "2020-03-08 16:42:20,161 epoch 54 - iter 205/417 - loss 4.48605411 - samples/sec: 141.77\n",
            "2020-03-08 16:42:29,379 epoch 54 - iter 246/417 - loss 4.45730228 - samples/sec: 142.53\n",
            "2020-03-08 16:42:38,686 epoch 54 - iter 287/417 - loss 4.49704643 - samples/sec: 141.13\n",
            "2020-03-08 16:42:48,023 epoch 54 - iter 328/417 - loss 4.50968271 - samples/sec: 140.71\n",
            "2020-03-08 16:42:57,278 epoch 54 - iter 369/417 - loss 4.49392172 - samples/sec: 141.90\n",
            "2020-03-08 16:43:06,367 epoch 54 - iter 410/417 - loss 4.48824476 - samples/sec: 144.54\n",
            "2020-03-08 16:43:07,903 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:43:07,904 EPOCH 54 done: loss 4.4781 - lr 0.1000\n",
            "2020-03-08 16:43:39,488 DEV : loss 0.21489717066287994 - score 0.6993138438299795\n",
            "2020-03-08 16:43:40,924 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:43:40,925 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:43:50,778 epoch 55 - iter 41/417 - loss 4.37560605 - samples/sec: 133.22\n",
            "2020-03-08 16:44:00,005 epoch 55 - iter 82/417 - loss 4.29348971 - samples/sec: 142.35\n",
            "2020-03-08 16:44:09,232 epoch 55 - iter 123/417 - loss 4.32568151 - samples/sec: 142.37\n",
            "2020-03-08 16:44:18,346 epoch 55 - iter 164/417 - loss 4.30870548 - samples/sec: 144.13\n",
            "2020-03-08 16:44:27,258 epoch 55 - iter 205/417 - loss 4.30840172 - samples/sec: 147.41\n",
            "2020-03-08 16:44:36,015 epoch 55 - iter 246/417 - loss 4.24924810 - samples/sec: 150.02\n",
            "2020-03-08 16:44:44,630 epoch 55 - iter 287/417 - loss 4.28333055 - samples/sec: 152.48\n",
            "2020-03-08 16:44:53,420 epoch 55 - iter 328/417 - loss 4.31010850 - samples/sec: 149.44\n",
            "2020-03-08 16:45:02,176 epoch 55 - iter 369/417 - loss 4.34481825 - samples/sec: 150.02\n",
            "2020-03-08 16:45:10,908 epoch 55 - iter 410/417 - loss 4.35544143 - samples/sec: 150.47\n",
            "2020-03-08 16:45:12,349 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:45:12,350 EPOCH 55 done: loss 4.3497 - lr 0.1000\n",
            "2020-03-08 16:45:42,122 DEV : loss 0.1764804869890213 - score 0.7123029244196877\n",
            "2020-03-08 16:45:43,547 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 16:45:43,548 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:45:53,005 epoch 56 - iter 41/417 - loss 4.22381647 - samples/sec: 138.79\n",
            "2020-03-08 16:46:01,985 epoch 56 - iter 82/417 - loss 4.27830231 - samples/sec: 146.27\n",
            "2020-03-08 16:46:10,881 epoch 56 - iter 123/417 - loss 4.40215691 - samples/sec: 147.66\n",
            "2020-03-08 16:46:19,556 epoch 56 - iter 164/417 - loss 4.54184744 - samples/sec: 151.42\n",
            "2020-03-08 16:46:28,323 epoch 56 - iter 205/417 - loss 4.48356012 - samples/sec: 149.86\n",
            "2020-03-08 16:46:37,059 epoch 56 - iter 246/417 - loss 4.46985403 - samples/sec: 150.36\n",
            "2020-03-08 16:46:45,759 epoch 56 - iter 287/417 - loss 4.41734575 - samples/sec: 151.04\n",
            "2020-03-08 16:46:54,636 epoch 56 - iter 328/417 - loss 4.40253458 - samples/sec: 148.02\n",
            "2020-03-08 16:47:03,381 epoch 56 - iter 369/417 - loss 4.37208628 - samples/sec: 150.22\n",
            "2020-03-08 16:47:12,310 epoch 56 - iter 410/417 - loss 4.36612690 - samples/sec: 147.12\n",
            "2020-03-08 16:47:13,648 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:47:13,649 EPOCH 56 done: loss 4.3567 - lr 0.1000\n",
            "2020-03-08 16:47:45,928 DEV : loss 0.17587220668792725 - score 0.701447344066653\n",
            "2020-03-08 16:47:47,356 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 16:47:47,358 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:47:57,044 epoch 57 - iter 41/417 - loss 4.18983548 - samples/sec: 135.51\n",
            "2020-03-08 16:48:06,130 epoch 57 - iter 82/417 - loss 4.24995365 - samples/sec: 144.58\n",
            "2020-03-08 16:48:15,458 epoch 57 - iter 123/417 - loss 4.27399425 - samples/sec: 140.80\n",
            "2020-03-08 16:48:24,209 epoch 57 - iter 164/417 - loss 4.19174072 - samples/sec: 150.11\n",
            "2020-03-08 16:48:33,026 epoch 57 - iter 205/417 - loss 4.12687307 - samples/sec: 148.99\n",
            "2020-03-08 16:48:41,967 epoch 57 - iter 246/417 - loss 4.15655426 - samples/sec: 146.91\n",
            "2020-03-08 16:48:50,618 epoch 57 - iter 287/417 - loss 4.23709859 - samples/sec: 151.87\n",
            "2020-03-08 16:48:59,918 epoch 57 - iter 328/417 - loss 4.26626443 - samples/sec: 141.23\n",
            "2020-03-08 16:49:11,974 epoch 57 - iter 369/417 - loss 4.26105102 - samples/sec: 108.93\n",
            "2020-03-08 16:49:20,984 epoch 57 - iter 410/417 - loss 4.24814003 - samples/sec: 145.78\n",
            "2020-03-08 16:49:22,449 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:49:22,450 EPOCH 57 done: loss 4.2480 - lr 0.1000\n",
            "2020-03-08 16:49:52,888 DEV : loss 0.18255484104156494 - score 0.7075994889467031\n",
            "Epoch    57: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-03-08 16:49:54,335 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 16:49:54,337 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:50:03,721 epoch 58 - iter 41/417 - loss 3.84443781 - samples/sec: 139.86\n",
            "2020-03-08 16:50:12,406 epoch 58 - iter 82/417 - loss 3.74311998 - samples/sec: 151.27\n",
            "2020-03-08 16:50:21,160 epoch 58 - iter 123/417 - loss 3.55965368 - samples/sec: 150.06\n",
            "2020-03-08 16:50:30,095 epoch 58 - iter 164/417 - loss 3.65656220 - samples/sec: 147.04\n",
            "2020-03-08 16:50:38,603 epoch 58 - iter 205/417 - loss 3.62189469 - samples/sec: 154.39\n",
            "2020-03-08 16:50:47,155 epoch 58 - iter 246/417 - loss 3.62766441 - samples/sec: 153.61\n",
            "2020-03-08 16:50:55,961 epoch 58 - iter 287/417 - loss 3.67115688 - samples/sec: 149.18\n",
            "2020-03-08 16:51:04,785 epoch 58 - iter 328/417 - loss 3.69827798 - samples/sec: 148.86\n",
            "2020-03-08 16:51:13,401 epoch 58 - iter 369/417 - loss 3.66317047 - samples/sec: 152.47\n",
            "2020-03-08 16:51:22,199 epoch 58 - iter 410/417 - loss 3.69801934 - samples/sec: 149.32\n",
            "2020-03-08 16:51:23,661 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:51:23,663 EPOCH 58 done: loss 3.6989 - lr 0.0500\n",
            "2020-03-08 16:51:52,958 DEV : loss 0.17156881093978882 - score 0.7194467477609975\n",
            "2020-03-08 16:51:54,373 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:52:32,819 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:52:44,048 epoch 59 - iter 41/417 - loss 3.79022854 - samples/sec: 137.92\n",
            "2020-03-08 16:52:53,329 epoch 59 - iter 82/417 - loss 3.73833361 - samples/sec: 141.54\n",
            "2020-03-08 16:53:02,586 epoch 59 - iter 123/417 - loss 3.56103192 - samples/sec: 141.90\n",
            "2020-03-08 16:53:11,708 epoch 59 - iter 164/417 - loss 3.51758375 - samples/sec: 144.02\n",
            "2020-03-08 16:53:20,912 epoch 59 - iter 205/417 - loss 3.47902560 - samples/sec: 142.72\n",
            "2020-03-08 16:53:30,019 epoch 59 - iter 246/417 - loss 3.47754157 - samples/sec: 144.26\n",
            "2020-03-08 16:53:38,617 epoch 59 - iter 287/417 - loss 3.53818190 - samples/sec: 152.79\n",
            "2020-03-08 16:53:47,060 epoch 59 - iter 328/417 - loss 3.52591608 - samples/sec: 155.59\n",
            "2020-03-08 16:53:55,418 epoch 59 - iter 369/417 - loss 3.57962299 - samples/sec: 157.20\n",
            "2020-03-08 16:54:04,152 epoch 59 - iter 410/417 - loss 3.53422700 - samples/sec: 150.38\n",
            "2020-03-08 16:54:05,644 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:54:05,645 EPOCH 59 done: loss 3.5485 - lr 0.0500\n",
            "2020-03-08 16:54:37,212 DEV : loss 0.18650926649570465 - score 0.7167117025997788\n",
            "2020-03-08 16:54:38,652 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:54:38,653 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:54:48,075 epoch 60 - iter 41/417 - loss 3.40468019 - samples/sec: 139.32\n",
            "2020-03-08 16:54:57,099 epoch 60 - iter 82/417 - loss 3.58795172 - samples/sec: 145.56\n",
            "2020-03-08 16:55:06,272 epoch 60 - iter 123/417 - loss 3.55082175 - samples/sec: 143.21\n",
            "2020-03-08 16:55:15,468 epoch 60 - iter 164/417 - loss 3.48826763 - samples/sec: 142.83\n",
            "2020-03-08 16:55:24,458 epoch 60 - iter 205/417 - loss 3.50743386 - samples/sec: 146.10\n",
            "2020-03-08 16:55:33,528 epoch 60 - iter 246/417 - loss 3.46549277 - samples/sec: 144.82\n",
            "2020-03-08 16:55:42,116 epoch 60 - iter 287/417 - loss 3.45851961 - samples/sec: 152.98\n",
            "2020-03-08 16:55:50,747 epoch 60 - iter 328/417 - loss 3.46245201 - samples/sec: 152.20\n",
            "2020-03-08 16:55:59,822 epoch 60 - iter 369/417 - loss 3.45364856 - samples/sec: 144.74\n",
            "2020-03-08 16:56:09,187 epoch 60 - iter 410/417 - loss 3.45653195 - samples/sec: 140.27\n",
            "2020-03-08 16:56:10,766 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:56:10,767 EPOCH 60 done: loss 3.4482 - lr 0.0500\n",
            "2020-03-08 16:56:41,091 DEV : loss 0.1881655752658844 - score 0.7192163134544127\n",
            "2020-03-08 16:56:42,515 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 16:56:42,517 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:56:51,976 epoch 61 - iter 41/417 - loss 3.24169067 - samples/sec: 138.75\n",
            "2020-03-08 16:57:01,225 epoch 61 - iter 82/417 - loss 3.26329314 - samples/sec: 142.01\n",
            "2020-03-08 16:57:10,620 epoch 61 - iter 123/417 - loss 3.31342007 - samples/sec: 139.79\n",
            "2020-03-08 16:57:19,935 epoch 61 - iter 164/417 - loss 3.36017835 - samples/sec: 141.04\n",
            "2020-03-08 16:57:29,346 epoch 61 - iter 205/417 - loss 3.40144989 - samples/sec: 139.58\n",
            "2020-03-08 16:57:38,631 epoch 61 - iter 246/417 - loss 3.42037937 - samples/sec: 141.48\n",
            "2020-03-08 16:57:47,459 epoch 61 - iter 287/417 - loss 3.37494959 - samples/sec: 148.79\n",
            "2020-03-08 16:57:56,072 epoch 61 - iter 328/417 - loss 3.35732325 - samples/sec: 152.52\n",
            "2020-03-08 16:58:04,893 epoch 61 - iter 369/417 - loss 3.37736413 - samples/sec: 148.91\n",
            "2020-03-08 16:58:14,189 epoch 61 - iter 410/417 - loss 3.39849018 - samples/sec: 141.29\n",
            "2020-03-08 16:58:15,754 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:58:15,755 EPOCH 61 done: loss 3.3891 - lr 0.0500\n",
            "2020-03-08 16:58:47,500 DEV : loss 0.17690888047218323 - score 0.7287449167233518\n",
            "2020-03-08 16:58:48,956 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:59:28,131 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:59:38,752 epoch 62 - iter 41/417 - loss 3.01506356 - samples/sec: 138.90\n",
            "2020-03-08 16:59:48,016 epoch 62 - iter 82/417 - loss 3.06183364 - samples/sec: 141.78\n",
            "2020-03-08 16:59:57,150 epoch 62 - iter 123/417 - loss 3.07332437 - samples/sec: 143.81\n",
            "2020-03-08 17:00:05,896 epoch 62 - iter 164/417 - loss 3.14046355 - samples/sec: 150.17\n",
            "2020-03-08 17:00:14,621 epoch 62 - iter 205/417 - loss 3.21380309 - samples/sec: 150.56\n",
            "2020-03-08 17:00:23,212 epoch 62 - iter 246/417 - loss 3.28709596 - samples/sec: 152.89\n",
            "2020-03-08 17:00:31,958 epoch 62 - iter 287/417 - loss 3.23624886 - samples/sec: 150.21\n",
            "2020-03-08 17:00:40,940 epoch 62 - iter 328/417 - loss 3.24381548 - samples/sec: 146.24\n",
            "2020-03-08 17:00:49,474 epoch 62 - iter 369/417 - loss 3.28439822 - samples/sec: 153.92\n",
            "2020-03-08 17:00:58,089 epoch 62 - iter 410/417 - loss 3.28357941 - samples/sec: 152.49\n",
            "2020-03-08 17:00:59,503 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:00:59,504 EPOCH 62 done: loss 3.2967 - lr 0.0500\n",
            "2020-03-08 17:01:30,039 DEV : loss 0.1712280809879303 - score 0.7184959361477441\n",
            "2020-03-08 17:01:31,512 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:01:31,514 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:01:41,226 epoch 63 - iter 41/417 - loss 3.00569123 - samples/sec: 135.14\n",
            "2020-03-08 17:01:50,141 epoch 63 - iter 82/417 - loss 3.04438329 - samples/sec: 147.36\n",
            "2020-03-08 17:01:59,186 epoch 63 - iter 123/417 - loss 3.15657801 - samples/sec: 145.23\n",
            "2020-03-08 17:02:08,397 epoch 63 - iter 164/417 - loss 3.19199847 - samples/sec: 142.63\n",
            "2020-03-08 17:02:17,263 epoch 63 - iter 205/417 - loss 3.19079989 - samples/sec: 148.18\n",
            "2020-03-08 17:02:26,191 epoch 63 - iter 246/417 - loss 3.13903218 - samples/sec: 147.14\n",
            "2020-03-08 17:02:34,890 epoch 63 - iter 287/417 - loss 3.14152049 - samples/sec: 150.99\n",
            "2020-03-08 17:02:43,879 epoch 63 - iter 328/417 - loss 3.17144000 - samples/sec: 146.11\n",
            "2020-03-08 17:02:53,160 epoch 63 - iter 369/417 - loss 3.16226697 - samples/sec: 141.56\n",
            "2020-03-08 17:03:02,580 epoch 63 - iter 410/417 - loss 3.16670147 - samples/sec: 139.45\n",
            "2020-03-08 17:03:04,122 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:03:04,123 EPOCH 63 done: loss 3.1733 - lr 0.0500\n",
            "2020-03-08 17:03:35,961 DEV : loss 0.18560990691184998 - score 0.7163120732582917\n",
            "2020-03-08 17:03:37,401 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:03:37,402 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:03:47,090 epoch 64 - iter 41/417 - loss 3.26605276 - samples/sec: 135.49\n",
            "2020-03-08 17:03:56,311 epoch 64 - iter 82/417 - loss 3.26021820 - samples/sec: 142.45\n",
            "2020-03-08 17:04:05,565 epoch 64 - iter 123/417 - loss 3.28995214 - samples/sec: 141.95\n",
            "2020-03-08 17:04:15,231 epoch 64 - iter 164/417 - loss 3.21931134 - samples/sec: 135.89\n",
            "2020-03-08 17:04:24,378 epoch 64 - iter 205/417 - loss 3.19733620 - samples/sec: 143.61\n",
            "2020-03-08 17:04:33,258 epoch 64 - iter 246/417 - loss 3.18864789 - samples/sec: 147.93\n",
            "2020-03-08 17:04:42,234 epoch 64 - iter 287/417 - loss 3.21571771 - samples/sec: 146.34\n",
            "2020-03-08 17:04:51,448 epoch 64 - iter 328/417 - loss 3.16767592 - samples/sec: 142.56\n",
            "2020-03-08 17:05:00,720 epoch 64 - iter 369/417 - loss 3.15299045 - samples/sec: 141.67\n",
            "2020-03-08 17:05:09,789 epoch 64 - iter 410/417 - loss 3.17028300 - samples/sec: 144.85\n",
            "2020-03-08 17:05:11,289 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:05:11,291 EPOCH 64 done: loss 3.1622 - lr 0.0500\n",
            "2020-03-08 17:05:41,378 DEV : loss 0.18714341521263123 - score 0.7206496352434347\n",
            "2020-03-08 17:05:42,818 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:05:42,819 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:05:52,259 epoch 65 - iter 41/417 - loss 3.54593772 - samples/sec: 139.04\n",
            "2020-03-08 17:06:04,744 epoch 65 - iter 82/417 - loss 3.19929362 - samples/sec: 105.19\n",
            "2020-03-08 17:06:14,159 epoch 65 - iter 123/417 - loss 3.13019657 - samples/sec: 139.49\n",
            "2020-03-08 17:06:23,431 epoch 65 - iter 164/417 - loss 3.16957380 - samples/sec: 141.70\n",
            "2020-03-08 17:06:32,691 epoch 65 - iter 205/417 - loss 3.11934244 - samples/sec: 141.85\n",
            "2020-03-08 17:06:41,749 epoch 65 - iter 246/417 - loss 3.13193216 - samples/sec: 145.02\n",
            "2020-03-08 17:06:51,057 epoch 65 - iter 287/417 - loss 3.11173442 - samples/sec: 141.11\n",
            "2020-03-08 17:07:00,327 epoch 65 - iter 328/417 - loss 3.09446899 - samples/sec: 141.71\n",
            "2020-03-08 17:07:08,859 epoch 65 - iter 369/417 - loss 3.09135651 - samples/sec: 153.98\n",
            "2020-03-08 17:07:17,477 epoch 65 - iter 410/417 - loss 3.09344189 - samples/sec: 152.44\n",
            "2020-03-08 17:07:18,909 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:07:18,911 EPOCH 65 done: loss 3.0935 - lr 0.0500\n",
            "2020-03-08 17:07:50,455 DEV : loss 0.18428194522857666 - score 0.7196183120324774\n",
            "Epoch    65: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-03-08 17:07:51,910 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:07:51,912 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:08:01,611 epoch 66 - iter 41/417 - loss 2.86195075 - samples/sec: 135.32\n",
            "2020-03-08 17:08:10,780 epoch 66 - iter 82/417 - loss 2.72731821 - samples/sec: 143.27\n",
            "2020-03-08 17:08:20,193 epoch 66 - iter 123/417 - loss 2.78874153 - samples/sec: 139.55\n",
            "2020-03-08 17:08:29,400 epoch 66 - iter 164/417 - loss 2.83840560 - samples/sec: 142.70\n",
            "2020-03-08 17:08:38,664 epoch 66 - iter 205/417 - loss 2.86302208 - samples/sec: 141.81\n",
            "2020-03-08 17:08:47,526 epoch 66 - iter 246/417 - loss 2.84481884 - samples/sec: 148.24\n",
            "2020-03-08 17:08:56,479 epoch 66 - iter 287/417 - loss 2.87397514 - samples/sec: 146.72\n",
            "2020-03-08 17:09:05,353 epoch 66 - iter 328/417 - loss 2.88803942 - samples/sec: 148.04\n",
            "2020-03-08 17:09:13,984 epoch 66 - iter 369/417 - loss 2.87610935 - samples/sec: 152.21\n",
            "2020-03-08 17:09:22,939 epoch 66 - iter 410/417 - loss 2.87826207 - samples/sec: 146.68\n",
            "2020-03-08 17:09:24,402 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:09:24,403 EPOCH 66 done: loss 2.8865 - lr 0.0250\n",
            "2020-03-08 17:09:54,655 DEV : loss 0.17913351953029633 - score 0.7249210875752424\n",
            "2020-03-08 17:09:56,124 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:09:56,125 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:10:05,041 epoch 67 - iter 41/417 - loss 2.79968131 - samples/sec: 147.22\n",
            "2020-03-08 17:10:14,413 epoch 67 - iter 82/417 - loss 2.75626914 - samples/sec: 140.20\n",
            "2020-03-08 17:10:23,723 epoch 67 - iter 123/417 - loss 2.70874186 - samples/sec: 141.10\n",
            "2020-03-08 17:10:32,813 epoch 67 - iter 164/417 - loss 2.78464181 - samples/sec: 144.54\n",
            "2020-03-08 17:10:41,584 epoch 67 - iter 205/417 - loss 2.77553947 - samples/sec: 149.77\n",
            "2020-03-08 17:10:50,289 epoch 67 - iter 246/417 - loss 2.81042668 - samples/sec: 150.91\n",
            "2020-03-08 17:10:59,302 epoch 67 - iter 287/417 - loss 2.78152169 - samples/sec: 145.77\n",
            "2020-03-08 17:11:08,392 epoch 67 - iter 328/417 - loss 2.78232915 - samples/sec: 144.52\n",
            "2020-03-08 17:11:17,312 epoch 67 - iter 369/417 - loss 2.78902371 - samples/sec: 147.27\n",
            "2020-03-08 17:11:26,179 epoch 67 - iter 410/417 - loss 2.77433038 - samples/sec: 148.16\n",
            "2020-03-08 17:11:27,689 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:11:27,691 EPOCH 67 done: loss 2.7707 - lr 0.0250\n",
            "2020-03-08 17:11:59,184 DEV : loss 0.18128135800361633 - score 0.7252671940756117\n",
            "2020-03-08 17:12:00,621 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:12:00,622 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:12:10,604 epoch 68 - iter 41/417 - loss 3.18879160 - samples/sec: 131.51\n",
            "2020-03-08 17:12:20,323 epoch 68 - iter 82/417 - loss 3.00952219 - samples/sec: 135.15\n",
            "2020-03-08 17:12:29,552 epoch 68 - iter 123/417 - loss 2.95569052 - samples/sec: 142.34\n",
            "2020-03-08 17:12:38,988 epoch 68 - iter 164/417 - loss 2.96785777 - samples/sec: 139.20\n",
            "2020-03-08 17:12:48,490 epoch 68 - iter 205/417 - loss 2.90775799 - samples/sec: 138.24\n",
            "2020-03-08 17:12:57,989 epoch 68 - iter 246/417 - loss 2.89041623 - samples/sec: 138.28\n",
            "2020-03-08 17:13:07,407 epoch 68 - iter 287/417 - loss 2.84366613 - samples/sec: 139.46\n",
            "2020-03-08 17:13:16,803 epoch 68 - iter 328/417 - loss 2.83481773 - samples/sec: 139.79\n",
            "2020-03-08 17:13:26,019 epoch 68 - iter 369/417 - loss 2.82426244 - samples/sec: 142.53\n",
            "2020-03-08 17:13:35,178 epoch 68 - iter 410/417 - loss 2.79070339 - samples/sec: 143.41\n",
            "2020-03-08 17:13:36,768 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:13:36,770 EPOCH 68 done: loss 2.7930 - lr 0.0250\n",
            "2020-03-08 17:14:09,251 DEV : loss 0.17456088960170746 - score 0.7251199092877433\n",
            "2020-03-08 17:14:10,710 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:14:10,711 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:14:20,654 epoch 69 - iter 41/417 - loss 2.55088481 - samples/sec: 132.02\n",
            "2020-03-08 17:14:30,121 epoch 69 - iter 82/417 - loss 2.65398389 - samples/sec: 138.74\n",
            "2020-03-08 17:14:39,701 epoch 69 - iter 123/417 - loss 2.65339943 - samples/sec: 137.11\n",
            "2020-03-08 17:14:48,867 epoch 69 - iter 164/417 - loss 2.65867447 - samples/sec: 143.33\n",
            "2020-03-08 17:14:57,603 epoch 69 - iter 205/417 - loss 2.63089665 - samples/sec: 150.38\n",
            "2020-03-08 17:15:06,197 epoch 69 - iter 246/417 - loss 2.62470065 - samples/sec: 152.87\n",
            "2020-03-08 17:15:15,122 epoch 69 - iter 287/417 - loss 2.60328211 - samples/sec: 147.18\n",
            "2020-03-08 17:15:24,250 epoch 69 - iter 328/417 - loss 2.64175189 - samples/sec: 143.91\n",
            "2020-03-08 17:15:33,188 epoch 69 - iter 369/417 - loss 2.64528050 - samples/sec: 146.97\n",
            "2020-03-08 17:15:41,859 epoch 69 - iter 410/417 - loss 2.66045158 - samples/sec: 151.52\n",
            "2020-03-08 17:15:43,382 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:15:43,384 EPOCH 69 done: loss 2.6550 - lr 0.0250\n",
            "2020-03-08 17:16:14,375 DEV : loss 0.1773841679096222 - score 0.7221674453011416\n",
            "Epoch    69: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-03-08 17:16:15,847 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:16:15,849 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:16:25,805 epoch 70 - iter 41/417 - loss 2.53114642 - samples/sec: 131.83\n",
            "2020-03-08 17:16:35,042 epoch 70 - iter 82/417 - loss 2.59332906 - samples/sec: 142.21\n",
            "2020-03-08 17:16:44,452 epoch 70 - iter 123/417 - loss 2.51332362 - samples/sec: 139.60\n",
            "2020-03-08 17:16:53,649 epoch 70 - iter 164/417 - loss 2.49758472 - samples/sec: 142.84\n",
            "2020-03-08 17:17:02,416 epoch 70 - iter 205/417 - loss 2.53500833 - samples/sec: 149.86\n",
            "2020-03-08 17:17:11,543 epoch 70 - iter 246/417 - loss 2.52128900 - samples/sec: 143.92\n",
            "2020-03-08 17:17:20,299 epoch 70 - iter 287/417 - loss 2.52017403 - samples/sec: 150.04\n",
            "2020-03-08 17:17:29,075 epoch 70 - iter 328/417 - loss 2.51486506 - samples/sec: 149.69\n",
            "2020-03-08 17:17:38,140 epoch 70 - iter 369/417 - loss 2.53077830 - samples/sec: 144.92\n",
            "2020-03-08 17:17:47,732 epoch 70 - iter 410/417 - loss 2.51289890 - samples/sec: 136.97\n",
            "2020-03-08 17:17:49,331 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:17:49,332 EPOCH 70 done: loss 2.5102 - lr 0.0125\n",
            "2020-03-08 17:18:20,348 DEV : loss 0.1781647950410843 - score 0.7230403509070755\n",
            "2020-03-08 17:18:21,795 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:18:21,797 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:18:31,311 epoch 71 - iter 41/417 - loss 2.29265234 - samples/sec: 137.95\n",
            "2020-03-08 17:18:40,559 epoch 71 - iter 82/417 - loss 2.34888880 - samples/sec: 142.04\n",
            "2020-03-08 17:18:49,836 epoch 71 - iter 123/417 - loss 2.48401522 - samples/sec: 141.59\n",
            "2020-03-08 17:18:59,254 epoch 71 - iter 164/417 - loss 2.50324989 - samples/sec: 139.47\n",
            "2020-03-08 17:19:08,219 epoch 71 - iter 205/417 - loss 2.51515708 - samples/sec: 146.51\n",
            "2020-03-08 17:19:17,189 epoch 71 - iter 246/417 - loss 2.46772531 - samples/sec: 146.44\n",
            "2020-03-08 17:19:26,113 epoch 71 - iter 287/417 - loss 2.45721050 - samples/sec: 147.21\n",
            "2020-03-08 17:19:35,158 epoch 71 - iter 328/417 - loss 2.44440132 - samples/sec: 145.24\n",
            "2020-03-08 17:19:43,792 epoch 71 - iter 369/417 - loss 2.46910355 - samples/sec: 152.16\n",
            "2020-03-08 17:19:52,613 epoch 71 - iter 410/417 - loss 2.47890162 - samples/sec: 148.90\n",
            "2020-03-08 17:19:54,045 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:19:54,046 EPOCH 71 done: loss 2.4704 - lr 0.0125\n",
            "2020-03-08 17:20:23,652 DEV : loss 0.1703624278306961 - score 0.7286783163066887\n",
            "2020-03-08 17:20:25,108 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:20:25,109 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:20:34,594 epoch 72 - iter 41/417 - loss 2.60540583 - samples/sec: 138.39\n",
            "2020-03-08 17:20:43,911 epoch 72 - iter 82/417 - loss 2.57704930 - samples/sec: 140.99\n",
            "2020-03-08 17:20:53,191 epoch 72 - iter 123/417 - loss 2.55328403 - samples/sec: 141.56\n",
            "2020-03-08 17:21:01,773 epoch 72 - iter 164/417 - loss 2.51103544 - samples/sec: 153.06\n",
            "2020-03-08 17:21:10,854 epoch 72 - iter 205/417 - loss 2.49253081 - samples/sec: 144.65\n",
            "2020-03-08 17:21:19,969 epoch 72 - iter 246/417 - loss 2.51042249 - samples/sec: 144.12\n",
            "2020-03-08 17:21:28,814 epoch 72 - iter 287/417 - loss 2.49130843 - samples/sec: 148.52\n",
            "2020-03-08 17:21:37,656 epoch 72 - iter 328/417 - loss 2.50331351 - samples/sec: 148.57\n",
            "2020-03-08 17:21:46,363 epoch 72 - iter 369/417 - loss 2.49110449 - samples/sec: 150.88\n",
            "2020-03-08 17:21:58,387 epoch 72 - iter 410/417 - loss 2.49241191 - samples/sec: 109.21\n",
            "2020-03-08 17:21:59,969 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:21:59,971 EPOCH 72 done: loss 2.4963 - lr 0.0125\n",
            "2020-03-08 17:22:32,032 DEV : loss 0.17948636412620544 - score 0.7257065210686526\n",
            "2020-03-08 17:22:33,457 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:22:33,458 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:22:42,731 epoch 73 - iter 41/417 - loss 2.36065957 - samples/sec: 141.56\n",
            "2020-03-08 17:22:51,837 epoch 73 - iter 82/417 - loss 2.48542068 - samples/sec: 144.28\n",
            "2020-03-08 17:23:00,841 epoch 73 - iter 123/417 - loss 2.39943728 - samples/sec: 145.89\n",
            "2020-03-08 17:23:09,962 epoch 73 - iter 164/417 - loss 2.39896917 - samples/sec: 144.02\n",
            "2020-03-08 17:23:18,827 epoch 73 - iter 205/417 - loss 2.43066429 - samples/sec: 148.19\n",
            "2020-03-08 17:23:27,750 epoch 73 - iter 246/417 - loss 2.44482476 - samples/sec: 147.23\n",
            "2020-03-08 17:23:36,811 epoch 73 - iter 287/417 - loss 2.44310500 - samples/sec: 144.96\n",
            "2020-03-08 17:23:45,541 epoch 73 - iter 328/417 - loss 2.45375196 - samples/sec: 150.50\n",
            "2020-03-08 17:23:54,090 epoch 73 - iter 369/417 - loss 2.43352489 - samples/sec: 153.69\n",
            "2020-03-08 17:24:02,642 epoch 73 - iter 410/417 - loss 2.44047341 - samples/sec: 153.61\n",
            "2020-03-08 17:24:04,118 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:24:04,119 EPOCH 73 done: loss 2.4362 - lr 0.0125\n",
            "2020-03-08 17:24:34,498 DEV : loss 0.1727869063615799 - score 0.7275355743151434\n",
            "Epoch    73: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2020-03-08 17:24:35,939 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:24:35,940 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:24:45,536 epoch 74 - iter 41/417 - loss 2.44241435 - samples/sec: 136.78\n",
            "2020-03-08 17:24:54,901 epoch 74 - iter 82/417 - loss 2.32945110 - samples/sec: 140.27\n",
            "2020-03-08 17:25:04,225 epoch 74 - iter 123/417 - loss 2.32845629 - samples/sec: 140.87\n",
            "2020-03-08 17:25:13,259 epoch 74 - iter 164/417 - loss 2.35805050 - samples/sec: 145.42\n",
            "2020-03-08 17:25:22,163 epoch 74 - iter 205/417 - loss 2.35376404 - samples/sec: 147.52\n",
            "2020-03-08 17:25:30,828 epoch 74 - iter 246/417 - loss 2.39664965 - samples/sec: 151.62\n",
            "2020-03-08 17:25:39,650 epoch 74 - iter 287/417 - loss 2.38882552 - samples/sec: 148.91\n",
            "2020-03-08 17:25:48,287 epoch 74 - iter 328/417 - loss 2.38513601 - samples/sec: 152.10\n",
            "2020-03-08 17:25:56,844 epoch 74 - iter 369/417 - loss 2.36249819 - samples/sec: 153.54\n",
            "2020-03-08 17:26:06,010 epoch 74 - iter 410/417 - loss 2.39177690 - samples/sec: 143.30\n",
            "2020-03-08 17:26:07,510 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:26:07,511 EPOCH 74 done: loss 2.4001 - lr 0.0063\n",
            "2020-03-08 17:26:37,551 DEV : loss 0.17622677981853485 - score 0.7264287241873942\n",
            "2020-03-08 17:26:38,974 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:26:38,975 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:26:48,052 epoch 75 - iter 41/417 - loss 2.28492959 - samples/sec: 144.60\n",
            "2020-03-08 17:26:56,961 epoch 75 - iter 82/417 - loss 2.29743227 - samples/sec: 147.47\n",
            "2020-03-08 17:27:06,146 epoch 75 - iter 123/417 - loss 2.25464788 - samples/sec: 143.00\n",
            "2020-03-08 17:27:15,071 epoch 75 - iter 164/417 - loss 2.25183782 - samples/sec: 147.20\n",
            "2020-03-08 17:27:23,561 epoch 75 - iter 205/417 - loss 2.28735410 - samples/sec: 154.70\n",
            "2020-03-08 17:27:31,943 epoch 75 - iter 246/417 - loss 2.31209127 - samples/sec: 156.74\n",
            "2020-03-08 17:27:40,795 epoch 75 - iter 287/417 - loss 2.30292309 - samples/sec: 148.40\n",
            "2020-03-08 17:27:50,027 epoch 75 - iter 328/417 - loss 2.31080350 - samples/sec: 142.27\n",
            "2020-03-08 17:27:59,652 epoch 75 - iter 369/417 - loss 2.33563852 - samples/sec: 136.47\n",
            "2020-03-08 17:28:09,229 epoch 75 - iter 410/417 - loss 2.33003920 - samples/sec: 137.15\n",
            "2020-03-08 17:28:10,703 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:28:10,704 EPOCH 75 done: loss 2.3431 - lr 0.0063\n",
            "2020-03-08 17:28:40,939 DEV : loss 0.17170675098896027 - score 0.7278884350175435\n",
            "2020-03-08 17:28:42,437 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:28:42,438 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:28:52,213 epoch 76 - iter 41/417 - loss 2.02844642 - samples/sec: 134.29\n",
            "2020-03-08 17:29:01,730 epoch 76 - iter 82/417 - loss 2.14464234 - samples/sec: 138.01\n",
            "2020-03-08 17:29:11,207 epoch 76 - iter 123/417 - loss 2.20524062 - samples/sec: 138.60\n",
            "2020-03-08 17:29:20,024 epoch 76 - iter 164/417 - loss 2.18969052 - samples/sec: 149.00\n",
            "2020-03-08 17:29:29,143 epoch 76 - iter 205/417 - loss 2.23181373 - samples/sec: 144.04\n",
            "2020-03-08 17:29:38,450 epoch 76 - iter 246/417 - loss 2.24331120 - samples/sec: 141.15\n",
            "2020-03-08 17:29:47,578 epoch 76 - iter 287/417 - loss 2.24033643 - samples/sec: 143.91\n",
            "2020-03-08 17:29:56,310 epoch 76 - iter 328/417 - loss 2.22322350 - samples/sec: 150.45\n",
            "2020-03-08 17:30:04,921 epoch 76 - iter 369/417 - loss 2.22691273 - samples/sec: 152.54\n",
            "2020-03-08 17:30:14,020 epoch 76 - iter 410/417 - loss 2.24936948 - samples/sec: 144.39\n",
            "2020-03-08 17:30:15,493 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:30:15,494 EPOCH 76 done: loss 2.2505 - lr 0.0063\n",
            "2020-03-08 17:30:47,426 DEV : loss 0.16823036968708038 - score 0.7276452329758794\n",
            "2020-03-08 17:30:48,891 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:30:48,893 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:30:58,343 epoch 77 - iter 41/417 - loss 2.43998685 - samples/sec: 138.90\n",
            "2020-03-08 17:31:07,664 epoch 77 - iter 82/417 - loss 2.33971462 - samples/sec: 140.95\n",
            "2020-03-08 17:31:17,007 epoch 77 - iter 123/417 - loss 2.37772669 - samples/sec: 140.59\n",
            "2020-03-08 17:31:26,073 epoch 77 - iter 164/417 - loss 2.33435264 - samples/sec: 144.88\n",
            "2020-03-08 17:31:35,198 epoch 77 - iter 205/417 - loss 2.32578344 - samples/sec: 143.98\n",
            "2020-03-08 17:31:43,857 epoch 77 - iter 246/417 - loss 2.31162495 - samples/sec: 151.71\n",
            "2020-03-08 17:31:52,452 epoch 77 - iter 287/417 - loss 2.33134633 - samples/sec: 152.87\n",
            "2020-03-08 17:32:00,966 epoch 77 - iter 328/417 - loss 2.31719230 - samples/sec: 154.33\n",
            "2020-03-08 17:32:09,613 epoch 77 - iter 369/417 - loss 2.31647694 - samples/sec: 151.93\n",
            "2020-03-08 17:32:18,324 epoch 77 - iter 410/417 - loss 2.31009993 - samples/sec: 150.83\n",
            "2020-03-08 17:32:19,805 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:32:19,807 EPOCH 77 done: loss 2.3111 - lr 0.0063\n",
            "2020-03-08 17:32:48,815 DEV : loss 0.17323674261569977 - score 0.7278014302636328\n",
            "Epoch    77: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2020-03-08 17:32:50,257 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:32:50,258 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:32:59,206 epoch 78 - iter 41/417 - loss 2.32073919 - samples/sec: 146.68\n",
            "2020-03-08 17:33:08,416 epoch 78 - iter 82/417 - loss 2.32194551 - samples/sec: 142.63\n",
            "2020-03-08 17:33:17,428 epoch 78 - iter 123/417 - loss 2.23024077 - samples/sec: 145.77\n",
            "2020-03-08 17:33:26,583 epoch 78 - iter 164/417 - loss 2.21985584 - samples/sec: 143.52\n",
            "2020-03-08 17:33:35,271 epoch 78 - iter 205/417 - loss 2.22632013 - samples/sec: 151.24\n",
            "2020-03-08 17:33:44,166 epoch 78 - iter 246/417 - loss 2.24107580 - samples/sec: 147.68\n",
            "2020-03-08 17:33:53,557 epoch 78 - iter 287/417 - loss 2.22217725 - samples/sec: 139.88\n",
            "2020-03-08 17:34:02,999 epoch 78 - iter 328/417 - loss 2.24942444 - samples/sec: 139.14\n",
            "2020-03-08 17:34:12,030 epoch 78 - iter 369/417 - loss 2.27646561 - samples/sec: 145.46\n",
            "2020-03-08 17:34:20,619 epoch 78 - iter 410/417 - loss 2.27081239 - samples/sec: 152.97\n",
            "2020-03-08 17:34:22,073 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:34:22,075 EPOCH 78 done: loss 2.2605 - lr 0.0031\n",
            "2020-03-08 17:34:52,683 DEV : loss 0.17405761778354645 - score 0.7275222619842859\n",
            "2020-03-08 17:34:54,130 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:34:54,131 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:35:03,858 epoch 79 - iter 41/417 - loss 2.20149794 - samples/sec: 134.95\n",
            "2020-03-08 17:35:13,264 epoch 79 - iter 82/417 - loss 2.26047230 - samples/sec: 139.64\n",
            "2020-03-08 17:35:22,514 epoch 79 - iter 123/417 - loss 2.21397429 - samples/sec: 142.00\n",
            "2020-03-08 17:35:31,673 epoch 79 - iter 164/417 - loss 2.29238784 - samples/sec: 143.41\n",
            "2020-03-08 17:35:41,222 epoch 79 - iter 205/417 - loss 2.30090457 - samples/sec: 137.56\n",
            "2020-03-08 17:35:50,578 epoch 79 - iter 246/417 - loss 2.29666503 - samples/sec: 140.39\n",
            "2020-03-08 17:35:59,761 epoch 79 - iter 287/417 - loss 2.31041364 - samples/sec: 143.05\n",
            "2020-03-08 17:36:08,540 epoch 79 - iter 328/417 - loss 2.29065112 - samples/sec: 149.64\n",
            "2020-03-08 17:36:17,541 epoch 79 - iter 369/417 - loss 2.29551101 - samples/sec: 145.95\n",
            "2020-03-08 17:36:26,903 epoch 79 - iter 410/417 - loss 2.27237212 - samples/sec: 140.33\n",
            "2020-03-08 17:36:28,502 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:36:28,503 EPOCH 79 done: loss 2.2701 - lr 0.0031\n",
            "2020-03-08 17:37:00,377 DEV : loss 0.17513446509838104 - score 0.7273183953431904\n",
            "2020-03-08 17:37:01,825 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:37:01,826 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:37:11,353 epoch 80 - iter 41/417 - loss 2.22511255 - samples/sec: 137.76\n",
            "2020-03-08 17:37:20,755 epoch 80 - iter 82/417 - loss 2.21409008 - samples/sec: 139.69\n",
            "2020-03-08 17:37:29,947 epoch 80 - iter 123/417 - loss 2.19716096 - samples/sec: 142.92\n",
            "2020-03-08 17:37:42,583 epoch 80 - iter 164/417 - loss 2.18875349 - samples/sec: 103.91\n",
            "2020-03-08 17:37:52,094 epoch 80 - iter 205/417 - loss 2.19129525 - samples/sec: 138.12\n",
            "2020-03-08 17:38:01,231 epoch 80 - iter 246/417 - loss 2.17228239 - samples/sec: 143.76\n",
            "2020-03-08 17:38:10,111 epoch 80 - iter 287/417 - loss 2.20009635 - samples/sec: 147.93\n",
            "2020-03-08 17:38:18,463 epoch 80 - iter 328/417 - loss 2.20207813 - samples/sec: 157.27\n",
            "2020-03-08 17:38:27,071 epoch 80 - iter 369/417 - loss 2.19702888 - samples/sec: 152.60\n",
            "2020-03-08 17:38:36,404 epoch 80 - iter 410/417 - loss 2.20551379 - samples/sec: 140.76\n",
            "2020-03-08 17:38:37,881 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:38:37,882 EPOCH 80 done: loss 2.2155 - lr 0.0031\n",
            "2020-03-08 17:39:07,381 DEV : loss 0.17358653247356415 - score 0.7274357267046897\n",
            "2020-03-08 17:39:08,802 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:39:08,803 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:39:17,925 epoch 81 - iter 41/417 - loss 2.27921227 - samples/sec: 143.90\n",
            "2020-03-08 17:39:26,823 epoch 81 - iter 82/417 - loss 2.20490712 - samples/sec: 147.62\n",
            "2020-03-08 17:39:35,723 epoch 81 - iter 123/417 - loss 2.20486963 - samples/sec: 147.60\n",
            "2020-03-08 17:39:44,627 epoch 81 - iter 164/417 - loss 2.17767433 - samples/sec: 147.53\n",
            "2020-03-08 17:39:53,426 epoch 81 - iter 205/417 - loss 2.21171310 - samples/sec: 149.32\n",
            "2020-03-08 17:40:02,289 epoch 81 - iter 246/417 - loss 2.21937313 - samples/sec: 148.21\n",
            "2020-03-08 17:40:11,270 epoch 81 - iter 287/417 - loss 2.21541564 - samples/sec: 146.25\n",
            "2020-03-08 17:40:20,053 epoch 81 - iter 328/417 - loss 2.21319423 - samples/sec: 149.56\n",
            "2020-03-08 17:40:28,666 epoch 81 - iter 369/417 - loss 2.23921261 - samples/sec: 152.52\n",
            "2020-03-08 17:40:37,327 epoch 81 - iter 410/417 - loss 2.22360076 - samples/sec: 151.68\n",
            "2020-03-08 17:40:38,782 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:40:38,784 EPOCH 81 done: loss 2.2346 - lr 0.0031\n",
            "2020-03-08 17:41:10,299 DEV : loss 0.1753554344177246 - score 0.7265561912274826\n",
            "Epoch    81: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2020-03-08 17:41:11,733 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:41:11,734 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:41:21,169 epoch 82 - iter 41/417 - loss 2.30216627 - samples/sec: 139.12\n",
            "2020-03-08 17:41:30,282 epoch 82 - iter 82/417 - loss 2.28622073 - samples/sec: 144.15\n",
            "2020-03-08 17:41:39,412 epoch 82 - iter 123/417 - loss 2.21016387 - samples/sec: 143.88\n",
            "2020-03-08 17:41:49,120 epoch 82 - iter 164/417 - loss 2.26037537 - samples/sec: 135.29\n",
            "2020-03-08 17:41:58,579 epoch 82 - iter 205/417 - loss 2.26550583 - samples/sec: 138.85\n",
            "2020-03-08 17:42:07,643 epoch 82 - iter 246/417 - loss 2.25072018 - samples/sec: 144.93\n",
            "2020-03-08 17:42:16,545 epoch 82 - iter 287/417 - loss 2.26688867 - samples/sec: 147.56\n",
            "2020-03-08 17:42:25,418 epoch 82 - iter 328/417 - loss 2.29684100 - samples/sec: 148.05\n",
            "2020-03-08 17:42:34,449 epoch 82 - iter 369/417 - loss 2.28744233 - samples/sec: 145.43\n",
            "2020-03-08 17:42:43,589 epoch 82 - iter 410/417 - loss 2.25262058 - samples/sec: 143.73\n",
            "2020-03-08 17:42:45,025 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:42:45,027 EPOCH 82 done: loss 2.2584 - lr 0.0016\n",
            "2020-03-08 17:43:14,976 DEV : loss 0.17225489020347595 - score 0.7266748147217786\n",
            "2020-03-08 17:43:16,416 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:43:16,417 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:43:26,155 epoch 83 - iter 41/417 - loss 2.47658283 - samples/sec: 134.79\n",
            "2020-03-08 17:43:35,115 epoch 83 - iter 82/417 - loss 2.33451201 - samples/sec: 146.62\n",
            "2020-03-08 17:43:43,997 epoch 83 - iter 123/417 - loss 2.24519621 - samples/sec: 147.91\n",
            "2020-03-08 17:43:52,943 epoch 83 - iter 164/417 - loss 2.22470864 - samples/sec: 146.85\n",
            "2020-03-08 17:44:02,053 epoch 83 - iter 205/417 - loss 2.25050184 - samples/sec: 144.20\n",
            "2020-03-08 17:44:10,897 epoch 83 - iter 246/417 - loss 2.19544034 - samples/sec: 148.55\n",
            "2020-03-08 17:44:20,218 epoch 83 - iter 287/417 - loss 2.21001997 - samples/sec: 140.90\n",
            "2020-03-08 17:44:29,420 epoch 83 - iter 328/417 - loss 2.18878090 - samples/sec: 142.76\n",
            "2020-03-08 17:44:38,589 epoch 83 - iter 369/417 - loss 2.20198771 - samples/sec: 143.28\n",
            "2020-03-08 17:44:47,465 epoch 83 - iter 410/417 - loss 2.20513898 - samples/sec: 148.01\n",
            "2020-03-08 17:44:48,919 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:44:48,921 EPOCH 83 done: loss 2.2197 - lr 0.0016\n",
            "2020-03-08 17:45:20,243 DEV : loss 0.1737077534198761 - score 0.7269943091954394\n",
            "2020-03-08 17:45:21,677 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:45:21,678 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:45:31,524 epoch 84 - iter 41/417 - loss 2.23197607 - samples/sec: 133.32\n",
            "2020-03-08 17:45:40,498 epoch 84 - iter 82/417 - loss 2.28632678 - samples/sec: 146.38\n",
            "2020-03-08 17:45:49,488 epoch 84 - iter 123/417 - loss 2.33166063 - samples/sec: 146.13\n",
            "2020-03-08 17:45:58,656 epoch 84 - iter 164/417 - loss 2.32479705 - samples/sec: 143.25\n",
            "2020-03-08 17:46:07,926 epoch 84 - iter 205/417 - loss 2.30908509 - samples/sec: 141.73\n",
            "2020-03-08 17:46:17,560 epoch 84 - iter 246/417 - loss 2.28735170 - samples/sec: 136.38\n",
            "2020-03-08 17:46:26,551 epoch 84 - iter 287/417 - loss 2.29748844 - samples/sec: 146.11\n",
            "2020-03-08 17:46:35,364 epoch 84 - iter 328/417 - loss 2.29413401 - samples/sec: 149.07\n",
            "2020-03-08 17:46:44,035 epoch 84 - iter 369/417 - loss 2.28393330 - samples/sec: 151.49\n",
            "2020-03-08 17:46:52,973 epoch 84 - iter 410/417 - loss 2.25609213 - samples/sec: 146.95\n",
            "2020-03-08 17:46:54,446 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:46:54,447 EPOCH 84 done: loss 2.2525 - lr 0.0016\n",
            "2020-03-08 17:47:23,921 DEV : loss 0.17190751433372498 - score 0.727298768597787\n",
            "2020-03-08 17:47:25,382 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:47:25,383 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:47:34,209 epoch 85 - iter 41/417 - loss 2.01552275 - samples/sec: 148.74\n",
            "2020-03-08 17:47:43,461 epoch 85 - iter 82/417 - loss 2.06191869 - samples/sec: 141.99\n",
            "2020-03-08 17:47:52,802 epoch 85 - iter 123/417 - loss 2.13005818 - samples/sec: 140.67\n",
            "2020-03-08 17:48:02,021 epoch 85 - iter 164/417 - loss 2.20466960 - samples/sec: 142.49\n",
            "2020-03-08 17:48:11,080 epoch 85 - iter 205/417 - loss 2.21738878 - samples/sec: 145.02\n",
            "2020-03-08 17:48:19,885 epoch 85 - iter 246/417 - loss 2.24045050 - samples/sec: 149.18\n",
            "2020-03-08 17:48:28,490 epoch 85 - iter 287/417 - loss 2.22682856 - samples/sec: 152.66\n",
            "2020-03-08 17:48:37,615 epoch 85 - iter 328/417 - loss 2.21293163 - samples/sec: 143.96\n",
            "2020-03-08 17:48:46,912 epoch 85 - iter 369/417 - loss 2.21751892 - samples/sec: 141.30\n",
            "2020-03-08 17:48:55,914 epoch 85 - iter 410/417 - loss 2.20506002 - samples/sec: 145.93\n",
            "2020-03-08 17:48:57,434 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:48:57,435 EPOCH 85 done: loss 2.2054 - lr 0.0016\n",
            "2020-03-08 17:49:28,296 DEV : loss 0.17400529980659485 - score 0.7274931372653963\n",
            "Epoch    85: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2020-03-08 17:49:29,769 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:49:29,770 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:49:39,466 epoch 86 - iter 41/417 - loss 2.22221109 - samples/sec: 135.39\n",
            "2020-03-08 17:49:48,710 epoch 86 - iter 82/417 - loss 2.26932566 - samples/sec: 142.08\n",
            "2020-03-08 17:49:57,719 epoch 86 - iter 123/417 - loss 2.33260150 - samples/sec: 145.80\n",
            "2020-03-08 17:50:06,959 epoch 86 - iter 164/417 - loss 2.24611281 - samples/sec: 142.14\n",
            "2020-03-08 17:50:16,050 epoch 86 - iter 205/417 - loss 2.22317790 - samples/sec: 144.50\n",
            "2020-03-08 17:50:25,029 epoch 86 - iter 246/417 - loss 2.21006881 - samples/sec: 146.29\n",
            "2020-03-08 17:50:34,200 epoch 86 - iter 287/417 - loss 2.22872566 - samples/sec: 143.23\n",
            "2020-03-08 17:50:42,811 epoch 86 - iter 328/417 - loss 2.23403616 - samples/sec: 152.58\n",
            "2020-03-08 17:50:51,392 epoch 86 - iter 369/417 - loss 2.24797410 - samples/sec: 153.07\n",
            "2020-03-08 17:51:00,614 epoch 86 - iter 410/417 - loss 2.23657403 - samples/sec: 142.45\n",
            "2020-03-08 17:51:02,104 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:51:02,105 EPOCH 86 done: loss 2.2374 - lr 0.0008\n",
            "2020-03-08 17:51:32,131 DEV : loss 0.17285622656345367 - score 0.7273491443627275\n",
            "2020-03-08 17:51:33,568 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:51:33,569 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:51:42,827 epoch 87 - iter 41/417 - loss 2.22800860 - samples/sec: 141.79\n",
            "2020-03-08 17:51:52,142 epoch 87 - iter 82/417 - loss 2.22110849 - samples/sec: 141.03\n",
            "2020-03-08 17:52:01,066 epoch 87 - iter 123/417 - loss 2.19506826 - samples/sec: 147.21\n",
            "2020-03-08 17:52:10,119 epoch 87 - iter 164/417 - loss 2.23917179 - samples/sec: 145.13\n",
            "2020-03-08 17:52:18,968 epoch 87 - iter 205/417 - loss 2.20047423 - samples/sec: 148.44\n",
            "2020-03-08 17:52:27,846 epoch 87 - iter 246/417 - loss 2.20881117 - samples/sec: 147.95\n",
            "2020-03-08 17:52:37,138 epoch 87 - iter 287/417 - loss 2.18298666 - samples/sec: 141.36\n",
            "2020-03-08 17:52:46,793 epoch 87 - iter 328/417 - loss 2.18141055 - samples/sec: 136.04\n",
            "2020-03-08 17:52:56,393 epoch 87 - iter 369/417 - loss 2.18620126 - samples/sec: 136.83\n",
            "2020-03-08 17:53:05,792 epoch 87 - iter 410/417 - loss 2.21621561 - samples/sec: 139.76\n",
            "2020-03-08 17:53:07,254 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:53:07,255 EPOCH 87 done: loss 2.2207 - lr 0.0008\n",
            "2020-03-08 17:53:42,326 DEV : loss 0.17352350056171417 - score 0.727645381946515\n",
            "2020-03-08 17:53:43,761 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:53:43,763 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:53:53,400 epoch 88 - iter 41/417 - loss 2.31872446 - samples/sec: 136.20\n",
            "2020-03-08 17:54:02,842 epoch 88 - iter 82/417 - loss 2.27052755 - samples/sec: 139.12\n",
            "2020-03-08 17:54:12,305 epoch 88 - iter 123/417 - loss 2.19341916 - samples/sec: 138.80\n",
            "2020-03-08 17:54:21,605 epoch 88 - iter 164/417 - loss 2.14105361 - samples/sec: 141.24\n",
            "2020-03-08 17:54:30,661 epoch 88 - iter 205/417 - loss 2.12679014 - samples/sec: 145.04\n",
            "2020-03-08 17:54:39,898 epoch 88 - iter 246/417 - loss 2.14675896 - samples/sec: 142.23\n",
            "2020-03-08 17:54:48,795 epoch 88 - iter 287/417 - loss 2.16991569 - samples/sec: 147.66\n",
            "2020-03-08 17:54:57,909 epoch 88 - iter 328/417 - loss 2.17926684 - samples/sec: 144.12\n",
            "2020-03-08 17:55:07,279 epoch 88 - iter 369/417 - loss 2.20659579 - samples/sec: 140.20\n",
            "2020-03-08 17:55:16,572 epoch 88 - iter 410/417 - loss 2.20060412 - samples/sec: 141.35\n",
            "2020-03-08 17:55:18,046 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:55:18,047 EPOCH 88 done: loss 2.1980 - lr 0.0008\n",
            "2020-03-08 17:55:47,981 DEV : loss 0.1729273796081543 - score 0.7269024659674866\n",
            "2020-03-08 17:55:49,427 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:55:49,428 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:55:59,299 epoch 89 - iter 41/417 - loss 2.31185820 - samples/sec: 132.97\n",
            "2020-03-08 17:56:08,927 epoch 89 - iter 82/417 - loss 2.29851822 - samples/sec: 136.43\n",
            "2020-03-08 17:56:18,091 epoch 89 - iter 123/417 - loss 2.28470211 - samples/sec: 143.36\n",
            "2020-03-08 17:56:27,094 epoch 89 - iter 164/417 - loss 2.29280250 - samples/sec: 145.89\n",
            "2020-03-08 17:56:36,160 epoch 89 - iter 205/417 - loss 2.25848206 - samples/sec: 144.89\n",
            "2020-03-08 17:56:45,555 epoch 89 - iter 246/417 - loss 2.24214171 - samples/sec: 139.82\n",
            "2020-03-08 17:56:54,433 epoch 89 - iter 287/417 - loss 2.24958594 - samples/sec: 147.98\n",
            "2020-03-08 17:57:03,283 epoch 89 - iter 328/417 - loss 2.24761032 - samples/sec: 148.45\n",
            "2020-03-08 17:57:11,930 epoch 89 - iter 369/417 - loss 2.26227904 - samples/sec: 151.94\n",
            "2020-03-08 17:57:20,778 epoch 89 - iter 410/417 - loss 2.26921841 - samples/sec: 148.46\n",
            "2020-03-08 17:57:22,355 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:57:22,356 EPOCH 89 done: loss 2.2600 - lr 0.0008\n",
            "2020-03-08 17:57:54,377 DEV : loss 0.1730290949344635 - score 0.7269465859715899\n",
            "Epoch    89: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2020-03-08 17:57:55,836 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:57:55,837 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:58:05,322 epoch 90 - iter 41/417 - loss 2.32041502 - samples/sec: 138.37\n",
            "2020-03-08 17:58:14,507 epoch 90 - iter 82/417 - loss 2.15863553 - samples/sec: 143.02\n",
            "2020-03-08 17:58:23,828 epoch 90 - iter 123/417 - loss 2.14120113 - samples/sec: 140.94\n",
            "2020-03-08 17:58:32,980 epoch 90 - iter 164/417 - loss 2.13496157 - samples/sec: 143.54\n",
            "2020-03-08 17:58:41,802 epoch 90 - iter 205/417 - loss 2.14979658 - samples/sec: 148.91\n",
            "2020-03-08 17:58:50,590 epoch 90 - iter 246/417 - loss 2.18428976 - samples/sec: 149.49\n",
            "2020-03-08 17:58:59,537 epoch 90 - iter 287/417 - loss 2.20966153 - samples/sec: 146.83\n",
            "2020-03-08 17:59:08,320 epoch 90 - iter 328/417 - loss 2.19816567 - samples/sec: 149.56\n",
            "2020-03-08 17:59:17,104 epoch 90 - iter 369/417 - loss 2.18878818 - samples/sec: 149.53\n",
            "2020-03-08 17:59:26,147 epoch 90 - iter 410/417 - loss 2.18067904 - samples/sec: 145.26\n",
            "2020-03-08 17:59:27,607 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:59:27,608 EPOCH 90 done: loss 2.1809 - lr 0.0004\n",
            "2020-03-08 17:59:58,545 DEV : loss 0.17357216775417328 - score 0.727068479350323\n",
            "2020-03-08 17:59:59,984 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:59:59,985 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:00:09,743 epoch 91 - iter 41/417 - loss 2.29714934 - samples/sec: 134.51\n",
            "2020-03-08 18:00:19,227 epoch 91 - iter 82/417 - loss 2.27615081 - samples/sec: 138.50\n",
            "2020-03-08 18:00:28,558 epoch 91 - iter 123/417 - loss 2.26833945 - samples/sec: 140.77\n",
            "2020-03-08 18:00:38,114 epoch 91 - iter 164/417 - loss 2.21757513 - samples/sec: 137.45\n",
            "2020-03-08 18:00:47,341 epoch 91 - iter 205/417 - loss 2.26574230 - samples/sec: 142.36\n",
            "2020-03-08 18:00:56,397 epoch 91 - iter 246/417 - loss 2.23281085 - samples/sec: 145.04\n",
            "2020-03-08 18:01:05,430 epoch 91 - iter 287/417 - loss 2.24219292 - samples/sec: 145.43\n",
            "2020-03-08 18:01:14,304 epoch 91 - iter 328/417 - loss 2.20957583 - samples/sec: 148.03\n",
            "2020-03-08 18:01:23,088 epoch 91 - iter 369/417 - loss 2.23204178 - samples/sec: 149.52\n",
            "2020-03-08 18:01:32,046 epoch 91 - iter 410/417 - loss 2.23630796 - samples/sec: 146.63\n",
            "2020-03-08 18:01:33,560 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:01:33,561 EPOCH 91 done: loss 2.2309 - lr 0.0004\n",
            "2020-03-08 18:02:05,204 DEV : loss 0.17335009574890137 - score 0.7270984703770812\n",
            "2020-03-08 18:02:06,621 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 18:02:06,623 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:02:16,346 epoch 92 - iter 41/417 - loss 2.40016586 - samples/sec: 134.99\n",
            "2020-03-08 18:02:25,492 epoch 92 - iter 82/417 - loss 2.27118635 - samples/sec: 143.64\n",
            "2020-03-08 18:02:34,823 epoch 92 - iter 123/417 - loss 2.27406649 - samples/sec: 140.76\n",
            "2020-03-08 18:02:43,672 epoch 92 - iter 164/417 - loss 2.22846677 - samples/sec: 148.45\n",
            "2020-03-08 18:02:53,016 epoch 92 - iter 205/417 - loss 2.20959763 - samples/sec: 140.57\n",
            "2020-03-08 18:03:01,616 epoch 92 - iter 246/417 - loss 2.21432077 - samples/sec: 152.79\n",
            "2020-03-08 18:03:10,417 epoch 92 - iter 287/417 - loss 2.18917620 - samples/sec: 149.26\n",
            "2020-03-08 18:03:19,163 epoch 92 - iter 328/417 - loss 2.18450856 - samples/sec: 150.19\n",
            "2020-03-08 18:03:28,414 epoch 92 - iter 369/417 - loss 2.19404441 - samples/sec: 142.03\n",
            "2020-03-08 18:03:37,982 epoch 92 - iter 410/417 - loss 2.20091965 - samples/sec: 137.29\n",
            "2020-03-08 18:03:39,576 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:03:39,578 EPOCH 92 done: loss 2.2062 - lr 0.0004\n",
            "2020-03-08 18:04:09,771 DEV : loss 0.17350688576698303 - score 0.7270799514885967\n",
            "2020-03-08 18:04:11,259 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 18:04:11,260 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:04:20,831 epoch 93 - iter 41/417 - loss 2.10506198 - samples/sec: 137.14\n",
            "2020-03-08 18:04:30,137 epoch 93 - iter 82/417 - loss 2.09005762 - samples/sec: 141.18\n",
            "2020-03-08 18:04:39,388 epoch 93 - iter 123/417 - loss 2.08159355 - samples/sec: 141.96\n",
            "2020-03-08 18:04:48,458 epoch 93 - iter 164/417 - loss 2.10014232 - samples/sec: 144.83\n",
            "2020-03-08 18:04:57,344 epoch 93 - iter 205/417 - loss 2.13345767 - samples/sec: 147.82\n",
            "2020-03-08 18:05:06,736 epoch 93 - iter 246/417 - loss 2.14598880 - samples/sec: 139.85\n",
            "2020-03-08 18:05:15,713 epoch 93 - iter 287/417 - loss 2.14642467 - samples/sec: 146.32\n",
            "2020-03-08 18:05:24,702 epoch 93 - iter 328/417 - loss 2.16608010 - samples/sec: 146.15\n",
            "2020-03-08 18:05:33,748 epoch 93 - iter 369/417 - loss 2.14914640 - samples/sec: 145.21\n",
            "2020-03-08 18:05:42,598 epoch 93 - iter 410/417 - loss 2.16578396 - samples/sec: 148.46\n",
            "2020-03-08 18:05:44,094 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:05:44,095 EPOCH 93 done: loss 2.1661 - lr 0.0004\n",
            "2020-03-08 18:06:15,909 DEV : loss 0.1740618646144867 - score 0.7270494025622251\n",
            "Epoch    93: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2020-03-08 18:06:17,355 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 18:06:17,356 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:06:27,357 epoch 94 - iter 41/417 - loss 2.19741726 - samples/sec: 131.24\n",
            "2020-03-08 18:06:36,470 epoch 94 - iter 82/417 - loss 2.10878953 - samples/sec: 144.16\n",
            "2020-03-08 18:06:45,594 epoch 94 - iter 123/417 - loss 2.29399244 - samples/sec: 143.99\n",
            "2020-03-08 18:06:54,445 epoch 94 - iter 164/417 - loss 2.22644963 - samples/sec: 148.43\n",
            "2020-03-08 18:07:03,150 epoch 94 - iter 205/417 - loss 2.27478239 - samples/sec: 150.91\n",
            "2020-03-08 18:07:11,720 epoch 94 - iter 246/417 - loss 2.26507958 - samples/sec: 153.30\n",
            "2020-03-08 18:07:20,602 epoch 94 - iter 287/417 - loss 2.24155820 - samples/sec: 147.89\n",
            "2020-03-08 18:07:29,617 epoch 94 - iter 328/417 - loss 2.23790548 - samples/sec: 145.75\n",
            "2020-03-08 18:07:38,432 epoch 94 - iter 369/417 - loss 2.23660541 - samples/sec: 149.00\n",
            "2020-03-08 18:07:46,862 epoch 94 - iter 410/417 - loss 2.24546428 - samples/sec: 155.83\n",
            "2020-03-08 18:07:48,309 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:07:48,311 EPOCH 94 done: loss 2.2497 - lr 0.0002\n",
            "2020-03-08 18:08:18,163 DEV : loss 0.17384886741638184 - score 0.7270476216743897\n",
            "2020-03-08 18:08:19,624 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 18:08:19,626 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:08:29,273 epoch 95 - iter 41/417 - loss 2.21797255 - samples/sec: 136.06\n",
            "2020-03-08 18:08:38,699 epoch 95 - iter 82/417 - loss 2.24826955 - samples/sec: 139.36\n",
            "2020-03-08 18:08:47,710 epoch 95 - iter 123/417 - loss 2.19750529 - samples/sec: 145.78\n",
            "2020-03-08 18:08:56,917 epoch 95 - iter 164/417 - loss 2.22543115 - samples/sec: 142.66\n",
            "2020-03-08 18:09:06,032 epoch 95 - iter 205/417 - loss 2.24147158 - samples/sec: 144.12\n",
            "2020-03-08 18:09:14,870 epoch 95 - iter 246/417 - loss 2.23581877 - samples/sec: 148.64\n",
            "2020-03-08 18:09:23,525 epoch 95 - iter 287/417 - loss 2.23228993 - samples/sec: 151.79\n",
            "2020-03-08 18:09:35,353 epoch 95 - iter 328/417 - loss 2.20048744 - samples/sec: 111.02\n",
            "2020-03-08 18:09:43,990 epoch 95 - iter 369/417 - loss 2.17195817 - samples/sec: 152.09\n",
            "2020-03-08 18:09:53,098 epoch 95 - iter 410/417 - loss 2.19638302 - samples/sec: 144.23\n",
            "2020-03-08 18:09:54,726 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:09:54,727 EPOCH 95 done: loss 2.2032 - lr 0.0002\n",
            "2020-03-08 18:10:27,337 DEV : loss 0.17396779358386993 - score 0.7270287447662872\n",
            "2020-03-08 18:10:28,787 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 18:10:28,788 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:10:38,532 epoch 96 - iter 41/417 - loss 2.08859022 - samples/sec: 134.71\n",
            "2020-03-08 18:10:48,069 epoch 96 - iter 82/417 - loss 2.20674193 - samples/sec: 137.73\n",
            "2020-03-08 18:10:57,310 epoch 96 - iter 123/417 - loss 2.17754263 - samples/sec: 142.14\n",
            "2020-03-08 18:11:06,554 epoch 96 - iter 164/417 - loss 2.18856260 - samples/sec: 142.10\n",
            "2020-03-08 18:11:15,498 epoch 96 - iter 205/417 - loss 2.16241454 - samples/sec: 146.90\n",
            "2020-03-08 18:11:24,461 epoch 96 - iter 246/417 - loss 2.17064403 - samples/sec: 146.58\n",
            "2020-03-08 18:11:33,633 epoch 96 - iter 287/417 - loss 2.17531340 - samples/sec: 143.22\n",
            "2020-03-08 18:11:42,940 epoch 96 - iter 328/417 - loss 2.17824757 - samples/sec: 141.16\n",
            "2020-03-08 18:11:52,619 epoch 96 - iter 369/417 - loss 2.16374283 - samples/sec: 135.70\n",
            "2020-03-08 18:12:01,813 epoch 96 - iter 410/417 - loss 2.18534729 - samples/sec: 142.89\n",
            "2020-03-08 18:12:03,364 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:12:03,365 EPOCH 96 done: loss 2.1825 - lr 0.0002\n",
            "2020-03-08 18:12:34,151 DEV : loss 0.1736336499452591 - score 0.7269367323750097\n",
            "2020-03-08 18:12:35,575 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 18:12:35,576 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:12:45,202 epoch 97 - iter 41/417 - loss 2.41150488 - samples/sec: 136.36\n",
            "2020-03-08 18:12:54,151 epoch 97 - iter 82/417 - loss 2.28477237 - samples/sec: 146.79\n",
            "2020-03-08 18:13:03,039 epoch 97 - iter 123/417 - loss 2.27168996 - samples/sec: 147.79\n",
            "2020-03-08 18:13:12,046 epoch 97 - iter 164/417 - loss 2.21550991 - samples/sec: 145.84\n",
            "2020-03-08 18:13:21,520 epoch 97 - iter 205/417 - loss 2.22854552 - samples/sec: 138.66\n",
            "2020-03-08 18:13:31,096 epoch 97 - iter 246/417 - loss 2.21876842 - samples/sec: 137.18\n",
            "2020-03-08 18:13:40,240 epoch 97 - iter 287/417 - loss 2.19724770 - samples/sec: 143.65\n",
            "2020-03-08 18:13:49,273 epoch 97 - iter 328/417 - loss 2.21798004 - samples/sec: 145.41\n",
            "2020-03-08 18:13:57,925 epoch 97 - iter 369/417 - loss 2.22469640 - samples/sec: 151.85\n",
            "2020-03-08 18:14:07,068 epoch 97 - iter 410/417 - loss 2.21176148 - samples/sec: 143.67\n",
            "2020-03-08 18:14:08,585 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:14:08,586 EPOCH 97 done: loss 2.2114 - lr 0.0002\n",
            "2020-03-08 18:14:39,110 DEV : loss 0.17371807992458344 - score 0.7269613473853036\n",
            "Epoch    97: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2020-03-08 18:14:40,562 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 18:14:40,564 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:14:40,565 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:14:40,566 learning rate too small - quitting training!\n",
            "2020-03-08 18:14:40,567 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:15:14,894 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:15:18,549 Testing using best model ...\n",
            "2020-03-08 18:15:18,552 loading file train_0/best-model.pt\n",
            "2020-03-08 18:16:31,559 Using REGRESSION - experimental\n",
            "2020-03-08 18:17:02,380 5.635872861587368\t0.6728479239393163\t0.7287449167233518\n",
            "2020-03-08 18:17:02,381 AVG: mse: 5.6359 - mae: 1.6551 - pearson: 0.7287 - spearman: 0.6728\n",
            "2020-03-08 18:17:02,383 ----------------------------------------------------------------------------------------------------\n",
            "0 - Test score: 0.7287449167233518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHZeqNHFIbZT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "001427ba-27c0-4cca-e0bf-7e7872cd1171"
      },
      "source": [
        "#!wget -c https://ghc-flair.s3.amazonaws.com/BioWordVec_PubMed_MIMICIII_d200.vec.bin \n",
        "\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('/content/BioWordVec_PubMed_MIMICIII_d200.vec.bin', binary=True)\n",
        "word_vectors.save('biowordvec.model')\n",
        "\n",
        "embedding =  WordEmbeddings('biowordvec.model')\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-76cacd20a431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/BioWordVec_PubMed_MIMICIII_d200.vec.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'biowordvec.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mWordEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'biowordvec.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     return open(uri, mode, ignore_ext=ignore_extension,\n\u001b[0;32m--> 458\u001b[0;31m                 transport_params=transport_params, **scrubbed_kwargs)\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/BioWordVec_PubMed_MIMICIII_d200.vec.bin'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuwCP9UYLTjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget -c https://ghc-flair.s3.amazonaws.com/wiki.en.zip\n",
        "!unzip wiki.en.zip\n",
        "\n",
        "import gensim\n",
        "\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('/content/wiki.en.vec', binary=False)\n",
        "word_vectors.save('wiki.model')\n",
        "\n",
        "wiki_embedding =  WordEmbeddings('wiki.model')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}