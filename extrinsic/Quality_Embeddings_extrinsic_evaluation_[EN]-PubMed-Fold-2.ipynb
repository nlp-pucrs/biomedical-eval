{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quality_Embeddings_extrinsic_evaluation_[EN].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp5-a7qLGSFT",
        "colab_type": "code",
        "outputId": "ac09b5b8-4667-45db-9b60-b90499cdea4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install flair -q"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 143kB 2.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 983kB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 798kB 18.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 22.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 23.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 25.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 35.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 43.3MB/s \n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqvynY3V9iCc",
        "colab_type": "code",
        "outputId": "4ade95d1-4045-459e-aac8-cc1db86c9e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!wget -c https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
        "!unzip -o drugsCom_raw.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-08 14:40:56--  https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42989872 (41M) [application/x-httpd-php]\n",
            "Saving to: ‘drugsCom_raw.zip’\n",
            "\n",
            "drugsCom_raw.zip    100%[===================>]  41.00M  31.9MB/s    in 1.3s    \n",
            "\n",
            "2020-03-08 14:40:58 (31.9 MB/s) - ‘drugsCom_raw.zip’ saved [42989872/42989872]\n",
            "\n",
            "Archive:  drugsCom_raw.zip\n",
            "  inflating: drugsComTest_raw.tsv    \n",
            "  inflating: drugsComTrain_raw.tsv   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVgelMk39uuZ",
        "colab_type": "code",
        "outputId": "15c3849a-a9e2-4767-81f2-f3c0ff17afb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "drugs = pd.read_csv('/content/drugsComTrain_raw.tsv', sep='\\t', header=0)#, nrows=10000)\n",
        "print(drugs.shape, drugs.columns)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(161297, 7) Index(['Unnamed: 0', 'drugName', 'condition', 'review', 'rating', 'date',\n",
            "       'usefulCount'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1iEuePrhY6y",
        "colab_type": "code",
        "outputId": "a236b50e-16fa-4e39-a5a1-51df123dc650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "drugs[['Unnamed: 0','rating']].groupby('rating').count()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>21619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>6931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>6513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>5012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>8013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>6343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>9456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>18890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>27531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.0</th>\n",
              "      <td>50989</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0\n",
              "rating            \n",
              "1.0          21619\n",
              "2.0           6931\n",
              "3.0           6513\n",
              "4.0           5012\n",
              "5.0           8013\n",
              "6.0           6343\n",
              "7.0           9456\n",
              "8.0          18890\n",
              "9.0          27531\n",
              "10.0         50989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ay8xkQYhusm",
        "colab_type": "code",
        "outputId": "a50cb471-c4d3-48ec-eb78-780ae9ab9e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "drugs = pd.read_csv('/content/drugsComTrain_raw.tsv', sep='\\t', header=0, nrows=20000)\n",
        "drugs[['Unnamed: 0','rating']].groupby('rating').count()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>2658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4.0</th>\n",
              "      <td>651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5.0</th>\n",
              "      <td>1019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6.0</th>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7.0</th>\n",
              "      <td>1144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8.0</th>\n",
              "      <td>2269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9.0</th>\n",
              "      <td>3412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10.0</th>\n",
              "      <td>6387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0\n",
              "rating            \n",
              "1.0           2658\n",
              "2.0            872\n",
              "3.0            811\n",
              "4.0            651\n",
              "5.0           1019\n",
              "6.0            777\n",
              "7.0           1144\n",
              "8.0           2269\n",
              "9.0           3412\n",
              "10.0          6387"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFATEJgwHwQQ",
        "colab_type": "code",
        "outputId": "9b7b12c4-fc21-4d08-a506-578d007b7f85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from flair.data import Sentence, Label\n",
        "\n",
        "sentences = []\n",
        "for idx in drugs.index:\n",
        "  data = drugs.iloc[idx]\n",
        "  sentence = Sentence(data.review, labels=[Label(value=str(data.rating))], use_tokenizer=True)\n",
        "  sentences.append(sentence)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXUic-jpLXP0",
        "colab_type": "code",
        "outputId": "47843883-664c-4c06-b04e-1d96920b169e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "!wget -c https://ghc-flair.s3.amazonaws.com/PubMed-w2v.bin \n",
        "\n",
        "import gensim\n",
        "\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('/content/PubMed-w2v.bin', binary=True)\n",
        "word_vectors.save('pubmed.model')\n",
        "\n",
        "n_loop = 1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-08 14:44:35--  https://ghc-flair.s3.amazonaws.com/PubMed-w2v.bin\n",
            "Resolving ghc-flair.s3.amazonaws.com (ghc-flair.s3.amazonaws.com)... 52.216.236.203\n",
            "Connecting to ghc-flair.s3.amazonaws.com (ghc-flair.s3.amazonaws.com)|52.216.236.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1909156308 (1.8G) [application/octet-stream]\n",
            "Saving to: ‘PubMed-w2v.bin’\n",
            "\n",
            "PubMed-w2v.bin      100%[===================>]   1.78G  89.0MB/s    in 21s     \n",
            "\n",
            "2020-03-08 14:44:56 (86.7 MB/s) - ‘PubMed-w2v.bin’ saved [1909156308/1909156308]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzeJV4E1h6tf",
        "colab_type": "code",
        "outputId": "0329ef1e-923d-404f-ceba-0b0c151f40fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from flair.embeddings import WordEmbeddings\n",
        "custom_embedding =  WordEmbeddings('pubmed.model')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slP7-_93IaWF",
        "colab_type": "code",
        "outputId": "88bfa7d2-748e-4824-976b-a1220251e155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "from flair.data import Sentence, Corpus\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings, BertEmbeddings\n",
        "from flair.models.text_regression_model import TextRegressor\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "\n",
        "target_set = drugs['rating'].values\n",
        "\n",
        "results = []\n",
        "\n",
        "## TEST\n",
        "kfold_test = StratifiedKFold(n_splits=3, random_state=13)\n",
        "for i, (train, test) in enumerate(kfold_test.split(target_set, target_set)):\n",
        "\n",
        "  if i > n_loop:\n",
        "    break;\n",
        "\n",
        "  if i < n_loop:\n",
        "    continue;\n",
        "\n",
        "\n",
        "  print(i, len(train), len(test))\n",
        "  corpus = Corpus([sentences[t] for t in train], [sentences[d] for d in test], [sentences[e] for e in test]) \n",
        "\n",
        "  label_dict = corpus.make_label_dictionary()\n",
        "  \n",
        "  word_embeddings = [custom_embedding]\n",
        "  \n",
        "  document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
        "                                                                       hidden_size=512,\n",
        "                                                                       reproject_words=True,\n",
        "                                                                       reproject_words_dimension=256,\n",
        "                                                                       )\n",
        "  model = TextRegressor(document_embeddings)\n",
        "\n",
        "  trainer = ModelTrainer(model, corpus)\n",
        "\n",
        "  result = trainer.train('train_'+str(i)+'/')\n",
        "\n",
        "  print(str(i) + \" - Test score: \" + str(result[\"test_score\"]))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 13333 6667\n",
            "2020-03-08 14:45:58,275 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "100%|██████████| 13333/13333 [00:00<00:00, 236373.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-08 14:45:58,361 [b'9.0', b'8.0', b'5.0', b'2.0', b'1.0', b'10.0', b'4.0', b'3.0', b'7.0', b'6.0']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-08 14:46:06,465 Using REGRESSION - experimental\n",
            "2020-03-08 14:46:06,466 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:46:06,468 Model: \"TextRegressor(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('pubmed.model')\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=200, out_features=256, bias=True)\n",
            "    (rnn): GRU(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (loss_function): MSELoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-03-08 14:46:06,469 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:46:06,470 Corpus: \"Corpus: 13333 train + 6667 dev + 6667 test sentences\"\n",
            "2020-03-08 14:46:06,471 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:46:06,472 Parameters:\n",
            "2020-03-08 14:46:06,473  - learning_rate: \"0.1\"\n",
            "2020-03-08 14:46:06,475  - mini_batch_size: \"32\"\n",
            "2020-03-08 14:46:06,476  - patience: \"3\"\n",
            "2020-03-08 14:46:06,477  - anneal_factor: \"0.5\"\n",
            "2020-03-08 14:46:06,478  - max_epochs: \"100\"\n",
            "2020-03-08 14:46:06,479  - shuffle: \"True\"\n",
            "2020-03-08 14:46:06,480  - train_with_dev: \"False\"\n",
            "2020-03-08 14:46:06,480  - batch_growth_annealing: \"False\"\n",
            "2020-03-08 14:46:06,481 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:46:06,482 Model training base path: \"train_1\"\n",
            "2020-03-08 14:46:06,483 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:46:06,484 Device: cuda:0\n",
            "2020-03-08 14:46:06,485 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:46:06,486 Embeddings storage mode: cpu\n",
            "2020-03-08 14:46:06,487 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:46:23,635 epoch 1 - iter 41/417 - loss 16.17164712 - samples/sec: 76.57\n",
            "2020-03-08 14:46:40,816 epoch 1 - iter 82/417 - loss 14.47708910 - samples/sec: 76.43\n",
            "2020-03-08 14:46:57,670 epoch 1 - iter 123/417 - loss 13.78772582 - samples/sec: 77.90\n",
            "2020-03-08 14:47:14,299 epoch 1 - iter 164/417 - loss 13.31259897 - samples/sec: 78.95\n",
            "2020-03-08 14:47:31,489 epoch 1 - iter 205/417 - loss 13.03186068 - samples/sec: 76.37\n",
            "2020-03-08 14:47:48,971 epoch 1 - iter 246/417 - loss 12.69868019 - samples/sec: 75.10\n",
            "2020-03-08 14:48:05,462 epoch 1 - iter 287/417 - loss 12.53743865 - samples/sec: 79.61\n",
            "2020-03-08 14:48:21,934 epoch 1 - iter 328/417 - loss 12.39931938 - samples/sec: 79.71\n",
            "2020-03-08 14:48:41,891 epoch 1 - iter 369/417 - loss 12.26563252 - samples/sec: 65.78\n",
            "2020-03-08 14:48:58,381 epoch 1 - iter 410/417 - loss 12.08263711 - samples/sec: 79.62\n",
            "2020-03-08 14:49:01,041 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:49:01,043 EPOCH 1 done: loss 12.1031 - lr 0.1000\n",
            "2020-03-08 14:50:14,032 DEV : loss 0.33297431468963623 - score 0.23410812697176892\n",
            "2020-03-08 14:50:15,468 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:50:56,672 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:51:06,206 epoch 2 - iter 41/417 - loss 11.65612879 - samples/sec: 137.68\n",
            "2020-03-08 14:51:15,518 epoch 2 - iter 82/417 - loss 11.24997134 - samples/sec: 141.10\n",
            "2020-03-08 14:51:24,773 epoch 2 - iter 123/417 - loss 11.06860228 - samples/sec: 141.95\n",
            "2020-03-08 14:51:33,711 epoch 2 - iter 164/417 - loss 11.07331818 - samples/sec: 146.98\n",
            "2020-03-08 14:51:42,404 epoch 2 - iter 205/417 - loss 10.96744706 - samples/sec: 151.13\n",
            "2020-03-08 14:51:50,977 epoch 2 - iter 246/417 - loss 10.79065140 - samples/sec: 153.24\n",
            "2020-03-08 14:51:59,606 epoch 2 - iter 287/417 - loss 10.83058980 - samples/sec: 152.24\n",
            "2020-03-08 14:52:08,537 epoch 2 - iter 328/417 - loss 10.80451784 - samples/sec: 147.11\n",
            "2020-03-08 14:52:17,896 epoch 2 - iter 369/417 - loss 10.90790420 - samples/sec: 140.38\n",
            "2020-03-08 14:52:27,000 epoch 2 - iter 410/417 - loss 10.85939062 - samples/sec: 144.31\n",
            "2020-03-08 14:52:28,491 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:52:28,492 EPOCH 2 done: loss 10.8387 - lr 0.1000\n",
            "2020-03-08 14:52:59,430 DEV : loss 0.324627161026001 - score 0.2754506010206425\n",
            "2020-03-08 14:53:00,873 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:53:37,958 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:53:47,751 epoch 3 - iter 41/417 - loss 10.51501022 - samples/sec: 134.04\n",
            "2020-03-08 14:53:57,190 epoch 3 - iter 82/417 - loss 10.65716211 - samples/sec: 139.15\n",
            "2020-03-08 14:54:06,708 epoch 3 - iter 123/417 - loss 10.53733592 - samples/sec: 138.04\n",
            "2020-03-08 14:54:16,005 epoch 3 - iter 164/417 - loss 10.67982524 - samples/sec: 141.32\n",
            "2020-03-08 14:54:25,070 epoch 3 - iter 205/417 - loss 10.70323267 - samples/sec: 144.93\n",
            "2020-03-08 14:54:33,757 epoch 3 - iter 246/417 - loss 10.80670992 - samples/sec: 151.26\n",
            "2020-03-08 14:54:42,621 epoch 3 - iter 287/417 - loss 10.74707436 - samples/sec: 148.21\n",
            "2020-03-08 14:54:52,023 epoch 3 - iter 328/417 - loss 10.81669660 - samples/sec: 139.74\n",
            "2020-03-08 14:55:01,484 epoch 3 - iter 369/417 - loss 10.79553419 - samples/sec: 138.85\n",
            "2020-03-08 14:55:10,529 epoch 3 - iter 410/417 - loss 10.70089936 - samples/sec: 145.23\n",
            "2020-03-08 14:55:12,056 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:55:12,057 EPOCH 3 done: loss 10.7232 - lr 0.1000\n",
            "2020-03-08 14:55:43,276 DEV : loss 0.33824145793914795 - score 0.2958281562402311\n",
            "2020-03-08 14:55:44,735 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:56:23,021 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:56:37,080 epoch 4 - iter 41/417 - loss 10.60331969 - samples/sec: 99.12\n",
            "2020-03-08 14:56:46,332 epoch 4 - iter 82/417 - loss 10.61636681 - samples/sec: 141.97\n",
            "2020-03-08 14:56:55,436 epoch 4 - iter 123/417 - loss 10.72297948 - samples/sec: 144.32\n",
            "2020-03-08 14:57:04,188 epoch 4 - iter 164/417 - loss 10.67712306 - samples/sec: 150.10\n",
            "2020-03-08 14:57:13,379 epoch 4 - iter 205/417 - loss 10.66283474 - samples/sec: 142.93\n",
            "2020-03-08 14:57:22,874 epoch 4 - iter 246/417 - loss 10.70813324 - samples/sec: 138.37\n",
            "2020-03-08 14:57:32,396 epoch 4 - iter 287/417 - loss 10.75731975 - samples/sec: 137.97\n",
            "2020-03-08 14:57:41,811 epoch 4 - iter 328/417 - loss 10.69305284 - samples/sec: 139.53\n",
            "2020-03-08 14:57:51,131 epoch 4 - iter 369/417 - loss 10.62982150 - samples/sec: 140.96\n",
            "2020-03-08 14:58:00,122 epoch 4 - iter 410/417 - loss 10.62969356 - samples/sec: 146.13\n",
            "2020-03-08 14:58:01,558 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:58:01,559 EPOCH 4 done: loss 10.6490 - lr 0.1000\n",
            "2020-03-08 14:58:35,243 DEV : loss 0.31174787878990173 - score 0.3547398065939452\n",
            "2020-03-08 14:58:36,756 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 14:59:15,069 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 14:59:24,837 epoch 5 - iter 41/417 - loss 10.74621508 - samples/sec: 134.37\n",
            "2020-03-08 14:59:34,855 epoch 5 - iter 82/417 - loss 10.82119690 - samples/sec: 131.15\n",
            "2020-03-08 14:59:44,432 epoch 5 - iter 123/417 - loss 10.82177930 - samples/sec: 137.14\n",
            "2020-03-08 14:59:54,181 epoch 5 - iter 164/417 - loss 10.72670303 - samples/sec: 134.74\n",
            "2020-03-08 15:00:03,165 epoch 5 - iter 205/417 - loss 10.62423418 - samples/sec: 146.24\n",
            "2020-03-08 15:00:11,989 epoch 5 - iter 246/417 - loss 10.59778553 - samples/sec: 148.89\n",
            "2020-03-08 15:00:20,884 epoch 5 - iter 287/417 - loss 10.55815482 - samples/sec: 147.67\n",
            "2020-03-08 15:00:29,684 epoch 5 - iter 328/417 - loss 10.50493666 - samples/sec: 149.28\n",
            "2020-03-08 15:00:38,998 epoch 5 - iter 369/417 - loss 10.45816684 - samples/sec: 141.04\n",
            "2020-03-08 15:00:48,455 epoch 5 - iter 410/417 - loss 10.42421598 - samples/sec: 138.90\n",
            "2020-03-08 15:00:49,957 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:00:49,958 EPOCH 5 done: loss 10.3840 - lr 0.1000\n",
            "2020-03-08 15:01:21,207 DEV : loss 0.3075702488422394 - score 0.41874568252881084\n",
            "2020-03-08 15:01:22,673 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:01:59,565 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:02:09,217 epoch 6 - iter 41/417 - loss 9.62696224 - samples/sec: 136.00\n",
            "2020-03-08 15:02:18,823 epoch 6 - iter 82/417 - loss 9.98489782 - samples/sec: 136.77\n",
            "2020-03-08 15:02:28,229 epoch 6 - iter 123/417 - loss 9.93086282 - samples/sec: 139.64\n",
            "2020-03-08 15:02:37,937 epoch 6 - iter 164/417 - loss 9.96430832 - samples/sec: 135.31\n",
            "2020-03-08 15:02:47,036 epoch 6 - iter 205/417 - loss 9.95039474 - samples/sec: 144.41\n",
            "2020-03-08 15:02:56,163 epoch 6 - iter 246/417 - loss 9.96274792 - samples/sec: 143.92\n",
            "2020-03-08 15:03:05,143 epoch 6 - iter 287/417 - loss 9.94724097 - samples/sec: 146.29\n",
            "2020-03-08 15:03:14,193 epoch 6 - iter 328/417 - loss 9.91799275 - samples/sec: 145.15\n",
            "2020-03-08 15:03:23,228 epoch 6 - iter 369/417 - loss 9.84926157 - samples/sec: 145.39\n",
            "2020-03-08 15:03:32,608 epoch 6 - iter 410/417 - loss 9.87449473 - samples/sec: 140.07\n",
            "2020-03-08 15:03:34,115 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:03:34,117 EPOCH 6 done: loss 9.8634 - lr 0.1000\n",
            "2020-03-08 15:04:04,619 DEV : loss 0.4006614685058594 - score 0.4690527336283323\n",
            "2020-03-08 15:04:06,069 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:04:41,832 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:04:55,872 epoch 7 - iter 41/417 - loss 9.24510165 - samples/sec: 135.65\n",
            "2020-03-08 15:05:05,334 epoch 7 - iter 82/417 - loss 9.54484849 - samples/sec: 138.86\n",
            "2020-03-08 15:05:14,468 epoch 7 - iter 123/417 - loss 9.50891371 - samples/sec: 143.84\n",
            "2020-03-08 15:05:23,979 epoch 7 - iter 164/417 - loss 9.64495799 - samples/sec: 138.13\n",
            "2020-03-08 15:05:33,198 epoch 7 - iter 205/417 - loss 9.53501592 - samples/sec: 142.49\n",
            "2020-03-08 15:05:42,269 epoch 7 - iter 246/417 - loss 9.44754670 - samples/sec: 144.83\n",
            "2020-03-08 15:05:51,502 epoch 7 - iter 287/417 - loss 9.41297925 - samples/sec: 142.29\n",
            "2020-03-08 15:06:00,300 epoch 7 - iter 328/417 - loss 9.37119384 - samples/sec: 149.32\n",
            "2020-03-08 15:06:09,453 epoch 7 - iter 369/417 - loss 9.37664708 - samples/sec: 143.52\n",
            "2020-03-08 15:06:18,744 epoch 7 - iter 410/417 - loss 9.35000718 - samples/sec: 141.39\n",
            "2020-03-08 15:06:20,305 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:06:20,307 EPOCH 7 done: loss 9.3492 - lr 0.1000\n",
            "2020-03-08 15:06:51,385 DEV : loss 0.27446696162223816 - score 0.5324710514496628\n",
            "2020-03-08 15:06:52,861 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:07:29,404 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:07:40,336 epoch 8 - iter 41/417 - loss 9.11278326 - samples/sec: 137.68\n",
            "2020-03-08 15:07:49,633 epoch 8 - iter 82/417 - loss 9.19861370 - samples/sec: 141.30\n",
            "2020-03-08 15:07:58,801 epoch 8 - iter 123/417 - loss 9.15046659 - samples/sec: 143.29\n",
            "2020-03-08 15:08:07,758 epoch 8 - iter 164/417 - loss 9.09054158 - samples/sec: 146.66\n",
            "2020-03-08 15:08:16,498 epoch 8 - iter 205/417 - loss 9.18907488 - samples/sec: 150.31\n",
            "2020-03-08 15:08:25,160 epoch 8 - iter 246/417 - loss 9.16063221 - samples/sec: 151.67\n",
            "2020-03-08 15:08:34,458 epoch 8 - iter 287/417 - loss 9.15077348 - samples/sec: 141.27\n",
            "2020-03-08 15:08:43,832 epoch 8 - iter 328/417 - loss 9.16195177 - samples/sec: 140.13\n",
            "2020-03-08 15:08:52,774 epoch 8 - iter 369/417 - loss 9.12784586 - samples/sec: 146.92\n",
            "2020-03-08 15:09:01,701 epoch 8 - iter 410/417 - loss 9.12083260 - samples/sec: 147.16\n",
            "2020-03-08 15:09:03,226 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:09:03,227 EPOCH 8 done: loss 9.1044 - lr 0.1000\n",
            "2020-03-08 15:09:35,460 DEV : loss 0.23901312053203583 - score 0.5434630565247085\n",
            "2020-03-08 15:09:36,922 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:10:13,063 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:10:26,464 epoch 9 - iter 41/417 - loss 8.24004067 - samples/sec: 134.46\n",
            "2020-03-08 15:10:35,583 epoch 9 - iter 82/417 - loss 8.52867232 - samples/sec: 144.06\n",
            "2020-03-08 15:10:44,618 epoch 9 - iter 123/417 - loss 8.43588711 - samples/sec: 145.39\n",
            "2020-03-08 15:10:53,966 epoch 9 - iter 164/417 - loss 8.62164528 - samples/sec: 140.53\n",
            "2020-03-08 15:11:03,297 epoch 9 - iter 205/417 - loss 8.71306863 - samples/sec: 140.77\n",
            "2020-03-08 15:11:12,427 epoch 9 - iter 246/417 - loss 8.75659303 - samples/sec: 143.89\n",
            "2020-03-08 15:11:21,611 epoch 9 - iter 287/417 - loss 8.78877770 - samples/sec: 143.04\n",
            "2020-03-08 15:11:30,458 epoch 9 - iter 328/417 - loss 8.82179796 - samples/sec: 148.51\n",
            "2020-03-08 15:11:39,655 epoch 9 - iter 369/417 - loss 8.76973821 - samples/sec: 142.85\n",
            "2020-03-08 15:11:48,894 epoch 9 - iter 410/417 - loss 8.79803720 - samples/sec: 142.20\n",
            "2020-03-08 15:11:50,453 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:11:50,454 EPOCH 9 done: loss 8.8151 - lr 0.1000\n",
            "2020-03-08 15:12:21,705 DEV : loss 0.24518698453903198 - score 0.5409268843319288\n",
            "2020-03-08 15:12:23,155 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:12:23,157 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:12:32,892 epoch 10 - iter 41/417 - loss 8.41374486 - samples/sec: 134.83\n",
            "2020-03-08 15:12:42,506 epoch 10 - iter 82/417 - loss 8.77565599 - samples/sec: 136.64\n",
            "2020-03-08 15:12:51,569 epoch 10 - iter 123/417 - loss 8.89526409 - samples/sec: 144.94\n",
            "2020-03-08 15:13:00,279 epoch 10 - iter 164/417 - loss 8.83381142 - samples/sec: 150.83\n",
            "2020-03-08 15:13:09,454 epoch 10 - iter 205/417 - loss 8.72483089 - samples/sec: 143.19\n",
            "2020-03-08 15:13:18,783 epoch 10 - iter 246/417 - loss 8.71198589 - samples/sec: 140.80\n",
            "2020-03-08 15:13:27,871 epoch 10 - iter 287/417 - loss 8.64467188 - samples/sec: 144.53\n",
            "2020-03-08 15:13:37,042 epoch 10 - iter 328/417 - loss 8.61194553 - samples/sec: 143.22\n",
            "2020-03-08 15:13:46,430 epoch 10 - iter 369/417 - loss 8.61270775 - samples/sec: 139.92\n",
            "2020-03-08 15:13:55,686 epoch 10 - iter 410/417 - loss 8.57846341 - samples/sec: 141.92\n",
            "2020-03-08 15:13:57,228 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:13:57,229 EPOCH 10 done: loss 8.5785 - lr 0.1000\n",
            "2020-03-08 15:14:30,021 DEV : loss 0.2462594360113144 - score 0.5757421334725219\n",
            "2020-03-08 15:14:31,460 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:15:08,598 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:15:20,570 epoch 11 - iter 41/417 - loss 8.37830745 - samples/sec: 137.29\n",
            "2020-03-08 15:15:29,872 epoch 11 - iter 82/417 - loss 8.34104049 - samples/sec: 141.21\n",
            "2020-03-08 15:15:39,417 epoch 11 - iter 123/417 - loss 8.50852593 - samples/sec: 137.63\n",
            "2020-03-08 15:15:48,515 epoch 11 - iter 164/417 - loss 8.41604323 - samples/sec: 144.38\n",
            "2020-03-08 15:15:57,290 epoch 11 - iter 205/417 - loss 8.34469592 - samples/sec: 149.73\n",
            "2020-03-08 15:16:06,093 epoch 11 - iter 246/417 - loss 8.33441130 - samples/sec: 149.26\n",
            "2020-03-08 15:16:14,676 epoch 11 - iter 287/417 - loss 8.38540901 - samples/sec: 153.08\n",
            "2020-03-08 15:16:23,874 epoch 11 - iter 328/417 - loss 8.42025618 - samples/sec: 142.85\n",
            "2020-03-08 15:16:33,025 epoch 11 - iter 369/417 - loss 8.44089560 - samples/sec: 143.57\n",
            "2020-03-08 15:16:45,811 epoch 11 - iter 410/417 - loss 8.41124597 - samples/sec: 102.72\n",
            "2020-03-08 15:16:47,327 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:16:47,328 EPOCH 11 done: loss 8.4133 - lr 0.1000\n",
            "2020-03-08 15:17:19,162 DEV : loss 0.22490225732326508 - score 0.5970880782176251\n",
            "2020-03-08 15:17:20,624 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:18:01,296 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:18:11,077 epoch 12 - iter 41/417 - loss 8.20612093 - samples/sec: 134.55\n",
            "2020-03-08 15:18:20,339 epoch 12 - iter 82/417 - loss 8.28117126 - samples/sec: 141.84\n",
            "2020-03-08 15:18:29,802 epoch 12 - iter 123/417 - loss 8.37288535 - samples/sec: 138.83\n",
            "2020-03-08 15:18:39,158 epoch 12 - iter 164/417 - loss 8.20812430 - samples/sec: 140.42\n",
            "2020-03-08 15:18:48,059 epoch 12 - iter 205/417 - loss 8.37193215 - samples/sec: 147.61\n",
            "2020-03-08 15:18:56,668 epoch 12 - iter 246/417 - loss 8.18552513 - samples/sec: 152.62\n",
            "2020-03-08 15:19:05,223 epoch 12 - iter 287/417 - loss 8.21052691 - samples/sec: 153.58\n",
            "2020-03-08 15:19:13,937 epoch 12 - iter 328/417 - loss 8.19947549 - samples/sec: 150.75\n",
            "2020-03-08 15:19:22,629 epoch 12 - iter 369/417 - loss 8.23967493 - samples/sec: 151.15\n",
            "2020-03-08 15:19:31,476 epoch 12 - iter 410/417 - loss 8.18501440 - samples/sec: 148.47\n",
            "2020-03-08 15:19:32,999 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:19:33,000 EPOCH 12 done: loss 8.1961 - lr 0.1000\n",
            "2020-03-08 15:20:03,264 DEV : loss 0.24659191071987152 - score 0.615807220741635\n",
            "2020-03-08 15:20:04,706 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:20:41,173 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:20:51,647 epoch 13 - iter 41/417 - loss 7.85163901 - samples/sec: 133.59\n",
            "2020-03-08 15:21:00,959 epoch 13 - iter 82/417 - loss 8.02987634 - samples/sec: 141.06\n",
            "2020-03-08 15:21:10,455 epoch 13 - iter 123/417 - loss 8.02289457 - samples/sec: 138.33\n",
            "2020-03-08 15:21:19,780 epoch 13 - iter 164/417 - loss 8.05585626 - samples/sec: 140.89\n",
            "2020-03-08 15:21:28,841 epoch 13 - iter 205/417 - loss 8.00128825 - samples/sec: 144.98\n",
            "2020-03-08 15:21:37,679 epoch 13 - iter 246/417 - loss 8.07322781 - samples/sec: 148.66\n",
            "2020-03-08 15:21:46,270 epoch 13 - iter 287/417 - loss 8.10593927 - samples/sec: 152.94\n",
            "2020-03-08 15:21:55,358 epoch 13 - iter 328/417 - loss 8.15572926 - samples/sec: 144.57\n",
            "2020-03-08 15:22:04,916 epoch 13 - iter 369/417 - loss 8.11376820 - samples/sec: 137.44\n",
            "2020-03-08 15:22:14,421 epoch 13 - iter 410/417 - loss 8.09504141 - samples/sec: 138.21\n",
            "2020-03-08 15:22:15,999 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:22:16,001 EPOCH 13 done: loss 8.1135 - lr 0.1000\n",
            "2020-03-08 15:22:48,317 DEV : loss 0.23568496108055115 - score 0.6058759302277436\n",
            "2020-03-08 15:22:49,813 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:22:49,814 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:22:59,161 epoch 14 - iter 41/417 - loss 7.81374870 - samples/sec: 140.45\n",
            "2020-03-08 15:23:08,221 epoch 14 - iter 82/417 - loss 7.89449473 - samples/sec: 145.01\n",
            "2020-03-08 15:23:17,408 epoch 14 - iter 123/417 - loss 8.01476986 - samples/sec: 143.00\n",
            "2020-03-08 15:23:26,307 epoch 14 - iter 164/417 - loss 8.06885141 - samples/sec: 147.64\n",
            "2020-03-08 15:23:35,220 epoch 14 - iter 205/417 - loss 8.01211389 - samples/sec: 147.41\n",
            "2020-03-08 15:23:43,852 epoch 14 - iter 246/417 - loss 8.02528686 - samples/sec: 152.18\n",
            "2020-03-08 15:23:52,501 epoch 14 - iter 287/417 - loss 8.08854626 - samples/sec: 151.92\n",
            "2020-03-08 15:24:01,294 epoch 14 - iter 328/417 - loss 8.07874775 - samples/sec: 149.40\n",
            "2020-03-08 15:24:09,936 epoch 14 - iter 369/417 - loss 8.08032095 - samples/sec: 152.03\n",
            "2020-03-08 15:24:18,471 epoch 14 - iter 410/417 - loss 7.97629050 - samples/sec: 153.92\n",
            "2020-03-08 15:24:19,952 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:24:19,954 EPOCH 14 done: loss 7.9709 - lr 0.1000\n",
            "2020-03-08 15:24:50,358 DEV : loss 0.209527850151062 - score 0.6204896080157546\n",
            "2020-03-08 15:24:51,857 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:25:29,638 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:25:41,804 epoch 15 - iter 41/417 - loss 7.90128180 - samples/sec: 134.09\n",
            "2020-03-08 15:25:51,069 epoch 15 - iter 82/417 - loss 7.74981963 - samples/sec: 141.78\n",
            "2020-03-08 15:26:00,235 epoch 15 - iter 123/417 - loss 7.81688873 - samples/sec: 143.30\n",
            "2020-03-08 15:26:09,203 epoch 15 - iter 164/417 - loss 7.78526296 - samples/sec: 146.48\n",
            "2020-03-08 15:26:17,830 epoch 15 - iter 205/417 - loss 7.72526509 - samples/sec: 152.27\n",
            "2020-03-08 15:26:26,440 epoch 15 - iter 246/417 - loss 7.72521831 - samples/sec: 152.60\n",
            "2020-03-08 15:26:35,439 epoch 15 - iter 287/417 - loss 7.67481704 - samples/sec: 145.98\n",
            "2020-03-08 15:26:44,561 epoch 15 - iter 328/417 - loss 7.70597599 - samples/sec: 144.03\n",
            "2020-03-08 15:26:53,641 epoch 15 - iter 369/417 - loss 7.69382534 - samples/sec: 144.66\n",
            "2020-03-08 15:27:02,345 epoch 15 - iter 410/417 - loss 7.71577371 - samples/sec: 150.93\n",
            "2020-03-08 15:27:03,768 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:27:03,769 EPOCH 15 done: loss 7.7217 - lr 0.1000\n",
            "2020-03-08 15:27:35,430 DEV : loss 0.1986956000328064 - score 0.6487286393306684\n",
            "2020-03-08 15:27:36,942 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:28:13,160 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:28:22,717 epoch 16 - iter 41/417 - loss 7.22991026 - samples/sec: 139.42\n",
            "2020-03-08 15:28:32,221 epoch 16 - iter 82/417 - loss 7.52099640 - samples/sec: 138.22\n",
            "2020-03-08 15:28:41,518 epoch 16 - iter 123/417 - loss 7.82110230 - samples/sec: 141.31\n",
            "2020-03-08 15:28:50,909 epoch 16 - iter 164/417 - loss 7.78280400 - samples/sec: 139.88\n",
            "2020-03-08 15:29:00,310 epoch 16 - iter 205/417 - loss 7.72143161 - samples/sec: 139.75\n",
            "2020-03-08 15:29:09,726 epoch 16 - iter 246/417 - loss 7.67689322 - samples/sec: 139.51\n",
            "2020-03-08 15:29:19,387 epoch 16 - iter 287/417 - loss 7.73392206 - samples/sec: 135.97\n",
            "2020-03-08 15:29:28,600 epoch 16 - iter 328/417 - loss 7.68717406 - samples/sec: 142.60\n",
            "2020-03-08 15:29:37,779 epoch 16 - iter 369/417 - loss 7.62882076 - samples/sec: 143.12\n",
            "2020-03-08 15:29:46,960 epoch 16 - iter 410/417 - loss 7.66488794 - samples/sec: 143.11\n",
            "2020-03-08 15:29:48,475 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:29:48,476 EPOCH 16 done: loss 7.6565 - lr 0.1000\n",
            "2020-03-08 15:30:20,682 DEV : loss 0.2011609822511673 - score 0.6545694396543159\n",
            "2020-03-08 15:30:22,213 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:30:57,708 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:31:09,804 epoch 17 - iter 41/417 - loss 7.67994305 - samples/sec: 136.91\n",
            "2020-03-08 15:31:19,020 epoch 17 - iter 82/417 - loss 7.66005727 - samples/sec: 142.55\n",
            "2020-03-08 15:31:28,129 epoch 17 - iter 123/417 - loss 7.49869520 - samples/sec: 144.22\n",
            "2020-03-08 15:31:37,004 epoch 17 - iter 164/417 - loss 7.42385174 - samples/sec: 148.03\n",
            "2020-03-08 15:31:45,853 epoch 17 - iter 205/417 - loss 7.47362705 - samples/sec: 148.45\n",
            "2020-03-08 15:31:54,566 epoch 17 - iter 246/417 - loss 7.53161260 - samples/sec: 150.77\n",
            "2020-03-08 15:32:03,351 epoch 17 - iter 287/417 - loss 7.54377189 - samples/sec: 149.53\n",
            "2020-03-08 15:32:12,343 epoch 17 - iter 328/417 - loss 7.57704088 - samples/sec: 146.12\n",
            "2020-03-08 15:32:21,653 epoch 17 - iter 369/417 - loss 7.51329775 - samples/sec: 141.10\n",
            "2020-03-08 15:32:30,535 epoch 17 - iter 410/417 - loss 7.52263077 - samples/sec: 147.92\n",
            "2020-03-08 15:32:32,006 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:32:32,007 EPOCH 17 done: loss 7.4951 - lr 0.1000\n",
            "2020-03-08 15:33:03,030 DEV : loss 0.24848368763923645 - score 0.6382308716259533\n",
            "2020-03-08 15:33:04,533 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:33:04,535 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:33:14,411 epoch 18 - iter 41/417 - loss 7.30586597 - samples/sec: 132.90\n",
            "2020-03-08 15:33:23,762 epoch 18 - iter 82/417 - loss 7.28498763 - samples/sec: 140.50\n",
            "2020-03-08 15:33:32,606 epoch 18 - iter 123/417 - loss 7.35675751 - samples/sec: 148.56\n",
            "2020-03-08 15:33:41,481 epoch 18 - iter 164/417 - loss 7.29614610 - samples/sec: 148.04\n",
            "2020-03-08 15:33:50,334 epoch 18 - iter 205/417 - loss 7.33666776 - samples/sec: 148.42\n",
            "2020-03-08 15:33:59,309 epoch 18 - iter 246/417 - loss 7.33168675 - samples/sec: 146.39\n",
            "2020-03-08 15:34:08,316 epoch 18 - iter 287/417 - loss 7.30274739 - samples/sec: 145.85\n",
            "2020-03-08 15:34:17,291 epoch 18 - iter 328/417 - loss 7.31333156 - samples/sec: 146.38\n",
            "2020-03-08 15:34:26,299 epoch 18 - iter 369/417 - loss 7.32552609 - samples/sec: 145.84\n",
            "2020-03-08 15:34:35,562 epoch 18 - iter 410/417 - loss 7.33810834 - samples/sec: 141.81\n",
            "2020-03-08 15:34:37,132 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:34:37,133 EPOCH 18 done: loss 7.3483 - lr 0.1000\n",
            "2020-03-08 15:35:09,899 DEV : loss 0.19523300230503082 - score 0.6501701401148204\n",
            "2020-03-08 15:35:11,410 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 15:35:11,412 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:35:21,161 epoch 19 - iter 41/417 - loss 7.83593056 - samples/sec: 134.64\n",
            "2020-03-08 15:35:30,975 epoch 19 - iter 82/417 - loss 7.70003889 - samples/sec: 133.86\n",
            "2020-03-08 15:35:40,774 epoch 19 - iter 123/417 - loss 7.67564657 - samples/sec: 134.06\n",
            "2020-03-08 15:35:54,141 epoch 19 - iter 164/417 - loss 7.55261824 - samples/sec: 98.24\n",
            "2020-03-08 15:36:03,716 epoch 19 - iter 205/417 - loss 7.46093913 - samples/sec: 137.20\n",
            "2020-03-08 15:36:13,141 epoch 19 - iter 246/417 - loss 7.42838811 - samples/sec: 139.38\n",
            "2020-03-08 15:36:22,295 epoch 19 - iter 287/417 - loss 7.39074484 - samples/sec: 143.51\n",
            "2020-03-08 15:36:31,237 epoch 19 - iter 328/417 - loss 7.30435723 - samples/sec: 146.94\n",
            "2020-03-08 15:36:40,225 epoch 19 - iter 369/417 - loss 7.28910939 - samples/sec: 146.16\n",
            "2020-03-08 15:36:49,610 epoch 19 - iter 410/417 - loss 7.27151251 - samples/sec: 139.97\n",
            "2020-03-08 15:36:51,070 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:36:51,071 EPOCH 19 done: loss 7.2433 - lr 0.1000\n",
            "2020-03-08 15:37:22,079 DEV : loss 0.193617045879364 - score 0.6575250586583431\n",
            "2020-03-08 15:37:23,592 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:38:02,503 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:38:13,480 epoch 20 - iter 41/417 - loss 6.99232315 - samples/sec: 135.40\n",
            "2020-03-08 15:38:22,875 epoch 20 - iter 82/417 - loss 7.18232607 - samples/sec: 139.81\n",
            "2020-03-08 15:38:31,801 epoch 20 - iter 123/417 - loss 7.09994430 - samples/sec: 147.18\n",
            "2020-03-08 15:38:40,906 epoch 20 - iter 164/417 - loss 7.09128112 - samples/sec: 144.29\n",
            "2020-03-08 15:38:49,800 epoch 20 - iter 205/417 - loss 7.02229490 - samples/sec: 147.71\n",
            "2020-03-08 15:38:58,797 epoch 20 - iter 246/417 - loss 7.06898755 - samples/sec: 146.01\n",
            "2020-03-08 15:39:07,743 epoch 20 - iter 287/417 - loss 7.07500534 - samples/sec: 146.83\n",
            "2020-03-08 15:39:16,918 epoch 20 - iter 328/417 - loss 7.08685700 - samples/sec: 143.17\n",
            "2020-03-08 15:39:25,960 epoch 20 - iter 369/417 - loss 7.10814622 - samples/sec: 145.29\n",
            "2020-03-08 15:39:34,681 epoch 20 - iter 410/417 - loss 7.08766679 - samples/sec: 150.63\n",
            "2020-03-08 15:39:36,109 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:39:36,110 EPOCH 20 done: loss 7.0795 - lr 0.1000\n",
            "2020-03-08 15:40:07,780 DEV : loss 0.2219388335943222 - score 0.665069554070106\n",
            "2020-03-08 15:40:09,289 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:40:49,711 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:40:59,703 epoch 21 - iter 41/417 - loss 6.83815693 - samples/sec: 137.15\n",
            "2020-03-08 15:41:09,192 epoch 21 - iter 82/417 - loss 6.97950538 - samples/sec: 138.46\n",
            "2020-03-08 15:41:18,631 epoch 21 - iter 123/417 - loss 7.06651512 - samples/sec: 139.17\n",
            "2020-03-08 15:41:28,288 epoch 21 - iter 164/417 - loss 7.02285498 - samples/sec: 136.02\n",
            "2020-03-08 15:41:37,624 epoch 21 - iter 205/417 - loss 6.96406858 - samples/sec: 140.73\n",
            "2020-03-08 15:41:46,917 epoch 21 - iter 246/417 - loss 7.01324179 - samples/sec: 141.36\n",
            "2020-03-08 15:41:56,357 epoch 21 - iter 287/417 - loss 6.95802479 - samples/sec: 139.18\n",
            "2020-03-08 15:42:05,487 epoch 21 - iter 328/417 - loss 6.99110147 - samples/sec: 143.88\n",
            "2020-03-08 15:42:14,581 epoch 21 - iter 369/417 - loss 6.97666175 - samples/sec: 144.48\n",
            "2020-03-08 15:42:23,519 epoch 21 - iter 410/417 - loss 6.99505378 - samples/sec: 146.97\n",
            "2020-03-08 15:42:24,992 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:42:24,994 EPOCH 21 done: loss 6.9909 - lr 0.1000\n",
            "2020-03-08 15:42:57,711 DEV : loss 0.21345870196819305 - score 0.6556639954578701\n",
            "2020-03-08 15:42:59,221 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:42:59,222 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:43:09,049 epoch 22 - iter 41/417 - loss 6.21944366 - samples/sec: 133.57\n",
            "2020-03-08 15:43:18,323 epoch 22 - iter 82/417 - loss 6.51337908 - samples/sec: 141.67\n",
            "2020-03-08 15:43:27,738 epoch 22 - iter 123/417 - loss 6.64559595 - samples/sec: 139.52\n",
            "2020-03-08 15:43:36,963 epoch 22 - iter 164/417 - loss 6.82134382 - samples/sec: 142.40\n",
            "2020-03-08 15:43:45,924 epoch 22 - iter 205/417 - loss 6.92766366 - samples/sec: 146.61\n",
            "2020-03-08 15:43:54,913 epoch 22 - iter 246/417 - loss 6.94384420 - samples/sec: 146.14\n",
            "2020-03-08 15:44:03,684 epoch 22 - iter 287/417 - loss 6.92051271 - samples/sec: 149.78\n",
            "2020-03-08 15:44:12,474 epoch 22 - iter 328/417 - loss 6.97085729 - samples/sec: 149.45\n",
            "2020-03-08 15:44:21,578 epoch 22 - iter 369/417 - loss 6.95929643 - samples/sec: 144.30\n",
            "2020-03-08 15:44:30,196 epoch 22 - iter 410/417 - loss 6.99364330 - samples/sec: 152.43\n",
            "2020-03-08 15:44:31,627 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:44:31,628 EPOCH 22 done: loss 6.9903 - lr 0.1000\n",
            "2020-03-08 15:45:02,146 DEV : loss 0.18703515827655792 - score 0.667243429690288\n",
            "2020-03-08 15:45:03,663 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:45:40,307 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:45:49,996 epoch 23 - iter 41/417 - loss 6.86462105 - samples/sec: 136.11\n",
            "2020-03-08 15:45:59,760 epoch 23 - iter 82/417 - loss 6.65761916 - samples/sec: 134.55\n",
            "2020-03-08 15:46:09,586 epoch 23 - iter 123/417 - loss 6.57199253 - samples/sec: 133.71\n",
            "2020-03-08 15:46:18,882 epoch 23 - iter 164/417 - loss 6.61875855 - samples/sec: 141.32\n",
            "2020-03-08 15:46:28,227 epoch 23 - iter 205/417 - loss 6.72107259 - samples/sec: 140.59\n",
            "2020-03-08 15:46:37,244 epoch 23 - iter 246/417 - loss 6.74482234 - samples/sec: 145.68\n",
            "2020-03-08 15:46:46,446 epoch 23 - iter 287/417 - loss 6.76498386 - samples/sec: 142.77\n",
            "2020-03-08 15:46:55,956 epoch 23 - iter 328/417 - loss 6.80881010 - samples/sec: 138.11\n",
            "2020-03-08 15:47:05,444 epoch 23 - iter 369/417 - loss 6.82936795 - samples/sec: 138.44\n",
            "2020-03-08 15:47:14,979 epoch 23 - iter 410/417 - loss 6.82004665 - samples/sec: 137.76\n",
            "2020-03-08 15:47:16,591 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:47:16,592 EPOCH 23 done: loss 6.8035 - lr 0.1000\n",
            "2020-03-08 15:47:49,714 DEV : loss 0.18795907497406006 - score 0.6754290204728415\n",
            "2020-03-08 15:47:51,201 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:48:31,442 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:48:42,471 epoch 24 - iter 41/417 - loss 6.52584124 - samples/sec: 134.38\n",
            "2020-03-08 15:48:51,897 epoch 24 - iter 82/417 - loss 6.72556244 - samples/sec: 139.37\n",
            "2020-03-08 15:49:01,317 epoch 24 - iter 123/417 - loss 6.67416761 - samples/sec: 139.44\n",
            "2020-03-08 15:49:10,712 epoch 24 - iter 164/417 - loss 6.71779002 - samples/sec: 139.80\n",
            "2020-03-08 15:49:19,780 epoch 24 - iter 205/417 - loss 6.76980601 - samples/sec: 144.87\n",
            "2020-03-08 15:49:28,616 epoch 24 - iter 246/417 - loss 6.68447587 - samples/sec: 148.68\n",
            "2020-03-08 15:49:37,454 epoch 24 - iter 287/417 - loss 6.66211809 - samples/sec: 148.64\n",
            "2020-03-08 15:49:46,180 epoch 24 - iter 328/417 - loss 6.67304691 - samples/sec: 150.54\n",
            "2020-03-08 15:49:55,050 epoch 24 - iter 369/417 - loss 6.72987516 - samples/sec: 148.07\n",
            "2020-03-08 15:50:04,141 epoch 24 - iter 410/417 - loss 6.72778057 - samples/sec: 144.49\n",
            "2020-03-08 15:50:05,694 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:50:05,696 EPOCH 24 done: loss 6.7188 - lr 0.1000\n",
            "2020-03-08 15:50:37,914 DEV : loss 0.2182168960571289 - score 0.671046102385937\n",
            "2020-03-08 15:50:39,424 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:50:39,426 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:50:49,118 epoch 25 - iter 41/417 - loss 6.23177889 - samples/sec: 135.44\n",
            "2020-03-08 15:50:58,092 epoch 25 - iter 82/417 - loss 6.56593529 - samples/sec: 146.38\n",
            "2020-03-08 15:51:07,351 epoch 25 - iter 123/417 - loss 6.56593091 - samples/sec: 141.86\n",
            "2020-03-08 15:51:16,829 epoch 25 - iter 164/417 - loss 6.69934069 - samples/sec: 138.59\n",
            "2020-03-08 15:51:25,998 epoch 25 - iter 205/417 - loss 6.67036368 - samples/sec: 143.27\n",
            "2020-03-08 15:51:34,702 epoch 25 - iter 246/417 - loss 6.69857715 - samples/sec: 150.94\n",
            "2020-03-08 15:51:43,664 epoch 25 - iter 287/417 - loss 6.73411815 - samples/sec: 146.59\n",
            "2020-03-08 15:51:52,338 epoch 25 - iter 328/417 - loss 6.69983922 - samples/sec: 151.45\n",
            "2020-03-08 15:52:01,092 epoch 25 - iter 369/417 - loss 6.73071937 - samples/sec: 150.07\n",
            "2020-03-08 15:52:09,920 epoch 25 - iter 410/417 - loss 6.70148979 - samples/sec: 148.82\n",
            "2020-03-08 15:52:11,356 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:52:11,357 EPOCH 25 done: loss 6.7179 - lr 0.1000\n",
            "2020-03-08 15:52:42,729 DEV : loss 0.17859786748886108 - score 0.687731741036533\n",
            "2020-03-08 15:52:44,247 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:53:20,697 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:53:31,761 epoch 26 - iter 41/417 - loss 6.54068585 - samples/sec: 133.41\n",
            "2020-03-08 15:53:41,116 epoch 26 - iter 82/417 - loss 6.43931108 - samples/sec: 140.45\n",
            "2020-03-08 15:53:50,623 epoch 26 - iter 123/417 - loss 6.54549473 - samples/sec: 138.20\n",
            "2020-03-08 15:54:00,028 epoch 26 - iter 164/417 - loss 6.45245490 - samples/sec: 139.67\n",
            "2020-03-08 15:54:09,376 epoch 26 - iter 205/417 - loss 6.51282030 - samples/sec: 140.53\n",
            "2020-03-08 15:54:18,678 epoch 26 - iter 246/417 - loss 6.52899066 - samples/sec: 141.22\n",
            "2020-03-08 15:54:27,777 epoch 26 - iter 287/417 - loss 6.48082459 - samples/sec: 144.36\n",
            "2020-03-08 15:54:36,725 epoch 26 - iter 328/417 - loss 6.46017037 - samples/sec: 146.82\n",
            "2020-03-08 15:54:45,844 epoch 26 - iter 369/417 - loss 6.54007620 - samples/sec: 144.05\n",
            "2020-03-08 15:54:54,790 epoch 26 - iter 410/417 - loss 6.50950459 - samples/sec: 146.84\n",
            "2020-03-08 15:54:56,273 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:54:56,274 EPOCH 26 done: loss 6.5183 - lr 0.1000\n",
            "2020-03-08 15:55:30,173 DEV : loss 0.1978836953639984 - score 0.6854012430872117\n",
            "2020-03-08 15:55:31,690 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 15:55:31,692 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:55:41,537 epoch 27 - iter 41/417 - loss 6.06659568 - samples/sec: 133.32\n",
            "2020-03-08 15:55:50,859 epoch 27 - iter 82/417 - loss 6.25646985 - samples/sec: 140.91\n",
            "2020-03-08 15:55:59,992 epoch 27 - iter 123/417 - loss 6.43927139 - samples/sec: 143.83\n",
            "2020-03-08 15:56:08,701 epoch 27 - iter 164/417 - loss 6.50393873 - samples/sec: 150.85\n",
            "2020-03-08 15:56:17,863 epoch 27 - iter 205/417 - loss 6.52708124 - samples/sec: 143.38\n",
            "2020-03-08 15:56:26,760 epoch 27 - iter 246/417 - loss 6.56945149 - samples/sec: 147.65\n",
            "2020-03-08 15:56:35,719 epoch 27 - iter 287/417 - loss 6.53934589 - samples/sec: 146.63\n",
            "2020-03-08 15:56:44,689 epoch 27 - iter 328/417 - loss 6.52379331 - samples/sec: 146.45\n",
            "2020-03-08 15:56:53,338 epoch 27 - iter 369/417 - loss 6.48734218 - samples/sec: 151.89\n",
            "2020-03-08 15:57:02,485 epoch 27 - iter 410/417 - loss 6.44590023 - samples/sec: 143.60\n",
            "2020-03-08 15:57:04,027 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:57:04,029 EPOCH 27 done: loss 6.4345 - lr 0.1000\n",
            "2020-03-08 15:57:34,409 DEV : loss 0.17240628600120544 - score 0.6988217215264027\n",
            "2020-03-08 15:57:35,940 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 15:58:16,061 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:58:25,879 epoch 28 - iter 41/417 - loss 6.43778991 - samples/sec: 137.51\n",
            "2020-03-08 15:58:34,986 epoch 28 - iter 82/417 - loss 6.30138753 - samples/sec: 144.25\n",
            "2020-03-08 15:58:44,027 epoch 28 - iter 123/417 - loss 6.45627621 - samples/sec: 145.30\n",
            "2020-03-08 15:58:52,669 epoch 28 - iter 164/417 - loss 6.58450848 - samples/sec: 152.02\n",
            "2020-03-08 15:59:01,469 epoch 28 - iter 205/417 - loss 6.52012304 - samples/sec: 149.30\n",
            "2020-03-08 15:59:10,207 epoch 28 - iter 246/417 - loss 6.55687665 - samples/sec: 150.34\n",
            "2020-03-08 15:59:19,204 epoch 28 - iter 287/417 - loss 6.48599176 - samples/sec: 146.03\n",
            "2020-03-08 15:59:28,443 epoch 28 - iter 328/417 - loss 6.47778858 - samples/sec: 142.17\n",
            "2020-03-08 15:59:37,609 epoch 28 - iter 369/417 - loss 6.39292293 - samples/sec: 143.32\n",
            "2020-03-08 15:59:46,907 epoch 28 - iter 410/417 - loss 6.40589534 - samples/sec: 141.27\n",
            "2020-03-08 15:59:48,482 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 15:59:48,484 EPOCH 28 done: loss 6.4003 - lr 0.1000\n",
            "2020-03-08 16:00:19,765 DEV : loss 0.18159998953342438 - score 0.697536989797843\n",
            "2020-03-08 16:00:21,272 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:00:21,274 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:00:31,037 epoch 29 - iter 41/417 - loss 5.90167529 - samples/sec: 134.43\n",
            "2020-03-08 16:00:40,252 epoch 29 - iter 82/417 - loss 6.08774807 - samples/sec: 142.55\n",
            "2020-03-08 16:00:49,392 epoch 29 - iter 123/417 - loss 6.02314960 - samples/sec: 143.74\n",
            "2020-03-08 16:00:58,695 epoch 29 - iter 164/417 - loss 6.14998899 - samples/sec: 141.22\n",
            "2020-03-08 16:01:07,515 epoch 29 - iter 205/417 - loss 6.17375976 - samples/sec: 148.96\n",
            "2020-03-08 16:01:16,408 epoch 29 - iter 246/417 - loss 6.27551597 - samples/sec: 147.74\n",
            "2020-03-08 16:01:24,949 epoch 29 - iter 287/417 - loss 6.23335785 - samples/sec: 153.80\n",
            "2020-03-08 16:01:33,386 epoch 29 - iter 328/417 - loss 6.23109471 - samples/sec: 155.73\n",
            "2020-03-08 16:01:42,155 epoch 29 - iter 369/417 - loss 6.24799489 - samples/sec: 149.78\n",
            "2020-03-08 16:01:51,213 epoch 29 - iter 410/417 - loss 6.27362220 - samples/sec: 145.01\n",
            "2020-03-08 16:01:52,736 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:01:52,737 EPOCH 29 done: loss 6.2735 - lr 0.1000\n",
            "2020-03-08 16:02:26,349 DEV : loss 0.18883948028087616 - score 0.6960761061619098\n",
            "2020-03-08 16:02:27,778 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 16:02:27,779 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:02:37,551 epoch 30 - iter 41/417 - loss 5.69621191 - samples/sec: 134.33\n",
            "2020-03-08 16:02:46,609 epoch 30 - iter 82/417 - loss 5.94157623 - samples/sec: 145.03\n",
            "2020-03-08 16:02:55,836 epoch 30 - iter 123/417 - loss 5.85991612 - samples/sec: 142.35\n",
            "2020-03-08 16:03:05,103 epoch 30 - iter 164/417 - loss 5.84504732 - samples/sec: 141.74\n",
            "2020-03-08 16:03:14,398 epoch 30 - iter 205/417 - loss 5.90285526 - samples/sec: 141.31\n",
            "2020-03-08 16:03:23,445 epoch 30 - iter 246/417 - loss 5.89872642 - samples/sec: 145.22\n",
            "2020-03-08 16:03:32,728 epoch 30 - iter 287/417 - loss 5.97840657 - samples/sec: 141.51\n",
            "2020-03-08 16:03:41,860 epoch 30 - iter 328/417 - loss 6.01407371 - samples/sec: 143.84\n",
            "2020-03-08 16:03:51,041 epoch 30 - iter 369/417 - loss 6.02455642 - samples/sec: 143.07\n",
            "2020-03-08 16:04:00,116 epoch 30 - iter 410/417 - loss 6.04734401 - samples/sec: 144.76\n",
            "2020-03-08 16:04:01,637 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:04:01,639 EPOCH 30 done: loss 6.0676 - lr 0.1000\n",
            "2020-03-08 16:04:32,890 DEV : loss 0.18561166524887085 - score 0.6852367792416483\n",
            "2020-03-08 16:04:34,315 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 16:04:34,317 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:04:43,711 epoch 31 - iter 41/417 - loss 6.15124991 - samples/sec: 139.73\n",
            "2020-03-08 16:04:52,903 epoch 31 - iter 82/417 - loss 6.21589525 - samples/sec: 142.90\n",
            "2020-03-08 16:05:01,987 epoch 31 - iter 123/417 - loss 6.08784760 - samples/sec: 144.61\n",
            "2020-03-08 16:05:11,160 epoch 31 - iter 164/417 - loss 6.14523728 - samples/sec: 143.19\n",
            "2020-03-08 16:05:20,478 epoch 31 - iter 205/417 - loss 6.16374818 - samples/sec: 140.97\n",
            "2020-03-08 16:05:29,698 epoch 31 - iter 246/417 - loss 6.16238004 - samples/sec: 142.47\n",
            "2020-03-08 16:05:39,160 epoch 31 - iter 287/417 - loss 6.17221311 - samples/sec: 138.83\n",
            "2020-03-08 16:05:47,661 epoch 31 - iter 328/417 - loss 6.18318865 - samples/sec: 154.53\n",
            "2020-03-08 16:05:56,373 epoch 31 - iter 369/417 - loss 6.12728540 - samples/sec: 150.78\n",
            "2020-03-08 16:06:05,277 epoch 31 - iter 410/417 - loss 6.12914116 - samples/sec: 147.54\n",
            "2020-03-08 16:06:06,738 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:06:06,739 EPOCH 31 done: loss 6.1258 - lr 0.1000\n",
            "2020-03-08 16:06:39,389 DEV : loss 0.1696927696466446 - score 0.7051027985772997\n",
            "2020-03-08 16:06:40,862 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:07:17,453 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:07:30,537 epoch 32 - iter 41/417 - loss 6.08914467 - samples/sec: 138.24\n",
            "2020-03-08 16:07:40,086 epoch 32 - iter 82/417 - loss 6.10392038 - samples/sec: 137.58\n",
            "2020-03-08 16:07:49,451 epoch 32 - iter 123/417 - loss 6.08752321 - samples/sec: 140.27\n",
            "2020-03-08 16:07:58,699 epoch 32 - iter 164/417 - loss 6.07741422 - samples/sec: 142.06\n",
            "2020-03-08 16:08:07,383 epoch 32 - iter 205/417 - loss 6.05840487 - samples/sec: 151.30\n",
            "2020-03-08 16:08:16,173 epoch 32 - iter 246/417 - loss 5.96664031 - samples/sec: 149.47\n",
            "2020-03-08 16:08:24,987 epoch 32 - iter 287/417 - loss 5.88409185 - samples/sec: 149.05\n",
            "2020-03-08 16:08:33,947 epoch 32 - iter 328/417 - loss 5.88576208 - samples/sec: 146.62\n",
            "2020-03-08 16:08:42,787 epoch 32 - iter 369/417 - loss 5.95009776 - samples/sec: 148.64\n",
            "2020-03-08 16:08:51,546 epoch 32 - iter 410/417 - loss 5.94513588 - samples/sec: 150.00\n",
            "2020-03-08 16:08:52,985 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:08:52,986 EPOCH 32 done: loss 5.9511 - lr 0.1000\n",
            "2020-03-08 16:09:23,895 DEV : loss 0.17199057340621948 - score 0.7052486311633255\n",
            "2020-03-08 16:09:25,314 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:10:01,629 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:10:15,213 epoch 33 - iter 41/417 - loss 6.06799079 - samples/sec: 136.22\n",
            "2020-03-08 16:10:24,606 epoch 33 - iter 82/417 - loss 5.66977873 - samples/sec: 139.86\n",
            "2020-03-08 16:10:33,875 epoch 33 - iter 123/417 - loss 5.71104151 - samples/sec: 141.72\n",
            "2020-03-08 16:10:43,223 epoch 33 - iter 164/417 - loss 5.71097788 - samples/sec: 140.52\n",
            "2020-03-08 16:10:52,452 epoch 33 - iter 205/417 - loss 5.73536189 - samples/sec: 142.36\n",
            "2020-03-08 16:11:01,683 epoch 33 - iter 246/417 - loss 5.74744550 - samples/sec: 142.31\n",
            "2020-03-08 16:11:10,631 epoch 33 - iter 287/417 - loss 5.78483315 - samples/sec: 146.81\n",
            "2020-03-08 16:11:19,513 epoch 33 - iter 328/417 - loss 5.83526393 - samples/sec: 147.91\n",
            "2020-03-08 16:11:28,118 epoch 33 - iter 369/417 - loss 5.84099270 - samples/sec: 152.68\n",
            "2020-03-08 16:11:36,742 epoch 33 - iter 410/417 - loss 5.89553735 - samples/sec: 152.33\n",
            "2020-03-08 16:11:38,121 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:11:38,122 EPOCH 33 done: loss 5.8870 - lr 0.1000\n",
            "2020-03-08 16:12:09,528 DEV : loss 0.17380934953689575 - score 0.6993519048156257\n",
            "2020-03-08 16:12:10,978 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:12:10,980 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:12:20,591 epoch 34 - iter 41/417 - loss 5.56282939 - samples/sec: 136.58\n",
            "2020-03-08 16:12:29,648 epoch 34 - iter 82/417 - loss 5.61202314 - samples/sec: 145.01\n",
            "2020-03-08 16:12:38,825 epoch 34 - iter 123/417 - loss 5.65047453 - samples/sec: 143.16\n",
            "2020-03-08 16:12:48,059 epoch 34 - iter 164/417 - loss 5.67900468 - samples/sec: 142.25\n",
            "2020-03-08 16:12:56,838 epoch 34 - iter 205/417 - loss 5.64728572 - samples/sec: 149.64\n",
            "2020-03-08 16:13:05,712 epoch 34 - iter 246/417 - loss 5.66505900 - samples/sec: 148.02\n",
            "2020-03-08 16:13:14,319 epoch 34 - iter 287/417 - loss 5.74948105 - samples/sec: 152.62\n",
            "2020-03-08 16:13:22,923 epoch 34 - iter 328/417 - loss 5.76107466 - samples/sec: 152.71\n",
            "2020-03-08 16:13:32,087 epoch 34 - iter 369/417 - loss 5.80046974 - samples/sec: 143.33\n",
            "2020-03-08 16:13:41,648 epoch 34 - iter 410/417 - loss 5.82426090 - samples/sec: 137.39\n",
            "2020-03-08 16:13:43,201 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:13:43,203 EPOCH 34 done: loss 5.8255 - lr 0.1000\n",
            "2020-03-08 16:14:17,336 DEV : loss 0.17074185609817505 - score 0.7072546909763788\n",
            "2020-03-08 16:14:18,835 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:14:56,742 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:15:06,865 epoch 35 - iter 41/417 - loss 5.87697316 - samples/sec: 133.18\n",
            "2020-03-08 16:15:16,289 epoch 35 - iter 82/417 - loss 5.79230231 - samples/sec: 139.38\n",
            "2020-03-08 16:15:25,670 epoch 35 - iter 123/417 - loss 5.70270348 - samples/sec: 140.02\n",
            "2020-03-08 16:15:35,155 epoch 35 - iter 164/417 - loss 5.77367426 - samples/sec: 138.48\n",
            "2020-03-08 16:15:44,570 epoch 35 - iter 205/417 - loss 5.67977096 - samples/sec: 139.53\n",
            "2020-03-08 16:15:53,760 epoch 35 - iter 246/417 - loss 5.71265695 - samples/sec: 142.92\n",
            "2020-03-08 16:16:02,697 epoch 35 - iter 287/417 - loss 5.64397492 - samples/sec: 147.00\n",
            "2020-03-08 16:16:11,456 epoch 35 - iter 328/417 - loss 5.67003651 - samples/sec: 149.97\n",
            "2020-03-08 16:16:19,959 epoch 35 - iter 369/417 - loss 5.66118239 - samples/sec: 154.48\n",
            "2020-03-08 16:16:28,723 epoch 35 - iter 410/417 - loss 5.67719550 - samples/sec: 149.92\n",
            "2020-03-08 16:16:30,370 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:16:30,371 EPOCH 35 done: loss 5.6761 - lr 0.1000\n",
            "2020-03-08 16:17:03,507 DEV : loss 0.18024107813835144 - score 0.7110209565849863\n",
            "2020-03-08 16:17:04,985 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:17:41,637 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:17:55,373 epoch 36 - iter 41/417 - loss 5.39179907 - samples/sec: 132.52\n",
            "2020-03-08 16:18:04,964 epoch 36 - iter 82/417 - loss 5.31844414 - samples/sec: 136.97\n",
            "2020-03-08 16:18:14,268 epoch 36 - iter 123/417 - loss 5.36057090 - samples/sec: 141.20\n",
            "2020-03-08 16:18:23,841 epoch 36 - iter 164/417 - loss 5.58688130 - samples/sec: 137.19\n",
            "2020-03-08 16:18:33,082 epoch 36 - iter 205/417 - loss 5.63026689 - samples/sec: 142.17\n",
            "2020-03-08 16:18:41,993 epoch 36 - iter 246/417 - loss 5.64346343 - samples/sec: 147.41\n",
            "2020-03-08 16:18:50,825 epoch 36 - iter 287/417 - loss 5.65026914 - samples/sec: 148.76\n",
            "2020-03-08 16:19:00,360 epoch 36 - iter 328/417 - loss 5.67439563 - samples/sec: 137.78\n",
            "2020-03-08 16:19:09,834 epoch 36 - iter 369/417 - loss 5.67920083 - samples/sec: 138.65\n",
            "2020-03-08 16:19:19,398 epoch 36 - iter 410/417 - loss 5.64482130 - samples/sec: 137.37\n",
            "2020-03-08 16:19:20,979 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:19:20,980 EPOCH 36 done: loss 5.6372 - lr 0.1000\n",
            "2020-03-08 16:19:54,315 DEV : loss 0.16818362474441528 - score 0.7164411690922587\n",
            "2020-03-08 16:19:55,830 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:20:31,822 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:20:44,588 epoch 37 - iter 41/417 - loss 5.78483544 - samples/sec: 134.91\n",
            "2020-03-08 16:20:53,931 epoch 37 - iter 82/417 - loss 5.49702428 - samples/sec: 140.60\n",
            "2020-03-08 16:21:03,281 epoch 37 - iter 123/417 - loss 5.54314183 - samples/sec: 140.49\n",
            "2020-03-08 16:21:12,557 epoch 37 - iter 164/417 - loss 5.62347938 - samples/sec: 141.60\n",
            "2020-03-08 16:21:21,540 epoch 37 - iter 205/417 - loss 5.55379440 - samples/sec: 146.24\n",
            "2020-03-08 16:21:30,517 epoch 37 - iter 246/417 - loss 5.56666850 - samples/sec: 146.32\n",
            "2020-03-08 16:21:39,680 epoch 37 - iter 287/417 - loss 5.62617980 - samples/sec: 143.38\n",
            "2020-03-08 16:21:48,725 epoch 37 - iter 328/417 - loss 5.64136418 - samples/sec: 145.21\n",
            "2020-03-08 16:21:58,014 epoch 37 - iter 369/417 - loss 5.67971150 - samples/sec: 141.42\n",
            "2020-03-08 16:22:07,135 epoch 37 - iter 410/417 - loss 5.65814837 - samples/sec: 144.03\n",
            "2020-03-08 16:22:08,625 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:22:08,626 EPOCH 37 done: loss 5.6623 - lr 0.1000\n",
            "2020-03-08 16:22:39,358 DEV : loss 0.1800607591867447 - score 0.7168625944012867\n",
            "2020-03-08 16:22:40,864 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:23:20,384 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:23:31,009 epoch 38 - iter 41/417 - loss 5.80506456 - samples/sec: 137.27\n",
            "2020-03-08 16:23:40,354 epoch 38 - iter 82/417 - loss 5.53358534 - samples/sec: 140.59\n",
            "2020-03-08 16:23:49,689 epoch 38 - iter 123/417 - loss 5.47957237 - samples/sec: 140.72\n",
            "2020-03-08 16:23:58,904 epoch 38 - iter 164/417 - loss 5.48469603 - samples/sec: 142.54\n",
            "2020-03-08 16:24:08,236 epoch 38 - iter 205/417 - loss 5.50597949 - samples/sec: 140.75\n",
            "2020-03-08 16:24:17,379 epoch 38 - iter 246/417 - loss 5.51347256 - samples/sec: 143.69\n",
            "2020-03-08 16:24:26,568 epoch 38 - iter 287/417 - loss 5.52576557 - samples/sec: 142.97\n",
            "2020-03-08 16:24:35,744 epoch 38 - iter 328/417 - loss 5.57302274 - samples/sec: 143.17\n",
            "2020-03-08 16:24:45,060 epoch 38 - iter 369/417 - loss 5.56367991 - samples/sec: 141.00\n",
            "2020-03-08 16:24:54,491 epoch 38 - iter 410/417 - loss 5.57229787 - samples/sec: 139.27\n",
            "2020-03-08 16:24:56,035 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:24:56,036 EPOCH 38 done: loss 5.5707 - lr 0.1000\n",
            "2020-03-08 16:25:27,216 DEV : loss 0.18585370481014252 - score 0.7167417934857591\n",
            "2020-03-08 16:25:28,732 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:25:28,734 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:25:38,719 epoch 39 - iter 41/417 - loss 5.49602752 - samples/sec: 131.45\n",
            "2020-03-08 16:25:48,032 epoch 39 - iter 82/417 - loss 5.45609876 - samples/sec: 141.06\n",
            "2020-03-08 16:25:57,366 epoch 39 - iter 123/417 - loss 5.34826783 - samples/sec: 140.73\n",
            "2020-03-08 16:26:06,534 epoch 39 - iter 164/417 - loss 5.32851539 - samples/sec: 143.29\n",
            "2020-03-08 16:26:15,221 epoch 39 - iter 205/417 - loss 5.39024759 - samples/sec: 151.22\n",
            "2020-03-08 16:26:24,120 epoch 39 - iter 246/417 - loss 5.33686481 - samples/sec: 147.62\n",
            "2020-03-08 16:26:32,665 epoch 39 - iter 287/417 - loss 5.34719138 - samples/sec: 153.76\n",
            "2020-03-08 16:26:41,314 epoch 39 - iter 328/417 - loss 5.42799797 - samples/sec: 151.89\n",
            "2020-03-08 16:26:50,010 epoch 39 - iter 369/417 - loss 5.40280899 - samples/sec: 151.07\n",
            "2020-03-08 16:26:59,116 epoch 39 - iter 410/417 - loss 5.38757245 - samples/sec: 144.25\n",
            "2020-03-08 16:27:00,776 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:27:00,777 EPOCH 39 done: loss 5.3968 - lr 0.1000\n",
            "2020-03-08 16:27:33,543 DEV : loss 0.16696928441524506 - score 0.7151019188172083\n",
            "2020-03-08 16:27:35,042 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 16:27:35,044 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:27:44,449 epoch 40 - iter 41/417 - loss 5.38116816 - samples/sec: 139.56\n",
            "2020-03-08 16:27:53,904 epoch 40 - iter 82/417 - loss 5.17029103 - samples/sec: 138.92\n",
            "2020-03-08 16:28:03,035 epoch 40 - iter 123/417 - loss 5.22084866 - samples/sec: 143.85\n",
            "2020-03-08 16:28:12,127 epoch 40 - iter 164/417 - loss 5.27719253 - samples/sec: 144.48\n",
            "2020-03-08 16:28:20,962 epoch 40 - iter 205/417 - loss 5.28172628 - samples/sec: 148.68\n",
            "2020-03-08 16:28:29,727 epoch 40 - iter 246/417 - loss 5.34816455 - samples/sec: 149.86\n",
            "2020-03-08 16:28:38,464 epoch 40 - iter 287/417 - loss 5.40779187 - samples/sec: 150.35\n",
            "2020-03-08 16:28:47,835 epoch 40 - iter 328/417 - loss 5.38614576 - samples/sec: 140.17\n",
            "2020-03-08 16:28:56,455 epoch 40 - iter 369/417 - loss 5.42710403 - samples/sec: 152.40\n",
            "2020-03-08 16:29:05,177 epoch 40 - iter 410/417 - loss 5.38670091 - samples/sec: 150.63\n",
            "2020-03-08 16:29:06,606 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:29:06,607 EPOCH 40 done: loss 5.4063 - lr 0.1000\n",
            "2020-03-08 16:29:37,563 DEV : loss 0.16279608011245728 - score 0.7201101256714929\n",
            "2020-03-08 16:29:39,042 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:30:15,234 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:30:28,905 epoch 41 - iter 41/417 - loss 5.10339664 - samples/sec: 137.61\n",
            "2020-03-08 16:30:38,249 epoch 41 - iter 82/417 - loss 5.21022604 - samples/sec: 140.58\n",
            "2020-03-08 16:30:47,681 epoch 41 - iter 123/417 - loss 5.23639041 - samples/sec: 139.29\n",
            "2020-03-08 16:30:57,253 epoch 41 - iter 164/417 - loss 5.30593747 - samples/sec: 137.24\n",
            "2020-03-08 16:31:06,791 epoch 41 - iter 205/417 - loss 5.28584817 - samples/sec: 137.75\n",
            "2020-03-08 16:31:15,682 epoch 41 - iter 246/417 - loss 5.30484363 - samples/sec: 147.76\n",
            "2020-03-08 16:31:24,762 epoch 41 - iter 287/417 - loss 5.30193161 - samples/sec: 144.68\n",
            "2020-03-08 16:31:33,938 epoch 41 - iter 328/417 - loss 5.27771322 - samples/sec: 143.15\n",
            "2020-03-08 16:31:43,180 epoch 41 - iter 369/417 - loss 5.28622007 - samples/sec: 142.11\n",
            "2020-03-08 16:31:52,091 epoch 41 - iter 410/417 - loss 5.32353143 - samples/sec: 147.42\n",
            "2020-03-08 16:31:53,588 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:31:53,589 EPOCH 41 done: loss 5.3253 - lr 0.1000\n",
            "2020-03-08 16:32:24,501 DEV : loss 0.1646367609500885 - score 0.7150715104713649\n",
            "2020-03-08 16:32:26,011 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:32:26,012 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:32:35,458 epoch 42 - iter 41/417 - loss 4.96121989 - samples/sec: 138.95\n",
            "2020-03-08 16:32:44,606 epoch 42 - iter 82/417 - loss 4.95221710 - samples/sec: 143.59\n",
            "2020-03-08 16:32:53,953 epoch 42 - iter 123/417 - loss 5.01565220 - samples/sec: 140.54\n",
            "2020-03-08 16:33:03,173 epoch 42 - iter 164/417 - loss 5.03168326 - samples/sec: 142.46\n",
            "2020-03-08 16:33:12,688 epoch 42 - iter 205/417 - loss 5.07603230 - samples/sec: 138.04\n",
            "2020-03-08 16:33:25,124 epoch 42 - iter 246/417 - loss 5.09224448 - samples/sec: 105.60\n",
            "2020-03-08 16:33:33,898 epoch 42 - iter 287/417 - loss 5.12155297 - samples/sec: 149.71\n",
            "2020-03-08 16:33:42,649 epoch 42 - iter 328/417 - loss 5.16397353 - samples/sec: 150.12\n",
            "2020-03-08 16:33:51,182 epoch 42 - iter 369/417 - loss 5.17017920 - samples/sec: 153.94\n",
            "2020-03-08 16:34:00,530 epoch 42 - iter 410/417 - loss 5.22270668 - samples/sec: 140.51\n",
            "2020-03-08 16:34:02,075 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:34:02,076 EPOCH 42 done: loss 5.2240 - lr 0.1000\n",
            "2020-03-08 16:34:34,789 DEV : loss 0.1895424872636795 - score 0.7215081280409781\n",
            "2020-03-08 16:34:36,277 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:35:12,860 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:35:26,320 epoch 43 - iter 41/417 - loss 5.23325413 - samples/sec: 136.73\n",
            "2020-03-08 16:35:35,656 epoch 43 - iter 82/417 - loss 5.18008810 - samples/sec: 140.70\n",
            "2020-03-08 16:35:44,775 epoch 43 - iter 123/417 - loss 5.16592849 - samples/sec: 144.06\n",
            "2020-03-08 16:35:53,736 epoch 43 - iter 164/417 - loss 5.18330274 - samples/sec: 146.67\n",
            "2020-03-08 16:36:02,495 epoch 43 - iter 205/417 - loss 5.23884810 - samples/sec: 149.99\n",
            "2020-03-08 16:36:11,196 epoch 43 - iter 246/417 - loss 5.17247778 - samples/sec: 150.97\n",
            "2020-03-08 16:36:19,982 epoch 43 - iter 287/417 - loss 5.18805711 - samples/sec: 149.53\n",
            "2020-03-08 16:36:28,907 epoch 43 - iter 328/417 - loss 5.18249815 - samples/sec: 147.20\n",
            "2020-03-08 16:36:37,598 epoch 43 - iter 369/417 - loss 5.16791660 - samples/sec: 151.20\n",
            "2020-03-08 16:36:46,385 epoch 43 - iter 410/417 - loss 5.15543895 - samples/sec: 149.50\n",
            "2020-03-08 16:36:47,828 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:36:47,830 EPOCH 43 done: loss 5.1551 - lr 0.1000\n",
            "2020-03-08 16:37:19,085 DEV : loss 0.25484922528266907 - score 0.6899131090892742\n",
            "2020-03-08 16:37:20,586 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:37:20,588 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:37:30,621 epoch 44 - iter 41/417 - loss 4.80725762 - samples/sec: 130.82\n",
            "2020-03-08 16:37:40,167 epoch 44 - iter 82/417 - loss 4.92182933 - samples/sec: 137.60\n",
            "2020-03-08 16:37:49,770 epoch 44 - iter 123/417 - loss 4.97893082 - samples/sec: 136.77\n",
            "2020-03-08 16:37:58,969 epoch 44 - iter 164/417 - loss 4.99399548 - samples/sec: 142.82\n",
            "2020-03-08 16:38:07,884 epoch 44 - iter 205/417 - loss 4.96783396 - samples/sec: 147.35\n",
            "2020-03-08 16:38:16,919 epoch 44 - iter 246/417 - loss 5.03171603 - samples/sec: 145.42\n",
            "2020-03-08 16:38:25,842 epoch 44 - iter 287/417 - loss 5.05643270 - samples/sec: 147.24\n",
            "2020-03-08 16:38:34,979 epoch 44 - iter 328/417 - loss 5.05336551 - samples/sec: 143.78\n",
            "2020-03-08 16:38:43,610 epoch 44 - iter 369/417 - loss 5.02026127 - samples/sec: 152.22\n",
            "2020-03-08 16:38:52,656 epoch 44 - iter 410/417 - loss 5.08088589 - samples/sec: 145.22\n",
            "2020-03-08 16:38:54,122 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:38:54,124 EPOCH 44 done: loss 5.0751 - lr 0.1000\n",
            "2020-03-08 16:39:24,885 DEV : loss 0.16504037380218506 - score 0.7168980197840329\n",
            "2020-03-08 16:39:26,399 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 16:39:26,400 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:39:35,684 epoch 45 - iter 41/417 - loss 4.93282698 - samples/sec: 141.39\n",
            "2020-03-08 16:39:44,754 epoch 45 - iter 82/417 - loss 5.07423256 - samples/sec: 144.83\n",
            "2020-03-08 16:39:53,892 epoch 45 - iter 123/417 - loss 5.04832588 - samples/sec: 143.76\n",
            "2020-03-08 16:40:03,025 epoch 45 - iter 164/417 - loss 5.06584941 - samples/sec: 143.85\n",
            "2020-03-08 16:40:12,098 epoch 45 - iter 205/417 - loss 5.01714290 - samples/sec: 144.80\n",
            "2020-03-08 16:40:21,176 epoch 45 - iter 246/417 - loss 5.04206677 - samples/sec: 144.71\n",
            "2020-03-08 16:40:30,261 epoch 45 - iter 287/417 - loss 4.98598039 - samples/sec: 144.60\n",
            "2020-03-08 16:40:39,173 epoch 45 - iter 328/417 - loss 4.96899361 - samples/sec: 147.40\n",
            "2020-03-08 16:40:48,097 epoch 45 - iter 369/417 - loss 5.04584080 - samples/sec: 147.22\n",
            "2020-03-08 16:40:56,844 epoch 45 - iter 410/417 - loss 5.03119750 - samples/sec: 150.19\n",
            "2020-03-08 16:40:58,294 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:40:58,295 EPOCH 45 done: loss 5.0319 - lr 0.1000\n",
            "2020-03-08 16:41:30,907 DEV : loss 0.19439774751663208 - score 0.7112800902804525\n",
            "2020-03-08 16:41:32,402 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 16:41:32,403 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:41:42,053 epoch 46 - iter 41/417 - loss 4.83752094 - samples/sec: 136.02\n",
            "2020-03-08 16:41:51,239 epoch 46 - iter 82/417 - loss 4.81395926 - samples/sec: 142.99\n",
            "2020-03-08 16:42:00,671 epoch 46 - iter 123/417 - loss 4.81450803 - samples/sec: 139.28\n",
            "2020-03-08 16:42:09,640 epoch 46 - iter 164/417 - loss 4.83726014 - samples/sec: 146.49\n",
            "2020-03-08 16:42:18,466 epoch 46 - iter 205/417 - loss 4.89465980 - samples/sec: 148.87\n",
            "2020-03-08 16:42:27,105 epoch 46 - iter 246/417 - loss 4.95247768 - samples/sec: 152.06\n",
            "2020-03-08 16:42:35,875 epoch 46 - iter 287/417 - loss 4.97374969 - samples/sec: 149.78\n",
            "2020-03-08 16:42:44,759 epoch 46 - iter 328/417 - loss 4.97690227 - samples/sec: 147.87\n",
            "2020-03-08 16:42:53,453 epoch 46 - iter 369/417 - loss 4.97783646 - samples/sec: 151.10\n",
            "2020-03-08 16:43:02,221 epoch 46 - iter 410/417 - loss 5.00165319 - samples/sec: 149.83\n",
            "2020-03-08 16:43:03,609 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:43:03,611 EPOCH 46 done: loss 5.0048 - lr 0.1000\n",
            "2020-03-08 16:43:34,301 DEV : loss 0.18140576779842377 - score 0.7109612766103577\n",
            "Epoch    46: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-03-08 16:43:35,798 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 16:43:35,800 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:43:45,562 epoch 47 - iter 41/417 - loss 4.60697801 - samples/sec: 134.46\n",
            "2020-03-08 16:43:54,995 epoch 47 - iter 82/417 - loss 4.57545606 - samples/sec: 139.25\n",
            "2020-03-08 16:44:04,696 epoch 47 - iter 123/417 - loss 4.47107430 - samples/sec: 135.39\n",
            "2020-03-08 16:44:13,727 epoch 47 - iter 164/417 - loss 4.40715257 - samples/sec: 145.47\n",
            "2020-03-08 16:44:22,686 epoch 47 - iter 205/417 - loss 4.42093222 - samples/sec: 146.63\n",
            "2020-03-08 16:44:32,284 epoch 47 - iter 246/417 - loss 4.39385785 - samples/sec: 136.85\n",
            "2020-03-08 16:44:41,285 epoch 47 - iter 287/417 - loss 4.37796596 - samples/sec: 145.99\n",
            "2020-03-08 16:44:50,320 epoch 47 - iter 328/417 - loss 4.37867899 - samples/sec: 145.38\n",
            "2020-03-08 16:44:59,419 epoch 47 - iter 369/417 - loss 4.37550743 - samples/sec: 144.40\n",
            "2020-03-08 16:45:08,647 epoch 47 - iter 410/417 - loss 4.38881121 - samples/sec: 142.37\n",
            "2020-03-08 16:45:10,249 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:45:10,250 EPOCH 47 done: loss 4.3917 - lr 0.0500\n",
            "2020-03-08 16:45:43,205 DEV : loss 0.16259801387786865 - score 0.7267099188486756\n",
            "2020-03-08 16:45:44,697 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:46:21,250 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:46:35,634 epoch 48 - iter 41/417 - loss 4.09513089 - samples/sec: 136.33\n",
            "2020-03-08 16:46:45,236 epoch 48 - iter 82/417 - loss 4.28147115 - samples/sec: 136.80\n",
            "2020-03-08 16:46:54,602 epoch 48 - iter 123/417 - loss 4.28442912 - samples/sec: 140.26\n",
            "2020-03-08 16:47:03,581 epoch 48 - iter 164/417 - loss 4.24975395 - samples/sec: 146.34\n",
            "2020-03-08 16:47:12,174 epoch 48 - iter 205/417 - loss 4.25208470 - samples/sec: 152.90\n",
            "2020-03-08 16:47:20,977 epoch 48 - iter 246/417 - loss 4.25658025 - samples/sec: 149.23\n",
            "2020-03-08 16:47:30,061 epoch 48 - iter 287/417 - loss 4.25081646 - samples/sec: 144.64\n",
            "2020-03-08 16:47:39,584 epoch 48 - iter 328/417 - loss 4.23284981 - samples/sec: 137.94\n",
            "2020-03-08 16:47:48,964 epoch 48 - iter 369/417 - loss 4.18510019 - samples/sec: 140.06\n",
            "2020-03-08 16:47:57,864 epoch 48 - iter 410/417 - loss 4.19251075 - samples/sec: 147.62\n",
            "2020-03-08 16:47:59,338 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:47:59,339 EPOCH 48 done: loss 4.1939 - lr 0.0500\n",
            "2020-03-08 16:48:30,905 DEV : loss 0.16771960258483887 - score 0.7275016426220052\n",
            "2020-03-08 16:48:32,394 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:49:11,461 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:49:23,088 epoch 49 - iter 41/417 - loss 4.05060180 - samples/sec: 138.32\n",
            "2020-03-08 16:49:32,276 epoch 49 - iter 82/417 - loss 4.15844477 - samples/sec: 142.98\n",
            "2020-03-08 16:49:41,411 epoch 49 - iter 123/417 - loss 4.16848844 - samples/sec: 143.80\n",
            "2020-03-08 16:49:50,583 epoch 49 - iter 164/417 - loss 4.05466731 - samples/sec: 143.24\n",
            "2020-03-08 16:49:59,763 epoch 49 - iter 205/417 - loss 4.03965981 - samples/sec: 143.12\n",
            "2020-03-08 16:50:08,708 epoch 49 - iter 246/417 - loss 4.06834109 - samples/sec: 146.89\n",
            "2020-03-08 16:50:17,175 epoch 49 - iter 287/417 - loss 4.10367551 - samples/sec: 155.16\n",
            "2020-03-08 16:50:26,333 epoch 49 - iter 328/417 - loss 4.05976076 - samples/sec: 143.45\n",
            "2020-03-08 16:50:35,571 epoch 49 - iter 369/417 - loss 4.04490541 - samples/sec: 142.22\n",
            "2020-03-08 16:50:44,597 epoch 49 - iter 410/417 - loss 4.05365129 - samples/sec: 145.54\n",
            "2020-03-08 16:50:46,146 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:50:46,147 EPOCH 49 done: loss 4.0500 - lr 0.0500\n",
            "2020-03-08 16:51:20,170 DEV : loss 0.18865731358528137 - score 0.7247881177567678\n",
            "2020-03-08 16:51:21,678 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:51:21,680 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:51:30,876 epoch 50 - iter 41/417 - loss 3.73031094 - samples/sec: 142.72\n",
            "2020-03-08 16:51:39,718 epoch 50 - iter 82/417 - loss 3.95967896 - samples/sec: 148.57\n",
            "2020-03-08 16:51:48,669 epoch 50 - iter 123/417 - loss 3.90253534 - samples/sec: 146.78\n",
            "2020-03-08 16:51:57,436 epoch 50 - iter 164/417 - loss 4.02978905 - samples/sec: 149.85\n",
            "2020-03-08 16:52:06,833 epoch 50 - iter 205/417 - loss 4.00503340 - samples/sec: 139.79\n",
            "2020-03-08 16:52:15,900 epoch 50 - iter 246/417 - loss 4.03320117 - samples/sec: 144.87\n",
            "2020-03-08 16:52:24,918 epoch 50 - iter 287/417 - loss 4.00386433 - samples/sec: 145.67\n",
            "2020-03-08 16:52:34,074 epoch 50 - iter 328/417 - loss 4.00246209 - samples/sec: 143.48\n",
            "2020-03-08 16:52:43,107 epoch 50 - iter 369/417 - loss 4.00761445 - samples/sec: 145.42\n",
            "2020-03-08 16:52:51,550 epoch 50 - iter 410/417 - loss 4.02544230 - samples/sec: 155.59\n",
            "2020-03-08 16:52:53,147 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:52:53,148 EPOCH 50 done: loss 4.0166 - lr 0.0500\n",
            "2020-03-08 16:53:25,111 DEV : loss 0.18297407031059265 - score 0.7232574705270763\n",
            "2020-03-08 16:53:26,637 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 16:53:26,639 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:53:36,477 epoch 51 - iter 41/417 - loss 3.56655104 - samples/sec: 133.42\n",
            "2020-03-08 16:53:45,391 epoch 51 - iter 82/417 - loss 3.84929704 - samples/sec: 147.39\n",
            "2020-03-08 16:53:54,431 epoch 51 - iter 123/417 - loss 3.88432705 - samples/sec: 145.29\n",
            "2020-03-08 16:54:03,641 epoch 51 - iter 164/417 - loss 3.82173467 - samples/sec: 142.60\n",
            "2020-03-08 16:54:13,151 epoch 51 - iter 205/417 - loss 3.83939785 - samples/sec: 138.11\n",
            "2020-03-08 16:54:22,394 epoch 51 - iter 246/417 - loss 3.86730905 - samples/sec: 142.11\n",
            "2020-03-08 16:54:31,734 epoch 51 - iter 287/417 - loss 3.87893371 - samples/sec: 140.63\n",
            "2020-03-08 16:54:40,387 epoch 51 - iter 328/417 - loss 3.89057060 - samples/sec: 151.80\n",
            "2020-03-08 16:54:49,203 epoch 51 - iter 369/417 - loss 3.93885230 - samples/sec: 149.00\n",
            "2020-03-08 16:54:58,486 epoch 51 - iter 410/417 - loss 3.94233021 - samples/sec: 141.48\n",
            "2020-03-08 16:55:00,043 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:55:00,044 EPOCH 51 done: loss 3.9385 - lr 0.0500\n",
            "2020-03-08 16:55:31,999 DEV : loss 0.16620956361293793 - score 0.732067951694912\n",
            "2020-03-08 16:55:33,482 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 16:56:10,662 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:56:22,719 epoch 52 - iter 41/417 - loss 3.79306193 - samples/sec: 137.01\n",
            "2020-03-08 16:56:31,941 epoch 52 - iter 82/417 - loss 3.96667514 - samples/sec: 142.46\n",
            "2020-03-08 16:56:41,073 epoch 52 - iter 123/417 - loss 3.98893933 - samples/sec: 143.86\n",
            "2020-03-08 16:56:50,449 epoch 52 - iter 164/417 - loss 3.94545396 - samples/sec: 140.09\n",
            "2020-03-08 16:56:59,925 epoch 52 - iter 205/417 - loss 3.90932960 - samples/sec: 138.60\n",
            "2020-03-08 16:57:09,092 epoch 52 - iter 246/417 - loss 3.94613579 - samples/sec: 143.31\n",
            "2020-03-08 16:57:17,960 epoch 52 - iter 287/417 - loss 3.92852091 - samples/sec: 148.14\n",
            "2020-03-08 16:57:27,441 epoch 52 - iter 328/417 - loss 3.92181203 - samples/sec: 138.54\n",
            "2020-03-08 16:57:36,743 epoch 52 - iter 369/417 - loss 3.91456607 - samples/sec: 141.20\n",
            "2020-03-08 16:57:45,767 epoch 52 - iter 410/417 - loss 3.93764070 - samples/sec: 145.56\n",
            "2020-03-08 16:57:47,253 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:57:47,254 EPOCH 52 done: loss 3.9297 - lr 0.0500\n",
            "2020-03-08 16:58:18,581 DEV : loss 0.16662991046905518 - score 0.7314171465901516\n",
            "2020-03-08 16:58:20,078 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 16:58:20,079 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:58:29,668 epoch 53 - iter 41/417 - loss 3.80280316 - samples/sec: 136.88\n",
            "2020-03-08 16:58:39,317 epoch 53 - iter 82/417 - loss 3.84455326 - samples/sec: 136.14\n",
            "2020-03-08 16:58:48,281 epoch 53 - iter 123/417 - loss 3.91674339 - samples/sec: 146.57\n",
            "2020-03-08 16:58:57,212 epoch 53 - iter 164/417 - loss 3.82421311 - samples/sec: 147.10\n",
            "2020-03-08 16:59:06,166 epoch 53 - iter 205/417 - loss 3.79759868 - samples/sec: 146.71\n",
            "2020-03-08 16:59:14,819 epoch 53 - iter 246/417 - loss 3.79263867 - samples/sec: 151.82\n",
            "2020-03-08 16:59:23,520 epoch 53 - iter 287/417 - loss 3.77804395 - samples/sec: 151.01\n",
            "2020-03-08 16:59:32,135 epoch 53 - iter 328/417 - loss 3.77099020 - samples/sec: 152.50\n",
            "2020-03-08 16:59:41,062 epoch 53 - iter 369/417 - loss 3.77978928 - samples/sec: 147.16\n",
            "2020-03-08 16:59:49,967 epoch 53 - iter 410/417 - loss 3.81243813 - samples/sec: 147.54\n",
            "2020-03-08 16:59:51,354 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 16:59:51,355 EPOCH 53 done: loss 3.8180 - lr 0.0500\n",
            "2020-03-08 17:00:20,843 DEV : loss 0.17946740984916687 - score 0.7351230719988364\n",
            "2020-03-08 17:00:22,322 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 17:01:00,283 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:01:12,656 epoch 54 - iter 41/417 - loss 3.70760762 - samples/sec: 138.28\n",
            "2020-03-08 17:01:21,960 epoch 54 - iter 82/417 - loss 3.69874670 - samples/sec: 141.21\n",
            "2020-03-08 17:01:31,075 epoch 54 - iter 123/417 - loss 3.62607701 - samples/sec: 144.13\n",
            "2020-03-08 17:01:39,932 epoch 54 - iter 164/417 - loss 3.64412284 - samples/sec: 148.32\n",
            "2020-03-08 17:01:48,848 epoch 54 - iter 205/417 - loss 3.69905809 - samples/sec: 147.35\n",
            "2020-03-08 17:01:58,131 epoch 54 - iter 246/417 - loss 3.78633462 - samples/sec: 141.53\n",
            "2020-03-08 17:02:06,914 epoch 54 - iter 287/417 - loss 3.77625900 - samples/sec: 149.60\n",
            "2020-03-08 17:02:15,707 epoch 54 - iter 328/417 - loss 3.73977374 - samples/sec: 149.40\n",
            "2020-03-08 17:02:24,666 epoch 54 - iter 369/417 - loss 3.70250186 - samples/sec: 146.64\n",
            "2020-03-08 17:02:33,311 epoch 54 - iter 410/417 - loss 3.73105044 - samples/sec: 151.97\n",
            "2020-03-08 17:02:34,788 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:02:34,790 EPOCH 54 done: loss 3.7253 - lr 0.0500\n",
            "2020-03-08 17:03:04,670 DEV : loss 0.17802277207374573 - score 0.7295218305049147\n",
            "2020-03-08 17:03:06,083 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:03:06,085 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:03:15,568 epoch 55 - iter 41/417 - loss 3.60644053 - samples/sec: 138.41\n",
            "2020-03-08 17:03:24,501 epoch 55 - iter 82/417 - loss 3.67807966 - samples/sec: 147.07\n",
            "2020-03-08 17:03:33,018 epoch 55 - iter 123/417 - loss 3.65513855 - samples/sec: 154.25\n",
            "2020-03-08 17:03:41,451 epoch 55 - iter 164/417 - loss 3.63808404 - samples/sec: 155.79\n",
            "2020-03-08 17:03:50,218 epoch 55 - iter 205/417 - loss 3.64240356 - samples/sec: 149.85\n",
            "2020-03-08 17:03:59,541 epoch 55 - iter 246/417 - loss 3.69562048 - samples/sec: 140.90\n",
            "2020-03-08 17:04:08,679 epoch 55 - iter 287/417 - loss 3.68439069 - samples/sec: 143.77\n",
            "2020-03-08 17:04:17,430 epoch 55 - iter 328/417 - loss 3.69907832 - samples/sec: 150.10\n",
            "2020-03-08 17:04:26,337 epoch 55 - iter 369/417 - loss 3.66776283 - samples/sec: 147.49\n",
            "2020-03-08 17:04:34,959 epoch 55 - iter 410/417 - loss 3.64462625 - samples/sec: 152.37\n",
            "2020-03-08 17:04:36,401 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:04:36,402 EPOCH 55 done: loss 3.6462 - lr 0.0500\n",
            "2020-03-08 17:05:08,564 DEV : loss 0.18234883248806 - score 0.7237733755845664\n",
            "2020-03-08 17:05:09,988 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:05:09,990 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:05:19,422 epoch 56 - iter 41/417 - loss 3.56551218 - samples/sec: 139.17\n",
            "2020-03-08 17:05:28,775 epoch 56 - iter 82/417 - loss 3.54068757 - samples/sec: 140.43\n",
            "2020-03-08 17:05:38,142 epoch 56 - iter 123/417 - loss 3.49901233 - samples/sec: 140.26\n",
            "2020-03-08 17:05:47,457 epoch 56 - iter 164/417 - loss 3.50538133 - samples/sec: 141.03\n",
            "2020-03-08 17:05:56,524 epoch 56 - iter 205/417 - loss 3.56489297 - samples/sec: 144.89\n",
            "2020-03-08 17:06:05,858 epoch 56 - iter 246/417 - loss 3.61235718 - samples/sec: 140.70\n",
            "2020-03-08 17:06:14,693 epoch 56 - iter 287/417 - loss 3.61317214 - samples/sec: 148.71\n",
            "2020-03-08 17:06:23,477 epoch 56 - iter 328/417 - loss 3.60922920 - samples/sec: 149.56\n",
            "2020-03-08 17:06:32,294 epoch 56 - iter 369/417 - loss 3.61566819 - samples/sec: 149.01\n",
            "2020-03-08 17:06:41,008 epoch 56 - iter 410/417 - loss 3.61691888 - samples/sec: 150.75\n",
            "2020-03-08 17:06:42,450 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:06:42,451 EPOCH 56 done: loss 3.6313 - lr 0.0500\n",
            "2020-03-08 17:07:14,158 DEV : loss 0.15922291576862335 - score 0.7353540928740856\n",
            "2020-03-08 17:07:15,590 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 17:07:51,526 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:08:01,610 epoch 57 - iter 41/417 - loss 3.57098190 - samples/sec: 139.40\n",
            "2020-03-08 17:08:10,513 epoch 57 - iter 82/417 - loss 3.60587254 - samples/sec: 147.55\n",
            "2020-03-08 17:08:19,659 epoch 57 - iter 123/417 - loss 3.67562238 - samples/sec: 143.63\n",
            "2020-03-08 17:08:28,772 epoch 57 - iter 164/417 - loss 3.61034742 - samples/sec: 144.14\n",
            "2020-03-08 17:08:37,546 epoch 57 - iter 205/417 - loss 3.65675871 - samples/sec: 149.70\n",
            "2020-03-08 17:08:46,267 epoch 57 - iter 246/417 - loss 3.60496965 - samples/sec: 150.63\n",
            "2020-03-08 17:08:54,870 epoch 57 - iter 287/417 - loss 3.58996357 - samples/sec: 152.68\n",
            "2020-03-08 17:09:03,853 epoch 57 - iter 328/417 - loss 3.60024807 - samples/sec: 146.25\n",
            "2020-03-08 17:09:13,296 epoch 57 - iter 369/417 - loss 3.61399294 - samples/sec: 139.12\n",
            "2020-03-08 17:09:22,626 epoch 57 - iter 410/417 - loss 3.61914139 - samples/sec: 140.79\n",
            "2020-03-08 17:09:27,475 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:09:27,476 EPOCH 57 done: loss 3.6250 - lr 0.0500\n",
            "2020-03-08 17:09:58,796 DEV : loss 0.18630710244178772 - score 0.7250574369463262\n",
            "2020-03-08 17:10:00,248 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:10:00,250 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:10:09,857 epoch 58 - iter 41/417 - loss 3.43079568 - samples/sec: 136.62\n",
            "2020-03-08 17:10:18,810 epoch 58 - iter 82/417 - loss 3.55968311 - samples/sec: 146.75\n",
            "2020-03-08 17:10:27,560 epoch 58 - iter 123/417 - loss 3.62329648 - samples/sec: 150.17\n",
            "2020-03-08 17:10:36,357 epoch 58 - iter 164/417 - loss 3.58158488 - samples/sec: 149.34\n",
            "2020-03-08 17:10:45,576 epoch 58 - iter 205/417 - loss 3.57956832 - samples/sec: 142.48\n",
            "2020-03-08 17:10:54,335 epoch 58 - iter 246/417 - loss 3.52921815 - samples/sec: 149.96\n",
            "2020-03-08 17:11:03,299 epoch 58 - iter 287/417 - loss 3.52896174 - samples/sec: 146.56\n",
            "2020-03-08 17:11:12,169 epoch 58 - iter 328/417 - loss 3.54230262 - samples/sec: 148.09\n",
            "2020-03-08 17:11:20,946 epoch 58 - iter 369/417 - loss 3.53823228 - samples/sec: 149.68\n",
            "2020-03-08 17:11:29,672 epoch 58 - iter 410/417 - loss 3.49961966 - samples/sec: 150.54\n",
            "2020-03-08 17:11:31,230 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:11:31,231 EPOCH 58 done: loss 3.5092 - lr 0.0500\n",
            "2020-03-08 17:12:03,598 DEV : loss 0.1758722960948944 - score 0.724924995040818\n",
            "2020-03-08 17:12:05,048 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:12:05,049 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:12:14,767 epoch 59 - iter 41/417 - loss 3.09230993 - samples/sec: 135.08\n",
            "2020-03-08 17:12:24,069 epoch 59 - iter 82/417 - loss 3.24159260 - samples/sec: 141.21\n",
            "2020-03-08 17:12:33,195 epoch 59 - iter 123/417 - loss 3.26993211 - samples/sec: 143.93\n",
            "2020-03-08 17:12:42,518 epoch 59 - iter 164/417 - loss 3.30200664 - samples/sec: 140.93\n",
            "2020-03-08 17:12:51,768 epoch 59 - iter 205/417 - loss 3.27070134 - samples/sec: 142.03\n",
            "2020-03-08 17:13:00,967 epoch 59 - iter 246/417 - loss 3.30854471 - samples/sec: 142.82\n",
            "2020-03-08 17:13:09,821 epoch 59 - iter 287/417 - loss 3.31956991 - samples/sec: 148.40\n",
            "2020-03-08 17:13:18,634 epoch 59 - iter 328/417 - loss 3.34611111 - samples/sec: 149.08\n",
            "2020-03-08 17:13:28,114 epoch 59 - iter 369/417 - loss 3.35791401 - samples/sec: 138.58\n",
            "2020-03-08 17:13:37,419 epoch 59 - iter 410/417 - loss 3.37422134 - samples/sec: 141.17\n",
            "2020-03-08 17:13:39,003 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:13:39,004 EPOCH 59 done: loss 3.3909 - lr 0.0500\n",
            "2020-03-08 17:14:10,282 DEV : loss 0.17288343608379364 - score 0.7293862915083914\n",
            "2020-03-08 17:14:11,763 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:14:11,764 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:14:21,202 epoch 60 - iter 41/417 - loss 3.37077306 - samples/sec: 139.11\n",
            "2020-03-08 17:14:30,609 epoch 60 - iter 82/417 - loss 3.20928286 - samples/sec: 139.67\n",
            "2020-03-08 17:14:40,069 epoch 60 - iter 123/417 - loss 3.39695876 - samples/sec: 138.85\n",
            "2020-03-08 17:14:49,501 epoch 60 - iter 164/417 - loss 3.33842400 - samples/sec: 139.29\n",
            "2020-03-08 17:14:58,908 epoch 60 - iter 205/417 - loss 3.35175463 - samples/sec: 139.65\n",
            "2020-03-08 17:15:08,471 epoch 60 - iter 246/417 - loss 3.36934644 - samples/sec: 137.38\n",
            "2020-03-08 17:15:17,768 epoch 60 - iter 287/417 - loss 3.38986513 - samples/sec: 141.30\n",
            "2020-03-08 17:15:26,926 epoch 60 - iter 328/417 - loss 3.40378703 - samples/sec: 143.46\n",
            "2020-03-08 17:15:35,855 epoch 60 - iter 369/417 - loss 3.39922031 - samples/sec: 147.14\n",
            "2020-03-08 17:15:44,955 epoch 60 - iter 410/417 - loss 3.38400560 - samples/sec: 144.37\n",
            "2020-03-08 17:15:46,509 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:15:46,510 EPOCH 60 done: loss 3.3769 - lr 0.0500\n",
            "2020-03-08 17:16:19,260 DEV : loss 0.22515641152858734 - score 0.7203433018467522\n",
            "Epoch    60: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-03-08 17:16:20,766 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:16:20,768 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:16:30,426 epoch 61 - iter 41/417 - loss 3.13232278 - samples/sec: 135.89\n",
            "2020-03-08 17:16:39,671 epoch 61 - iter 82/417 - loss 3.10185680 - samples/sec: 142.08\n",
            "2020-03-08 17:16:49,155 epoch 61 - iter 123/417 - loss 3.06933617 - samples/sec: 138.50\n",
            "2020-03-08 17:16:58,277 epoch 61 - iter 164/417 - loss 3.05647427 - samples/sec: 144.01\n",
            "2020-03-08 17:17:07,404 epoch 61 - iter 205/417 - loss 3.02632688 - samples/sec: 143.91\n",
            "2020-03-08 17:17:16,545 epoch 61 - iter 246/417 - loss 3.06020315 - samples/sec: 143.70\n",
            "2020-03-08 17:17:25,428 epoch 61 - iter 287/417 - loss 3.06220703 - samples/sec: 147.87\n",
            "2020-03-08 17:17:34,094 epoch 61 - iter 328/417 - loss 3.07375476 - samples/sec: 151.62\n",
            "2020-03-08 17:17:43,065 epoch 61 - iter 369/417 - loss 3.07999328 - samples/sec: 146.45\n",
            "2020-03-08 17:17:52,434 epoch 61 - iter 410/417 - loss 3.09212353 - samples/sec: 140.21\n",
            "2020-03-08 17:17:54,006 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:17:54,007 EPOCH 61 done: loss 3.0884 - lr 0.0250\n",
            "2020-03-08 17:18:25,186 DEV : loss 0.16613508760929108 - score 0.7323543464900888\n",
            "2020-03-08 17:18:26,708 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:18:26,710 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:18:36,756 epoch 62 - iter 41/417 - loss 2.64865773 - samples/sec: 130.65\n",
            "2020-03-08 17:18:45,833 epoch 62 - iter 82/417 - loss 2.79038337 - samples/sec: 144.72\n",
            "2020-03-08 17:18:55,089 epoch 62 - iter 123/417 - loss 2.81732558 - samples/sec: 141.94\n",
            "2020-03-08 17:19:03,908 epoch 62 - iter 164/417 - loss 2.84119081 - samples/sec: 148.96\n",
            "2020-03-08 17:19:12,671 epoch 62 - iter 205/417 - loss 2.85022302 - samples/sec: 149.91\n",
            "2020-03-08 17:19:21,713 epoch 62 - iter 246/417 - loss 2.86601306 - samples/sec: 145.28\n",
            "2020-03-08 17:19:31,045 epoch 62 - iter 287/417 - loss 2.87339855 - samples/sec: 140.78\n",
            "2020-03-08 17:19:40,397 epoch 62 - iter 328/417 - loss 2.91878922 - samples/sec: 140.45\n",
            "2020-03-08 17:19:49,284 epoch 62 - iter 369/417 - loss 2.91182929 - samples/sec: 147.81\n",
            "2020-03-08 17:19:58,173 epoch 62 - iter 410/417 - loss 2.94493045 - samples/sec: 147.78\n",
            "2020-03-08 17:19:59,684 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:19:59,685 EPOCH 62 done: loss 2.9373 - lr 0.0250\n",
            "2020-03-08 17:20:31,789 DEV : loss 0.17062880098819733 - score 0.7314143295550999\n",
            "2020-03-08 17:20:33,274 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:20:33,275 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:20:42,813 epoch 63 - iter 41/417 - loss 3.02395679 - samples/sec: 137.61\n",
            "2020-03-08 17:20:51,780 epoch 63 - iter 82/417 - loss 2.79043202 - samples/sec: 146.50\n",
            "2020-03-08 17:21:00,825 epoch 63 - iter 123/417 - loss 2.72878754 - samples/sec: 145.24\n",
            "2020-03-08 17:21:09,716 epoch 63 - iter 164/417 - loss 2.79197126 - samples/sec: 147.74\n",
            "2020-03-08 17:21:18,573 epoch 63 - iter 205/417 - loss 2.76590415 - samples/sec: 148.31\n",
            "2020-03-08 17:21:27,384 epoch 63 - iter 246/417 - loss 2.84705616 - samples/sec: 149.10\n",
            "2020-03-08 17:21:36,233 epoch 63 - iter 287/417 - loss 2.89987445 - samples/sec: 148.45\n",
            "2020-03-08 17:21:45,061 epoch 63 - iter 328/417 - loss 2.90811680 - samples/sec: 148.79\n",
            "2020-03-08 17:21:54,196 epoch 63 - iter 369/417 - loss 2.92071448 - samples/sec: 143.81\n",
            "2020-03-08 17:22:03,177 epoch 63 - iter 410/417 - loss 2.94169483 - samples/sec: 146.27\n",
            "2020-03-08 17:22:04,653 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:22:04,654 EPOCH 63 done: loss 2.9342 - lr 0.0250\n",
            "2020-03-08 17:22:34,775 DEV : loss 0.16816365718841553 - score 0.7378075252139934\n",
            "2020-03-08 17:22:36,266 BAD EPOCHS (no improvement): 0\n",
            "2020-03-08 17:23:12,550 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:23:25,517 epoch 64 - iter 41/417 - loss 2.95560267 - samples/sec: 137.64\n",
            "2020-03-08 17:23:34,682 epoch 64 - iter 82/417 - loss 2.89339019 - samples/sec: 143.33\n",
            "2020-03-08 17:23:43,896 epoch 64 - iter 123/417 - loss 2.89653113 - samples/sec: 142.57\n",
            "2020-03-08 17:23:53,151 epoch 64 - iter 164/417 - loss 2.92376602 - samples/sec: 141.92\n",
            "2020-03-08 17:24:02,143 epoch 64 - iter 205/417 - loss 2.89156265 - samples/sec: 146.10\n",
            "2020-03-08 17:24:11,007 epoch 64 - iter 246/417 - loss 2.91006935 - samples/sec: 148.20\n",
            "2020-03-08 17:24:19,629 epoch 64 - iter 287/417 - loss 2.95322933 - samples/sec: 152.38\n",
            "2020-03-08 17:24:28,209 epoch 64 - iter 328/417 - loss 2.92815327 - samples/sec: 153.12\n",
            "2020-03-08 17:24:37,425 epoch 64 - iter 369/417 - loss 2.92546423 - samples/sec: 142.54\n",
            "2020-03-08 17:24:46,621 epoch 64 - iter 410/417 - loss 2.92696247 - samples/sec: 142.84\n",
            "2020-03-08 17:24:48,129 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:24:48,130 EPOCH 64 done: loss 2.9296 - lr 0.0250\n",
            "2020-03-08 17:25:18,641 DEV : loss 0.16475145518779755 - score 0.7344501707382011\n",
            "2020-03-08 17:25:20,133 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:25:20,134 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:25:29,520 epoch 65 - iter 41/417 - loss 2.74387429 - samples/sec: 139.86\n",
            "2020-03-08 17:25:38,891 epoch 65 - iter 82/417 - loss 2.71382915 - samples/sec: 140.18\n",
            "2020-03-08 17:25:48,226 epoch 65 - iter 123/417 - loss 2.69431343 - samples/sec: 140.70\n",
            "2020-03-08 17:25:57,625 epoch 65 - iter 164/417 - loss 2.76176247 - samples/sec: 139.74\n",
            "2020-03-08 17:26:06,886 epoch 65 - iter 205/417 - loss 2.77735710 - samples/sec: 141.83\n",
            "2020-03-08 17:26:16,227 epoch 65 - iter 246/417 - loss 2.80268595 - samples/sec: 140.61\n",
            "2020-03-08 17:26:25,288 epoch 65 - iter 287/417 - loss 2.81612763 - samples/sec: 144.96\n",
            "2020-03-08 17:26:37,805 epoch 65 - iter 328/417 - loss 2.82108029 - samples/sec: 104.91\n",
            "2020-03-08 17:26:46,957 epoch 65 - iter 369/417 - loss 2.83072791 - samples/sec: 143.55\n",
            "2020-03-08 17:26:56,377 epoch 65 - iter 410/417 - loss 2.81510299 - samples/sec: 139.47\n",
            "2020-03-08 17:26:57,903 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:26:57,905 EPOCH 65 done: loss 2.8030 - lr 0.0250\n",
            "2020-03-08 17:27:27,793 DEV : loss 0.16871574521064758 - score 0.7335643927748855\n",
            "2020-03-08 17:27:29,295 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:27:29,297 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:27:38,078 epoch 66 - iter 41/417 - loss 3.12600421 - samples/sec: 149.49\n",
            "2020-03-08 17:27:47,200 epoch 66 - iter 82/417 - loss 2.85608992 - samples/sec: 144.04\n",
            "2020-03-08 17:27:56,465 epoch 66 - iter 123/417 - loss 2.84168456 - samples/sec: 141.76\n",
            "2020-03-08 17:28:05,555 epoch 66 - iter 164/417 - loss 2.81307980 - samples/sec: 144.56\n",
            "2020-03-08 17:28:14,475 epoch 66 - iter 205/417 - loss 2.82804751 - samples/sec: 147.30\n",
            "2020-03-08 17:28:23,799 epoch 66 - iter 246/417 - loss 2.86238722 - samples/sec: 140.88\n",
            "2020-03-08 17:28:32,858 epoch 66 - iter 287/417 - loss 2.83757347 - samples/sec: 145.00\n",
            "2020-03-08 17:28:41,769 epoch 66 - iter 328/417 - loss 2.81837805 - samples/sec: 147.41\n",
            "2020-03-08 17:28:50,484 epoch 66 - iter 369/417 - loss 2.80893360 - samples/sec: 150.77\n",
            "2020-03-08 17:28:59,290 epoch 66 - iter 410/417 - loss 2.79855107 - samples/sec: 149.18\n",
            "2020-03-08 17:29:00,779 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:29:00,780 EPOCH 66 done: loss 2.7981 - lr 0.0250\n",
            "2020-03-08 17:29:31,799 DEV : loss 0.1700652688741684 - score 0.7295676710096417\n",
            "2020-03-08 17:29:33,297 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:29:33,298 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:29:42,949 epoch 67 - iter 41/417 - loss 2.77598845 - samples/sec: 136.00\n",
            "2020-03-08 17:29:52,116 epoch 67 - iter 82/417 - loss 2.89142342 - samples/sec: 143.29\n",
            "2020-03-08 17:30:01,431 epoch 67 - iter 123/417 - loss 2.89343687 - samples/sec: 141.01\n",
            "2020-03-08 17:30:10,655 epoch 67 - iter 164/417 - loss 2.84153395 - samples/sec: 142.41\n",
            "2020-03-08 17:30:19,751 epoch 67 - iter 205/417 - loss 2.81048866 - samples/sec: 144.42\n",
            "2020-03-08 17:30:28,749 epoch 67 - iter 246/417 - loss 2.78546207 - samples/sec: 146.00\n",
            "2020-03-08 17:30:37,577 epoch 67 - iter 287/417 - loss 2.74157093 - samples/sec: 148.82\n",
            "2020-03-08 17:30:46,374 epoch 67 - iter 328/417 - loss 2.74337819 - samples/sec: 149.35\n",
            "2020-03-08 17:30:55,294 epoch 67 - iter 369/417 - loss 2.76185150 - samples/sec: 147.27\n",
            "2020-03-08 17:31:04,276 epoch 67 - iter 410/417 - loss 2.79279504 - samples/sec: 146.28\n",
            "2020-03-08 17:31:05,734 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:31:05,735 EPOCH 67 done: loss 2.7983 - lr 0.0250\n",
            "2020-03-08 17:31:35,262 DEV : loss 0.16860826313495636 - score 0.7342053208779665\n",
            "Epoch    67: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-03-08 17:31:36,745 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:31:36,747 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:31:45,397 epoch 68 - iter 41/417 - loss 2.89466718 - samples/sec: 151.75\n",
            "2020-03-08 17:31:54,459 epoch 68 - iter 82/417 - loss 2.73862159 - samples/sec: 144.96\n",
            "2020-03-08 17:32:03,794 epoch 68 - iter 123/417 - loss 2.66865908 - samples/sec: 140.75\n",
            "2020-03-08 17:32:12,646 epoch 68 - iter 164/417 - loss 2.66313107 - samples/sec: 148.42\n",
            "2020-03-08 17:32:21,466 epoch 68 - iter 205/417 - loss 2.66961021 - samples/sec: 148.96\n",
            "2020-03-08 17:32:30,633 epoch 68 - iter 246/417 - loss 2.65081172 - samples/sec: 143.30\n",
            "2020-03-08 17:32:39,161 epoch 68 - iter 287/417 - loss 2.64418081 - samples/sec: 154.06\n",
            "2020-03-08 17:32:48,251 epoch 68 - iter 328/417 - loss 2.64074925 - samples/sec: 144.52\n",
            "2020-03-08 17:32:57,231 epoch 68 - iter 369/417 - loss 2.64775576 - samples/sec: 146.27\n",
            "2020-03-08 17:33:06,008 epoch 68 - iter 410/417 - loss 2.64898932 - samples/sec: 149.67\n",
            "2020-03-08 17:33:07,469 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:33:07,470 EPOCH 68 done: loss 2.6522 - lr 0.0125\n",
            "2020-03-08 17:33:37,724 DEV : loss 0.17072540521621704 - score 0.7317490289225127\n",
            "2020-03-08 17:33:39,220 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:33:39,221 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:33:48,760 epoch 69 - iter 41/417 - loss 2.70769010 - samples/sec: 137.61\n",
            "2020-03-08 17:33:57,438 epoch 69 - iter 82/417 - loss 2.71847286 - samples/sec: 151.39\n",
            "2020-03-08 17:34:06,176 epoch 69 - iter 123/417 - loss 2.66625175 - samples/sec: 150.34\n",
            "2020-03-08 17:34:14,793 epoch 69 - iter 164/417 - loss 2.66272611 - samples/sec: 152.45\n",
            "2020-03-08 17:34:23,925 epoch 69 - iter 205/417 - loss 2.70635650 - samples/sec: 143.84\n",
            "2020-03-08 17:34:33,353 epoch 69 - iter 246/417 - loss 2.67765943 - samples/sec: 139.31\n",
            "2020-03-08 17:34:42,645 epoch 69 - iter 287/417 - loss 2.64130475 - samples/sec: 141.36\n",
            "2020-03-08 17:34:51,753 epoch 69 - iter 328/417 - loss 2.66274436 - samples/sec: 144.25\n",
            "2020-03-08 17:35:00,489 epoch 69 - iter 369/417 - loss 2.66062987 - samples/sec: 150.37\n",
            "2020-03-08 17:35:09,614 epoch 69 - iter 410/417 - loss 2.64114581 - samples/sec: 143.96\n",
            "2020-03-08 17:35:11,178 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:35:11,179 EPOCH 69 done: loss 2.6352 - lr 0.0125\n",
            "2020-03-08 17:35:41,594 DEV : loss 0.16468273103237152 - score 0.734034318743148\n",
            "2020-03-08 17:35:43,098 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:35:43,099 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:35:52,224 epoch 70 - iter 41/417 - loss 2.54030204 - samples/sec: 143.85\n",
            "2020-03-08 17:36:01,914 epoch 70 - iter 82/417 - loss 2.55648016 - samples/sec: 135.56\n",
            "2020-03-08 17:36:10,933 epoch 70 - iter 123/417 - loss 2.64659641 - samples/sec: 145.66\n",
            "2020-03-08 17:36:20,081 epoch 70 - iter 164/417 - loss 2.57979265 - samples/sec: 143.61\n",
            "2020-03-08 17:36:29,302 epoch 70 - iter 205/417 - loss 2.60913977 - samples/sec: 142.49\n",
            "2020-03-08 17:36:38,267 epoch 70 - iter 246/417 - loss 2.59795963 - samples/sec: 146.55\n",
            "2020-03-08 17:36:47,268 epoch 70 - iter 287/417 - loss 2.59972809 - samples/sec: 145.96\n",
            "2020-03-08 17:36:56,473 epoch 70 - iter 328/417 - loss 2.58961162 - samples/sec: 142.73\n",
            "2020-03-08 17:37:05,439 epoch 70 - iter 369/417 - loss 2.61209396 - samples/sec: 146.55\n",
            "2020-03-08 17:37:14,312 epoch 70 - iter 410/417 - loss 2.60957640 - samples/sec: 148.04\n",
            "2020-03-08 17:37:15,852 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:37:15,853 EPOCH 70 done: loss 2.6185 - lr 0.0125\n",
            "2020-03-08 17:37:47,389 DEV : loss 0.16672956943511963 - score 0.7349296109671857\n",
            "2020-03-08 17:37:48,893 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:37:48,895 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:37:58,445 epoch 71 - iter 41/417 - loss 2.35225202 - samples/sec: 137.43\n",
            "2020-03-08 17:38:07,786 epoch 71 - iter 82/417 - loss 2.59477815 - samples/sec: 140.63\n",
            "2020-03-08 17:38:16,967 epoch 71 - iter 123/417 - loss 2.57113232 - samples/sec: 143.08\n",
            "2020-03-08 17:38:26,336 epoch 71 - iter 164/417 - loss 2.57565853 - samples/sec: 140.20\n",
            "2020-03-08 17:38:35,411 epoch 71 - iter 205/417 - loss 2.54879717 - samples/sec: 144.78\n",
            "2020-03-08 17:38:44,337 epoch 71 - iter 246/417 - loss 2.54728231 - samples/sec: 147.18\n",
            "2020-03-08 17:38:53,390 epoch 71 - iter 287/417 - loss 2.54425886 - samples/sec: 145.11\n",
            "2020-03-08 17:39:02,371 epoch 71 - iter 328/417 - loss 2.54430475 - samples/sec: 146.29\n",
            "2020-03-08 17:39:11,778 epoch 71 - iter 369/417 - loss 2.55013336 - samples/sec: 139.66\n",
            "2020-03-08 17:39:20,789 epoch 71 - iter 410/417 - loss 2.56434402 - samples/sec: 145.81\n",
            "2020-03-08 17:39:22,293 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:39:22,294 EPOCH 71 done: loss 2.5586 - lr 0.0125\n",
            "2020-03-08 17:39:52,303 DEV : loss 0.175059512257576 - score 0.7341033293591395\n",
            "Epoch    71: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2020-03-08 17:39:53,797 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:39:53,799 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:40:03,297 epoch 72 - iter 41/417 - loss 2.49385749 - samples/sec: 138.20\n",
            "2020-03-08 17:40:12,583 epoch 72 - iter 82/417 - loss 2.47052250 - samples/sec: 141.47\n",
            "2020-03-08 17:40:21,677 epoch 72 - iter 123/417 - loss 2.50107290 - samples/sec: 144.45\n",
            "2020-03-08 17:40:30,858 epoch 72 - iter 164/417 - loss 2.45846189 - samples/sec: 143.09\n",
            "2020-03-08 17:40:39,906 epoch 72 - iter 205/417 - loss 2.44875006 - samples/sec: 145.19\n",
            "2020-03-08 17:40:49,328 epoch 72 - iter 246/417 - loss 2.44133834 - samples/sec: 139.42\n",
            "2020-03-08 17:40:58,285 epoch 72 - iter 287/417 - loss 2.45323678 - samples/sec: 146.69\n",
            "2020-03-08 17:41:07,180 epoch 72 - iter 328/417 - loss 2.44475189 - samples/sec: 147.68\n",
            "2020-03-08 17:41:15,966 epoch 72 - iter 369/417 - loss 2.43125225 - samples/sec: 149.52\n",
            "2020-03-08 17:41:24,592 epoch 72 - iter 410/417 - loss 2.44265841 - samples/sec: 152.31\n",
            "2020-03-08 17:41:26,104 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:41:26,106 EPOCH 72 done: loss 2.4333 - lr 0.0063\n",
            "2020-03-08 17:41:58,751 DEV : loss 0.1759827435016632 - score 0.7325707959492344\n",
            "2020-03-08 17:42:00,266 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:42:00,268 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:42:09,949 epoch 73 - iter 41/417 - loss 2.45660293 - samples/sec: 135.58\n",
            "2020-03-08 17:42:22,900 epoch 73 - iter 82/417 - loss 2.45877262 - samples/sec: 101.40\n",
            "2020-03-08 17:42:32,666 epoch 73 - iter 123/417 - loss 2.43774407 - samples/sec: 134.50\n",
            "2020-03-08 17:42:41,798 epoch 73 - iter 164/417 - loss 2.47385766 - samples/sec: 143.85\n",
            "2020-03-08 17:42:50,854 epoch 73 - iter 205/417 - loss 2.47677952 - samples/sec: 145.06\n",
            "2020-03-08 17:42:59,739 epoch 73 - iter 246/417 - loss 2.46956108 - samples/sec: 147.85\n",
            "2020-03-08 17:43:08,634 epoch 73 - iter 287/417 - loss 2.46996940 - samples/sec: 147.69\n",
            "2020-03-08 17:43:17,677 epoch 73 - iter 328/417 - loss 2.46281859 - samples/sec: 145.26\n",
            "2020-03-08 17:43:26,783 epoch 73 - iter 369/417 - loss 2.47866542 - samples/sec: 144.27\n",
            "2020-03-08 17:43:35,337 epoch 73 - iter 410/417 - loss 2.47892472 - samples/sec: 153.59\n",
            "2020-03-08 17:43:36,739 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:43:36,740 EPOCH 73 done: loss 2.4888 - lr 0.0063\n",
            "2020-03-08 17:44:07,405 DEV : loss 0.1705087274312973 - score 0.7354593083749182\n",
            "2020-03-08 17:44:08,906 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:44:08,908 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:44:18,682 epoch 74 - iter 41/417 - loss 2.23555900 - samples/sec: 134.29\n",
            "2020-03-08 17:44:28,225 epoch 74 - iter 82/417 - loss 2.29045663 - samples/sec: 137.65\n",
            "2020-03-08 17:44:37,327 epoch 74 - iter 123/417 - loss 2.33517131 - samples/sec: 144.32\n",
            "2020-03-08 17:44:46,385 epoch 74 - iter 164/417 - loss 2.36909086 - samples/sec: 145.03\n",
            "2020-03-08 17:44:55,675 epoch 74 - iter 205/417 - loss 2.35324425 - samples/sec: 141.39\n",
            "2020-03-08 17:45:04,496 epoch 74 - iter 246/417 - loss 2.36380760 - samples/sec: 148.95\n",
            "2020-03-08 17:45:13,510 epoch 74 - iter 287/417 - loss 2.39119029 - samples/sec: 145.75\n",
            "2020-03-08 17:45:22,451 epoch 74 - iter 328/417 - loss 2.38620554 - samples/sec: 146.94\n",
            "2020-03-08 17:45:31,026 epoch 74 - iter 369/417 - loss 2.39704770 - samples/sec: 153.22\n",
            "2020-03-08 17:45:40,552 epoch 74 - iter 410/417 - loss 2.39359296 - samples/sec: 137.89\n",
            "2020-03-08 17:45:42,182 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:45:42,183 EPOCH 74 done: loss 2.3924 - lr 0.0063\n",
            "2020-03-08 17:46:13,605 DEV : loss 0.1680862158536911 - score 0.7355026837662896\n",
            "2020-03-08 17:46:15,114 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:46:15,115 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:46:24,573 epoch 75 - iter 41/417 - loss 2.43470067 - samples/sec: 138.79\n",
            "2020-03-08 17:46:34,030 epoch 75 - iter 82/417 - loss 2.42812337 - samples/sec: 138.90\n",
            "2020-03-08 17:46:43,019 epoch 75 - iter 123/417 - loss 2.40761504 - samples/sec: 146.15\n",
            "2020-03-08 17:46:51,931 epoch 75 - iter 164/417 - loss 2.44619449 - samples/sec: 147.40\n",
            "2020-03-08 17:47:00,570 epoch 75 - iter 205/417 - loss 2.46391069 - samples/sec: 152.10\n",
            "2020-03-08 17:47:09,329 epoch 75 - iter 246/417 - loss 2.43010795 - samples/sec: 149.97\n",
            "2020-03-08 17:47:18,258 epoch 75 - iter 287/417 - loss 2.44830034 - samples/sec: 147.15\n",
            "2020-03-08 17:47:27,664 epoch 75 - iter 328/417 - loss 2.46522183 - samples/sec: 139.66\n",
            "2020-03-08 17:47:36,586 epoch 75 - iter 369/417 - loss 2.46363612 - samples/sec: 147.26\n",
            "2020-03-08 17:47:45,649 epoch 75 - iter 410/417 - loss 2.45370146 - samples/sec: 144.97\n",
            "2020-03-08 17:47:47,153 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:47:47,155 EPOCH 75 done: loss 2.4604 - lr 0.0063\n",
            "2020-03-08 17:48:18,820 DEV : loss 0.16809897124767303 - score 0.7366703150415757\n",
            "Epoch    75: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2020-03-08 17:48:20,323 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:48:20,325 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:48:29,875 epoch 76 - iter 41/417 - loss 2.42718929 - samples/sec: 137.43\n",
            "2020-03-08 17:48:38,877 epoch 76 - iter 82/417 - loss 2.43035584 - samples/sec: 145.92\n",
            "2020-03-08 17:48:47,808 epoch 76 - iter 123/417 - loss 2.41110769 - samples/sec: 147.10\n",
            "2020-03-08 17:48:56,951 epoch 76 - iter 164/417 - loss 2.40208025 - samples/sec: 143.69\n",
            "2020-03-08 17:49:06,199 epoch 76 - iter 205/417 - loss 2.40274039 - samples/sec: 142.06\n",
            "2020-03-08 17:49:14,985 epoch 76 - iter 246/417 - loss 2.39344690 - samples/sec: 149.51\n",
            "2020-03-08 17:49:23,528 epoch 76 - iter 287/417 - loss 2.40272974 - samples/sec: 153.78\n",
            "2020-03-08 17:49:31,930 epoch 76 - iter 328/417 - loss 2.39905022 - samples/sec: 156.37\n",
            "2020-03-08 17:49:40,745 epoch 76 - iter 369/417 - loss 2.41025033 - samples/sec: 149.04\n",
            "2020-03-08 17:49:49,647 epoch 76 - iter 410/417 - loss 2.42732340 - samples/sec: 147.61\n",
            "2020-03-08 17:49:51,167 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:49:51,168 EPOCH 76 done: loss 2.4197 - lr 0.0031\n",
            "2020-03-08 17:50:23,183 DEV : loss 0.16925972700119019 - score 0.7361145986342508\n",
            "2020-03-08 17:50:24,684 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:50:24,686 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:50:34,362 epoch 77 - iter 41/417 - loss 2.16180948 - samples/sec: 135.65\n",
            "2020-03-08 17:50:43,881 epoch 77 - iter 82/417 - loss 2.24243983 - samples/sec: 137.99\n",
            "2020-03-08 17:50:53,060 epoch 77 - iter 123/417 - loss 2.22284133 - samples/sec: 143.12\n",
            "2020-03-08 17:51:01,947 epoch 77 - iter 164/417 - loss 2.30883243 - samples/sec: 147.82\n",
            "2020-03-08 17:51:11,074 epoch 77 - iter 205/417 - loss 2.32373548 - samples/sec: 143.93\n",
            "2020-03-08 17:51:19,919 epoch 77 - iter 246/417 - loss 2.33938761 - samples/sec: 148.52\n",
            "2020-03-08 17:51:28,919 epoch 77 - iter 287/417 - loss 2.33495869 - samples/sec: 145.97\n",
            "2020-03-08 17:51:37,777 epoch 77 - iter 328/417 - loss 2.29551334 - samples/sec: 148.31\n",
            "2020-03-08 17:51:46,442 epoch 77 - iter 369/417 - loss 2.31709407 - samples/sec: 151.60\n",
            "2020-03-08 17:51:55,010 epoch 77 - iter 410/417 - loss 2.33443461 - samples/sec: 153.35\n",
            "2020-03-08 17:51:56,430 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:51:56,431 EPOCH 77 done: loss 2.3343 - lr 0.0031\n",
            "2020-03-08 17:52:25,782 DEV : loss 0.16992469131946564 - score 0.7365200001327072\n",
            "2020-03-08 17:52:27,284 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 17:52:27,285 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:52:36,209 epoch 78 - iter 41/417 - loss 2.27024668 - samples/sec: 147.07\n",
            "2020-03-08 17:52:45,052 epoch 78 - iter 82/417 - loss 2.26636626 - samples/sec: 148.57\n",
            "2020-03-08 17:52:53,564 epoch 78 - iter 123/417 - loss 2.32225118 - samples/sec: 154.32\n",
            "2020-03-08 17:53:02,180 epoch 78 - iter 164/417 - loss 2.30560350 - samples/sec: 152.47\n",
            "2020-03-08 17:53:10,658 epoch 78 - iter 205/417 - loss 2.31918663 - samples/sec: 154.97\n",
            "2020-03-08 17:53:19,181 epoch 78 - iter 246/417 - loss 2.33991888 - samples/sec: 154.17\n",
            "2020-03-08 17:53:28,057 epoch 78 - iter 287/417 - loss 2.37084372 - samples/sec: 148.01\n",
            "2020-03-08 17:53:36,648 epoch 78 - iter 328/417 - loss 2.36661297 - samples/sec: 152.94\n",
            "2020-03-08 17:53:45,231 epoch 78 - iter 369/417 - loss 2.37011412 - samples/sec: 153.07\n",
            "2020-03-08 17:53:54,026 epoch 78 - iter 410/417 - loss 2.34693900 - samples/sec: 149.37\n",
            "2020-03-08 17:53:55,469 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:53:55,471 EPOCH 78 done: loss 2.3450 - lr 0.0031\n",
            "2020-03-08 17:54:26,812 DEV : loss 0.16824354231357574 - score 0.7361279549671762\n",
            "2020-03-08 17:54:28,326 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 17:54:28,328 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:54:38,058 epoch 79 - iter 41/417 - loss 2.28940538 - samples/sec: 134.89\n",
            "2020-03-08 17:54:47,580 epoch 79 - iter 82/417 - loss 2.39483041 - samples/sec: 137.97\n",
            "2020-03-08 17:54:56,952 epoch 79 - iter 123/417 - loss 2.41449629 - samples/sec: 140.18\n",
            "2020-03-08 17:55:05,779 epoch 79 - iter 164/417 - loss 2.38481480 - samples/sec: 148.82\n",
            "2020-03-08 17:55:14,716 epoch 79 - iter 205/417 - loss 2.38451781 - samples/sec: 146.99\n",
            "2020-03-08 17:55:23,523 epoch 79 - iter 246/417 - loss 2.42177724 - samples/sec: 149.16\n",
            "2020-03-08 17:55:32,454 epoch 79 - iter 287/417 - loss 2.41197965 - samples/sec: 147.06\n",
            "2020-03-08 17:55:41,606 epoch 79 - iter 328/417 - loss 2.39576590 - samples/sec: 143.56\n",
            "2020-03-08 17:55:50,730 epoch 79 - iter 369/417 - loss 2.39567686 - samples/sec: 143.95\n",
            "2020-03-08 17:55:59,497 epoch 79 - iter 410/417 - loss 2.40259916 - samples/sec: 149.84\n",
            "2020-03-08 17:56:01,017 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:56:01,018 EPOCH 79 done: loss 2.4080 - lr 0.0031\n",
            "2020-03-08 17:56:31,049 DEV : loss 0.16789767146110535 - score 0.7359327631044997\n",
            "Epoch    79: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2020-03-08 17:56:32,548 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 17:56:32,549 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:56:42,077 epoch 80 - iter 41/417 - loss 2.33317043 - samples/sec: 137.76\n",
            "2020-03-08 17:56:51,121 epoch 80 - iter 82/417 - loss 2.33006780 - samples/sec: 145.23\n",
            "2020-03-08 17:57:00,302 epoch 80 - iter 123/417 - loss 2.37698443 - samples/sec: 143.06\n",
            "2020-03-08 17:57:09,339 epoch 80 - iter 164/417 - loss 2.33709160 - samples/sec: 145.35\n",
            "2020-03-08 17:57:18,518 epoch 80 - iter 205/417 - loss 2.29544560 - samples/sec: 143.12\n",
            "2020-03-08 17:57:27,513 epoch 80 - iter 246/417 - loss 2.29930541 - samples/sec: 146.07\n",
            "2020-03-08 17:57:36,331 epoch 80 - iter 287/417 - loss 2.32431808 - samples/sec: 148.97\n",
            "2020-03-08 17:57:45,307 epoch 80 - iter 328/417 - loss 2.32712374 - samples/sec: 146.37\n",
            "2020-03-08 17:57:54,090 epoch 80 - iter 369/417 - loss 2.33453370 - samples/sec: 149.59\n",
            "2020-03-08 17:58:03,045 epoch 80 - iter 410/417 - loss 2.31696805 - samples/sec: 146.69\n",
            "2020-03-08 17:58:04,547 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:58:04,549 EPOCH 80 done: loss 2.3217 - lr 0.0016\n",
            "2020-03-08 17:58:40,074 DEV : loss 0.1678745150566101 - score 0.7361300016301442\n",
            "2020-03-08 17:58:41,568 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 17:58:41,569 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 17:58:50,838 epoch 81 - iter 41/417 - loss 2.38447234 - samples/sec: 141.61\n",
            "2020-03-08 17:58:59,624 epoch 81 - iter 82/417 - loss 2.34130571 - samples/sec: 149.54\n",
            "2020-03-08 17:59:08,700 epoch 81 - iter 123/417 - loss 2.36562234 - samples/sec: 144.73\n",
            "2020-03-08 17:59:17,392 epoch 81 - iter 164/417 - loss 2.32418706 - samples/sec: 151.16\n",
            "2020-03-08 17:59:25,928 epoch 81 - iter 205/417 - loss 2.35152664 - samples/sec: 153.89\n",
            "2020-03-08 17:59:34,688 epoch 81 - iter 246/417 - loss 2.36145421 - samples/sec: 149.97\n",
            "2020-03-08 17:59:43,376 epoch 81 - iter 287/417 - loss 2.37755359 - samples/sec: 151.21\n",
            "2020-03-08 17:59:52,189 epoch 81 - iter 328/417 - loss 2.35853560 - samples/sec: 149.07\n",
            "2020-03-08 18:00:02,203 epoch 81 - iter 369/417 - loss 2.35655096 - samples/sec: 131.21\n",
            "2020-03-08 18:00:11,295 epoch 81 - iter 410/417 - loss 2.35152894 - samples/sec: 144.49\n",
            "2020-03-08 18:00:13,306 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:00:13,309 EPOCH 81 done: loss 2.3421 - lr 0.0016\n",
            "2020-03-08 18:00:45,512 DEV : loss 0.16829092800617218 - score 0.7360194096729142\n",
            "2020-03-08 18:00:46,946 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 18:00:46,947 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:00:56,587 epoch 82 - iter 41/417 - loss 1.95806314 - samples/sec: 136.17\n",
            "2020-03-08 18:01:05,160 epoch 82 - iter 82/417 - loss 2.22302680 - samples/sec: 153.23\n",
            "2020-03-08 18:01:13,835 epoch 82 - iter 123/417 - loss 2.23660848 - samples/sec: 151.42\n",
            "2020-03-08 18:01:22,702 epoch 82 - iter 164/417 - loss 2.26413158 - samples/sec: 148.16\n",
            "2020-03-08 18:01:31,684 epoch 82 - iter 205/417 - loss 2.33206169 - samples/sec: 146.29\n",
            "2020-03-08 18:01:40,533 epoch 82 - iter 246/417 - loss 2.37017229 - samples/sec: 148.44\n",
            "2020-03-08 18:01:49,443 epoch 82 - iter 287/417 - loss 2.37307233 - samples/sec: 147.44\n",
            "2020-03-08 18:01:58,238 epoch 82 - iter 328/417 - loss 2.36389088 - samples/sec: 149.34\n",
            "2020-03-08 18:02:07,030 epoch 82 - iter 369/417 - loss 2.35130579 - samples/sec: 149.41\n",
            "2020-03-08 18:02:16,067 epoch 82 - iter 410/417 - loss 2.32604418 - samples/sec: 145.36\n",
            "2020-03-08 18:02:17,581 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:02:17,582 EPOCH 82 done: loss 2.3264 - lr 0.0016\n",
            "2020-03-08 18:02:50,361 DEV : loss 0.1693795770406723 - score 0.7357895131564773\n",
            "2020-03-08 18:02:51,779 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 18:02:51,781 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:03:01,747 epoch 83 - iter 41/417 - loss 2.33099333 - samples/sec: 131.71\n",
            "2020-03-08 18:03:10,943 epoch 83 - iter 82/417 - loss 2.31647842 - samples/sec: 142.85\n",
            "2020-03-08 18:03:20,249 epoch 83 - iter 123/417 - loss 2.30170488 - samples/sec: 141.18\n",
            "2020-03-08 18:03:28,882 epoch 83 - iter 164/417 - loss 2.37884705 - samples/sec: 152.17\n",
            "2020-03-08 18:03:37,549 epoch 83 - iter 205/417 - loss 2.36709316 - samples/sec: 151.60\n",
            "2020-03-08 18:03:46,378 epoch 83 - iter 246/417 - loss 2.30537052 - samples/sec: 148.78\n",
            "2020-03-08 18:03:54,862 epoch 83 - iter 287/417 - loss 2.31545745 - samples/sec: 154.88\n",
            "2020-03-08 18:04:03,601 epoch 83 - iter 328/417 - loss 2.33358791 - samples/sec: 150.33\n",
            "2020-03-08 18:04:12,655 epoch 83 - iter 369/417 - loss 2.34906072 - samples/sec: 145.09\n",
            "2020-03-08 18:04:21,233 epoch 83 - iter 410/417 - loss 2.37113752 - samples/sec: 153.15\n",
            "2020-03-08 18:04:22,684 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:04:22,685 EPOCH 83 done: loss 2.3650 - lr 0.0016\n",
            "2020-03-08 18:04:52,549 DEV : loss 0.167038694024086 - score 0.7360580527521111\n",
            "Epoch    83: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2020-03-08 18:04:53,988 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 18:04:53,990 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:05:03,500 epoch 84 - iter 41/417 - loss 2.17390047 - samples/sec: 138.01\n",
            "2020-03-08 18:05:12,486 epoch 84 - iter 82/417 - loss 2.18068419 - samples/sec: 146.21\n",
            "2020-03-08 18:05:21,378 epoch 84 - iter 123/417 - loss 2.17656688 - samples/sec: 147.75\n",
            "2020-03-08 18:05:30,217 epoch 84 - iter 164/417 - loss 2.20142037 - samples/sec: 148.64\n",
            "2020-03-08 18:05:38,996 epoch 84 - iter 205/417 - loss 2.24351996 - samples/sec: 149.64\n",
            "2020-03-08 18:05:48,238 epoch 84 - iter 246/417 - loss 2.25592332 - samples/sec: 142.15\n",
            "2020-03-08 18:05:57,422 epoch 84 - iter 287/417 - loss 2.27269771 - samples/sec: 143.04\n",
            "2020-03-08 18:06:06,461 epoch 84 - iter 328/417 - loss 2.28782647 - samples/sec: 145.32\n",
            "2020-03-08 18:06:15,601 epoch 84 - iter 369/417 - loss 2.26285665 - samples/sec: 143.73\n",
            "2020-03-08 18:06:24,654 epoch 84 - iter 410/417 - loss 2.27111751 - samples/sec: 145.09\n",
            "2020-03-08 18:06:26,174 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:06:26,175 EPOCH 84 done: loss 2.2745 - lr 0.0008\n",
            "2020-03-08 18:06:58,888 DEV : loss 0.16973945498466492 - score 0.7355400750823107\n",
            "2020-03-08 18:07:00,334 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 18:07:00,336 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:07:10,116 epoch 85 - iter 41/417 - loss 2.34955682 - samples/sec: 134.21\n",
            "2020-03-08 18:07:19,682 epoch 85 - iter 82/417 - loss 2.44967657 - samples/sec: 137.33\n",
            "2020-03-08 18:07:28,948 epoch 85 - iter 123/417 - loss 2.44962054 - samples/sec: 141.79\n",
            "2020-03-08 18:07:38,400 epoch 85 - iter 164/417 - loss 2.43729163 - samples/sec: 138.97\n",
            "2020-03-08 18:07:48,094 epoch 85 - iter 205/417 - loss 2.41041424 - samples/sec: 135.52\n",
            "2020-03-08 18:07:57,405 epoch 85 - iter 246/417 - loss 2.37582755 - samples/sec: 141.08\n",
            "2020-03-08 18:08:06,852 epoch 85 - iter 287/417 - loss 2.37592792 - samples/sec: 139.05\n",
            "2020-03-08 18:08:16,523 epoch 85 - iter 328/417 - loss 2.35363014 - samples/sec: 135.82\n",
            "2020-03-08 18:08:25,634 epoch 85 - iter 369/417 - loss 2.34230274 - samples/sec: 144.21\n",
            "2020-03-08 18:08:35,082 epoch 85 - iter 410/417 - loss 2.32665768 - samples/sec: 139.03\n",
            "2020-03-08 18:08:36,707 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:08:36,709 EPOCH 85 done: loss 2.3158 - lr 0.0008\n",
            "2020-03-08 18:09:09,591 DEV : loss 0.16944235563278198 - score 0.735481426139693\n",
            "2020-03-08 18:09:11,015 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 18:09:11,017 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:09:21,147 epoch 86 - iter 41/417 - loss 2.18011484 - samples/sec: 129.57\n",
            "2020-03-08 18:09:30,778 epoch 86 - iter 82/417 - loss 2.27594879 - samples/sec: 136.39\n",
            "2020-03-08 18:09:40,124 epoch 86 - iter 123/417 - loss 2.28538390 - samples/sec: 140.55\n",
            "2020-03-08 18:09:49,459 epoch 86 - iter 164/417 - loss 2.27513950 - samples/sec: 140.71\n",
            "2020-03-08 18:09:58,470 epoch 86 - iter 205/417 - loss 2.24576876 - samples/sec: 145.82\n",
            "2020-03-08 18:10:07,150 epoch 86 - iter 246/417 - loss 2.23117039 - samples/sec: 151.38\n",
            "2020-03-08 18:10:15,778 epoch 86 - iter 287/417 - loss 2.25638039 - samples/sec: 152.26\n",
            "2020-03-08 18:10:24,826 epoch 86 - iter 328/417 - loss 2.26193820 - samples/sec: 145.18\n",
            "2020-03-08 18:10:33,955 epoch 86 - iter 369/417 - loss 2.24912931 - samples/sec: 143.90\n",
            "2020-03-08 18:10:43,039 epoch 86 - iter 410/417 - loss 2.26200403 - samples/sec: 144.60\n",
            "2020-03-08 18:10:44,524 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:10:44,525 EPOCH 86 done: loss 2.2643 - lr 0.0008\n",
            "2020-03-08 18:11:15,442 DEV : loss 0.1684461236000061 - score 0.7353410842797494\n",
            "2020-03-08 18:11:16,906 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 18:11:16,907 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:11:26,687 epoch 87 - iter 41/417 - loss 2.60785039 - samples/sec: 134.22\n",
            "2020-03-08 18:11:36,373 epoch 87 - iter 82/417 - loss 2.43282520 - samples/sec: 135.60\n",
            "2020-03-08 18:11:45,917 epoch 87 - iter 123/417 - loss 2.38772299 - samples/sec: 137.63\n",
            "2020-03-08 18:11:55,166 epoch 87 - iter 164/417 - loss 2.31024170 - samples/sec: 142.03\n",
            "2020-03-08 18:12:04,039 epoch 87 - iter 205/417 - loss 2.32932913 - samples/sec: 148.04\n",
            "2020-03-08 18:12:12,760 epoch 87 - iter 246/417 - loss 2.30858332 - samples/sec: 150.63\n",
            "2020-03-08 18:12:21,728 epoch 87 - iter 287/417 - loss 2.32547125 - samples/sec: 146.48\n",
            "2020-03-08 18:12:30,361 epoch 87 - iter 328/417 - loss 2.34524985 - samples/sec: 152.21\n",
            "2020-03-08 18:12:39,106 epoch 87 - iter 369/417 - loss 2.36974713 - samples/sec: 150.23\n",
            "2020-03-08 18:12:48,495 epoch 87 - iter 410/417 - loss 2.37023017 - samples/sec: 139.92\n",
            "2020-03-08 18:12:50,020 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:12:50,021 EPOCH 87 done: loss 2.3635 - lr 0.0008\n",
            "2020-03-08 18:13:22,866 DEV : loss 0.16869229078292847 - score 0.7357328979178699\n",
            "Epoch    87: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2020-03-08 18:13:24,349 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 18:13:24,350 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:13:34,360 epoch 88 - iter 41/417 - loss 2.09113540 - samples/sec: 131.13\n",
            "2020-03-08 18:13:44,119 epoch 88 - iter 82/417 - loss 2.21443466 - samples/sec: 134.59\n",
            "2020-03-08 18:13:53,308 epoch 88 - iter 123/417 - loss 2.21099400 - samples/sec: 142.94\n",
            "2020-03-08 18:14:02,459 epoch 88 - iter 164/417 - loss 2.30763750 - samples/sec: 143.55\n",
            "2020-03-08 18:14:11,397 epoch 88 - iter 205/417 - loss 2.30482010 - samples/sec: 146.96\n",
            "2020-03-08 18:14:20,417 epoch 88 - iter 246/417 - loss 2.31039607 - samples/sec: 145.62\n",
            "2020-03-08 18:14:29,138 epoch 88 - iter 287/417 - loss 2.28834417 - samples/sec: 150.64\n",
            "2020-03-08 18:14:38,323 epoch 88 - iter 328/417 - loss 2.27548251 - samples/sec: 143.01\n",
            "2020-03-08 18:14:50,583 epoch 88 - iter 369/417 - loss 2.28637031 - samples/sec: 107.12\n",
            "2020-03-08 18:14:59,617 epoch 88 - iter 410/417 - loss 2.32405185 - samples/sec: 145.41\n",
            "2020-03-08 18:15:01,191 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:15:01,192 EPOCH 88 done: loss 2.3311 - lr 0.0004\n",
            "2020-03-08 18:15:32,757 DEV : loss 0.16876888275146484 - score 0.7354374750882112\n",
            "2020-03-08 18:15:34,250 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 18:15:34,252 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:15:43,906 epoch 89 - iter 41/417 - loss 2.28986169 - samples/sec: 135.96\n",
            "2020-03-08 18:15:52,931 epoch 89 - iter 82/417 - loss 2.31634424 - samples/sec: 145.54\n",
            "2020-03-08 18:16:01,991 epoch 89 - iter 123/417 - loss 2.32763205 - samples/sec: 144.99\n",
            "2020-03-08 18:16:11,009 epoch 89 - iter 164/417 - loss 2.25619060 - samples/sec: 145.69\n",
            "2020-03-08 18:16:20,153 epoch 89 - iter 205/417 - loss 2.30286836 - samples/sec: 143.68\n",
            "2020-03-08 18:16:29,228 epoch 89 - iter 246/417 - loss 2.28906002 - samples/sec: 144.77\n",
            "2020-03-08 18:16:37,949 epoch 89 - iter 287/417 - loss 2.27090893 - samples/sec: 150.64\n",
            "2020-03-08 18:16:46,771 epoch 89 - iter 328/417 - loss 2.29960242 - samples/sec: 148.92\n",
            "2020-03-08 18:16:55,502 epoch 89 - iter 369/417 - loss 2.30337841 - samples/sec: 150.48\n",
            "2020-03-08 18:17:04,471 epoch 89 - iter 410/417 - loss 2.31247316 - samples/sec: 146.45\n",
            "2020-03-08 18:17:06,021 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:17:06,022 EPOCH 89 done: loss 2.3100 - lr 0.0004\n",
            "2020-03-08 18:17:38,960 DEV : loss 0.16911394894123077 - score 0.7353956916376636\n",
            "2020-03-08 18:17:40,465 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 18:17:40,467 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:17:50,237 epoch 90 - iter 41/417 - loss 2.31913523 - samples/sec: 134.34\n",
            "2020-03-08 18:17:59,522 epoch 90 - iter 82/417 - loss 2.26753101 - samples/sec: 141.48\n",
            "2020-03-08 18:18:09,006 epoch 90 - iter 123/417 - loss 2.19013280 - samples/sec: 138.51\n",
            "2020-03-08 18:18:18,549 epoch 90 - iter 164/417 - loss 2.17168646 - samples/sec: 137.65\n",
            "2020-03-08 18:18:27,964 epoch 90 - iter 205/417 - loss 2.19313284 - samples/sec: 139.50\n",
            "2020-03-08 18:18:37,035 epoch 90 - iter 246/417 - loss 2.17417922 - samples/sec: 144.82\n",
            "2020-03-08 18:18:46,149 epoch 90 - iter 287/417 - loss 2.20847646 - samples/sec: 144.12\n",
            "2020-03-08 18:18:55,345 epoch 90 - iter 328/417 - loss 2.24494953 - samples/sec: 142.86\n",
            "2020-03-08 18:19:04,367 epoch 90 - iter 369/417 - loss 2.24229274 - samples/sec: 145.59\n",
            "2020-03-08 18:19:13,089 epoch 90 - iter 410/417 - loss 2.26067750 - samples/sec: 150.63\n",
            "2020-03-08 18:19:14,563 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:19:14,564 EPOCH 90 done: loss 2.2643 - lr 0.0004\n",
            "2020-03-08 18:19:45,520 DEV : loss 0.16933497786521912 - score 0.7353719682262359\n",
            "2020-03-08 18:19:47,007 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 18:19:47,008 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:19:56,688 epoch 91 - iter 41/417 - loss 2.22996235 - samples/sec: 135.60\n",
            "2020-03-08 18:20:06,410 epoch 91 - iter 82/417 - loss 2.30474513 - samples/sec: 135.10\n",
            "2020-03-08 18:20:15,900 epoch 91 - iter 123/417 - loss 2.27312679 - samples/sec: 138.42\n",
            "2020-03-08 18:20:25,167 epoch 91 - iter 164/417 - loss 2.26641716 - samples/sec: 141.75\n",
            "2020-03-08 18:20:34,420 epoch 91 - iter 205/417 - loss 2.27471359 - samples/sec: 141.97\n",
            "2020-03-08 18:20:43,523 epoch 91 - iter 246/417 - loss 2.26390233 - samples/sec: 144.30\n",
            "2020-03-08 18:20:52,574 epoch 91 - iter 287/417 - loss 2.31882861 - samples/sec: 145.13\n",
            "2020-03-08 18:21:01,601 epoch 91 - iter 328/417 - loss 2.29624639 - samples/sec: 145.53\n",
            "2020-03-08 18:21:10,528 epoch 91 - iter 369/417 - loss 2.30720501 - samples/sec: 147.17\n",
            "2020-03-08 18:21:19,729 epoch 91 - iter 410/417 - loss 2.32581753 - samples/sec: 142.76\n",
            "2020-03-08 18:21:21,260 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:21:21,261 EPOCH 91 done: loss 2.3301 - lr 0.0004\n",
            "2020-03-08 18:21:51,736 DEV : loss 0.16903646290302277 - score 0.7352223862110511\n",
            "Epoch    91: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2020-03-08 18:21:53,235 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 18:21:53,237 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:22:02,101 epoch 92 - iter 41/417 - loss 2.47684082 - samples/sec: 148.09\n",
            "2020-03-08 18:22:11,345 epoch 92 - iter 82/417 - loss 2.37594104 - samples/sec: 142.11\n",
            "2020-03-08 18:22:20,384 epoch 92 - iter 123/417 - loss 2.34673321 - samples/sec: 145.33\n",
            "2020-03-08 18:22:29,339 epoch 92 - iter 164/417 - loss 2.34320634 - samples/sec: 146.68\n",
            "2020-03-08 18:22:37,994 epoch 92 - iter 205/417 - loss 2.36424488 - samples/sec: 151.78\n",
            "2020-03-08 18:22:46,733 epoch 92 - iter 246/417 - loss 2.37320908 - samples/sec: 150.33\n",
            "2020-03-08 18:22:55,670 epoch 92 - iter 287/417 - loss 2.35738267 - samples/sec: 146.98\n",
            "2020-03-08 18:23:04,642 epoch 92 - iter 328/417 - loss 2.32829004 - samples/sec: 146.43\n",
            "2020-03-08 18:23:13,394 epoch 92 - iter 369/417 - loss 2.34466216 - samples/sec: 150.15\n",
            "2020-03-08 18:23:22,189 epoch 92 - iter 410/417 - loss 2.34515450 - samples/sec: 149.37\n",
            "2020-03-08 18:23:23,555 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:23:23,557 EPOCH 92 done: loss 2.3528 - lr 0.0002\n",
            "2020-03-08 18:23:54,997 DEV : loss 0.16840891540050507 - score 0.7354343814356193\n",
            "2020-03-08 18:23:56,493 BAD EPOCHS (no improvement): 1\n",
            "2020-03-08 18:23:56,495 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:24:06,149 epoch 93 - iter 41/417 - loss 2.11600369 - samples/sec: 135.96\n",
            "2020-03-08 18:24:15,472 epoch 93 - iter 82/417 - loss 2.31083611 - samples/sec: 140.91\n",
            "2020-03-08 18:24:24,340 epoch 93 - iter 123/417 - loss 2.32778818 - samples/sec: 148.14\n",
            "2020-03-08 18:24:33,770 epoch 93 - iter 164/417 - loss 2.33004059 - samples/sec: 139.40\n",
            "2020-03-08 18:24:43,109 epoch 93 - iter 205/417 - loss 2.33274745 - samples/sec: 140.64\n",
            "2020-03-08 18:24:52,184 epoch 93 - iter 246/417 - loss 2.29666362 - samples/sec: 144.74\n",
            "2020-03-08 18:25:01,150 epoch 93 - iter 287/417 - loss 2.30021850 - samples/sec: 146.54\n",
            "2020-03-08 18:25:10,168 epoch 93 - iter 328/417 - loss 2.28213600 - samples/sec: 145.67\n",
            "2020-03-08 18:25:19,055 epoch 93 - iter 369/417 - loss 2.31786504 - samples/sec: 147.83\n",
            "2020-03-08 18:25:28,009 epoch 93 - iter 410/417 - loss 2.33085149 - samples/sec: 146.71\n",
            "2020-03-08 18:25:29,592 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:25:29,593 EPOCH 93 done: loss 2.3196 - lr 0.0002\n",
            "2020-03-08 18:26:02,132 DEV : loss 0.16840502619743347 - score 0.73542522395905\n",
            "2020-03-08 18:26:03,631 BAD EPOCHS (no improvement): 2\n",
            "2020-03-08 18:26:03,633 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:26:13,217 epoch 94 - iter 41/417 - loss 2.49378122 - samples/sec: 136.96\n",
            "2020-03-08 18:26:22,733 epoch 94 - iter 82/417 - loss 2.29401728 - samples/sec: 138.03\n",
            "2020-03-08 18:26:31,992 epoch 94 - iter 123/417 - loss 2.28931628 - samples/sec: 141.89\n",
            "2020-03-08 18:26:41,439 epoch 94 - iter 164/417 - loss 2.23935421 - samples/sec: 139.09\n",
            "2020-03-08 18:26:50,877 epoch 94 - iter 205/417 - loss 2.27172671 - samples/sec: 139.18\n",
            "2020-03-08 18:27:00,194 epoch 94 - iter 246/417 - loss 2.29141600 - samples/sec: 140.99\n",
            "2020-03-08 18:27:09,275 epoch 94 - iter 287/417 - loss 2.30682814 - samples/sec: 144.65\n",
            "2020-03-08 18:27:18,232 epoch 94 - iter 328/417 - loss 2.30275717 - samples/sec: 146.65\n",
            "2020-03-08 18:27:27,561 epoch 94 - iter 369/417 - loss 2.27360440 - samples/sec: 140.82\n",
            "2020-03-08 18:27:36,923 epoch 94 - iter 410/417 - loss 2.29268214 - samples/sec: 140.32\n",
            "2020-03-08 18:27:38,452 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:27:38,453 EPOCH 94 done: loss 2.3064 - lr 0.0002\n",
            "2020-03-08 18:28:08,709 DEV : loss 0.16824044287204742 - score 0.7355952215531749\n",
            "2020-03-08 18:28:10,205 BAD EPOCHS (no improvement): 3\n",
            "2020-03-08 18:28:10,207 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:28:20,260 epoch 95 - iter 41/417 - loss 2.34288031 - samples/sec: 130.57\n",
            "2020-03-08 18:28:29,507 epoch 95 - iter 82/417 - loss 2.40398661 - samples/sec: 142.09\n",
            "2020-03-08 18:28:38,517 epoch 95 - iter 123/417 - loss 2.28207835 - samples/sec: 145.83\n",
            "2020-03-08 18:28:47,431 epoch 95 - iter 164/417 - loss 2.32350787 - samples/sec: 147.36\n",
            "2020-03-08 18:28:56,367 epoch 95 - iter 205/417 - loss 2.35981583 - samples/sec: 147.00\n",
            "2020-03-08 18:29:06,043 epoch 95 - iter 246/417 - loss 2.34081689 - samples/sec: 135.76\n",
            "2020-03-08 18:29:15,529 epoch 95 - iter 287/417 - loss 2.31872635 - samples/sec: 138.47\n",
            "2020-03-08 18:29:24,601 epoch 95 - iter 328/417 - loss 2.30762508 - samples/sec: 144.80\n",
            "2020-03-08 18:29:33,458 epoch 95 - iter 369/417 - loss 2.29950163 - samples/sec: 148.33\n",
            "2020-03-08 18:29:42,463 epoch 95 - iter 410/417 - loss 2.28961759 - samples/sec: 145.87\n",
            "2020-03-08 18:29:43,936 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:29:43,937 EPOCH 95 done: loss 2.2837 - lr 0.0002\n",
            "2020-03-08 18:30:16,073 DEV : loss 0.16851915419101715 - score 0.7355220415832331\n",
            "Epoch    95: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2020-03-08 18:30:17,550 BAD EPOCHS (no improvement): 4\n",
            "2020-03-08 18:30:17,552 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:30:17,553 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:30:17,554 learning rate too small - quitting training!\n",
            "2020-03-08 18:30:17,555 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:30:53,402 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-08 18:30:56,491 Testing using best model ...\n",
            "2020-03-08 18:30:56,495 loading file train_1/best-model.pt\n",
            "2020-03-08 18:32:08,467 Using REGRESSION - experimental\n",
            "2020-03-08 18:32:39,352 5.362700952113174\t0.6846024034192297\t0.7378075252139934\n",
            "2020-03-08 18:32:39,353 AVG: mse: 5.3627 - mae: 1.5935 - pearson: 0.7378 - spearman: 0.6846\n",
            "2020-03-08 18:32:39,355 ----------------------------------------------------------------------------------------------------\n",
            "1 - Test score: 0.7378075252139934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHZeqNHFIbZT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ab4827-3b31-4471-8200-dc43d40d1994"
      },
      "source": [
        "#!wget -c https://ghc-flair.s3.amazonaws.com/BioWordVec_PubMed_MIMICIII_d200.vec.bin \n",
        "\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('/content/BioWordVec_PubMed_MIMICIII_d200.vec.bin', binary=True)\n",
        "word_vectors.save('biowordvec.model')\n",
        "\n",
        "embedding =  WordEmbeddings('biowordvec.model')\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-76cacd20a431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/BioWordVec_PubMed_MIMICIII_d200.vec.bin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'biowordvec.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mWordEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'biowordvec.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     return open(uri, mode, ignore_ext=ignore_extension,\n\u001b[0;32m--> 458\u001b[0;31m                 transport_params=transport_params, **scrubbed_kwargs)\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/BioWordVec_PubMed_MIMICIII_d200.vec.bin'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuwCP9UYLTjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget -c https://ghc-flair.s3.amazonaws.com/wiki.en.zip\n",
        "!unzip wiki.en.zip\n",
        "\n",
        "import gensim\n",
        "\n",
        "word_vectors = gensim.models.KeyedVectors.load_word2vec_format('/content/wiki.en.vec', binary=False)\n",
        "word_vectors.save('wiki.model')\n",
        "\n",
        "wiki_embedding =  WordEmbeddings('wiki.model')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}